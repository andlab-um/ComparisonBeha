{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import ttest_ind, ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pareto smoothed importance sampling (PSIS)\n",
    "\n",
    "This module implements Pareto smoothed importance sampling (PSIS) and PSIS\n",
    "leave-one-out (LOO) cross-validation for Python (Numpy).\n",
    "\n",
    "Included functions\n",
    "------------------\n",
    "psisloo\n",
    "    Pareto smoothed importance sampling leave-one-out log predictive densities.\n",
    "\n",
    "psislw\n",
    "    Pareto smoothed importance sampling.\n",
    "\n",
    "gpdfitnew\n",
    "    Estimate the paramaters for the Generalized Pareto Distribution (GPD).\n",
    "\n",
    "gpinv\n",
    "    Inverse Generalised Pareto distribution function.\n",
    "\n",
    "sumlogs\n",
    "    Sum of vector where numbers are represented by their logarithms.\n",
    "\n",
    "References\n",
    "----------\n",
    "Aki Vehtari, Andrew Gelman and Jonah Gabry (2017). Practical\n",
    "Bayesian model evaluation using leave-one-out cross-validation\n",
    "and WAIC. Statistics and Computing, 27(5):1413–1432.\n",
    "doi:10.1007/s11222-016-9696-4. https://arxiv.org/abs/1507.04544\n",
    "\n",
    "Aki Vehtari, Andrew Gelman and Jonah Gabry (2017). Pareto\n",
    "smoothed importance sampling. https://arxiv.org/abs/arXiv:1507.02646v5\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division # For Python 2 compatibility\n",
    "import numpy as np\n",
    "\n",
    "# 3-Clause BSD License\n",
    "\"\"\"\n",
    "Copyright 2017 Aki Vehtari, Tuomas Sivula\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification,\n",
    "are permitted provided that the following conditions are met:\n",
    "\n",
    "1. Redistributions of source code must retain the above copyright notice, this\n",
    "list of conditions and the following disclaimer.\n",
    "\n",
    "2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "this list of conditions and the following disclaimer in the documentation and/or\n",
    "other materials provided with the distribution.\n",
    "\n",
    "3. Neither the name of the copyright holder nor the names of its contributors\n",
    "may be used to endorse or promote products derived from this software without\n",
    "specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n",
    "ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\n",
    "ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    "(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n",
    "LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n",
    "ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
    "(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n",
    "SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. \"\"\"\n",
    "\n",
    "\n",
    "def psisloo(log_lik, **kwargs):\n",
    "    r\"\"\"PSIS leave-one-out log predictive densities.\n",
    "\n",
    "    Computes the log predictive densities given posterior samples of the log\n",
    "    likelihood terms :math:`p(y_i|\\theta^s)` in input parameter `log_lik`.\n",
    "    Returns a sum of the leave-one-out log predictive densities `loo`,\n",
    "    individual leave-one-out log predictive density terms `loos` and an estimate\n",
    "    of Pareto tail indeces `ks`. The estimates are unreliable if tail index\n",
    "    ``k > 0.7`` (see more in the references listed in the module docstring).\n",
    "\n",
    "    Additional keyword arguments are passed to the :meth:`psislw()` function\n",
    "    (see the corresponding documentation).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    log_lik : ndarray\n",
    "        Array of size n x m containing n posterior samples of the log likelihood\n",
    "        terms :math:`p(y_i|\\theta^s)`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loo : scalar\n",
    "        sum of the leave-one-out log predictive densities\n",
    "\n",
    "    loos : ndarray\n",
    "        individual leave-one-out log predictive density terms\n",
    "\n",
    "    ks : ndarray\n",
    "        estimated Pareto tail indeces\n",
    "\n",
    "    \"\"\"\n",
    "    # ensure overwrite flag in passed arguments\n",
    "    kwargs['overwrite_lw'] = True\n",
    "    # log raw weights from log_lik\n",
    "    lw = -log_lik\n",
    "    # compute Pareto smoothed log weights given raw log weights\n",
    "    lw, ks = psislw(lw, **kwargs)\n",
    "    # compute\n",
    "    lw += log_lik\n",
    "    loos = sumlogs(lw, axis=0)\n",
    "    loo = loos.sum()\n",
    "    return loo, loos, ks\n",
    "\n",
    "\n",
    "def psislw(lw, Reff=1.0, overwrite_lw=False):\n",
    "    \"\"\"Pareto smoothed importance sampling (PSIS).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lw : ndarray\n",
    "        Array of size n x m containing m sets of n log weights. It is also\n",
    "        possible to provide one dimensional array of length n.\n",
    "\n",
    "    Reff : scalar, optional\n",
    "        relative MCMC efficiency ``N_eff / N``\n",
    "\n",
    "    overwrite_lw : bool, optional\n",
    "        If True, the input array `lw` is smoothed in-place, assuming the array\n",
    "        is F-contiguous. By default, a new array is allocated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lw_out : ndarray\n",
    "        smoothed log weights\n",
    "    kss : ndarray\n",
    "        Pareto tail indices\n",
    "\n",
    "    \"\"\"\n",
    "    if lw.ndim == 2:\n",
    "        n, m = lw.shape\n",
    "    elif lw.ndim == 1:\n",
    "        n = len(lw)\n",
    "        m = 1\n",
    "    else:\n",
    "        raise ValueError(\"Argument `lw` must be 1 or 2 dimensional.\")\n",
    "    if n <= 1:\n",
    "        raise ValueError(\"More than one log-weight needed.\")\n",
    "\n",
    "    if overwrite_lw and lw.flags.f_contiguous:\n",
    "        # in-place operation\n",
    "        lw_out = lw\n",
    "    else:\n",
    "        # allocate new array for output\n",
    "        lw_out = np.copy(lw, order='F')\n",
    "\n",
    "    # allocate output array for kss\n",
    "    kss = np.empty(m)\n",
    "\n",
    "    # precalculate constants\n",
    "    cutoff_ind = - int(np.ceil(min(0.2 * n, 3 * np.sqrt(n / Reff)))) - 1\n",
    "    cutoffmin = np.log(np.finfo(float).tiny)\n",
    "    logn = np.log(n)\n",
    "    k_min = 1/3\n",
    "\n",
    "    # loop over sets of log weights\n",
    "    for i, x in enumerate(lw_out.T if lw_out.ndim == 2 else lw_out[None, :]):\n",
    "        # improve numerical accuracy\n",
    "        x -= np.max(x)\n",
    "        # sort the array\n",
    "        x_sort_ind = np.argsort(x)\n",
    "        # divide log weights into body and right tail\n",
    "        xcutoff = max(\n",
    "            x[x_sort_ind[cutoff_ind]],\n",
    "            cutoffmin\n",
    "        )\n",
    "        expxcutoff = np.exp(xcutoff)\n",
    "        tailinds, = np.where(x > xcutoff)\n",
    "        x2 = x[tailinds]\n",
    "        n2 = len(x2)\n",
    "        if n2 <= 4:\n",
    "            # not enough tail samples for gpdfitnew\n",
    "            k = np.inf\n",
    "        else:\n",
    "            # order of tail samples\n",
    "            x2si = np.argsort(x2)\n",
    "            # fit generalized Pareto distribution to the right tail samples\n",
    "            np.exp(x2, out=x2)\n",
    "            x2 -= expxcutoff\n",
    "            k, sigma = gpdfitnew(x2, sort=x2si)\n",
    "        if k >= k_min and not np.isinf(k):\n",
    "            # no smoothing if short tail or GPD fit failed\n",
    "            # compute ordered statistic for the fit\n",
    "            sti = np.arange(0.5, n2)\n",
    "            sti /= n2\n",
    "            qq = gpinv(sti, k, sigma)\n",
    "            qq += expxcutoff\n",
    "            np.log(qq, out=qq)\n",
    "            # place the smoothed tail into the output array\n",
    "            x[tailinds[x2si]] = qq\n",
    "            # truncate smoothed values to the largest raw weight 0\n",
    "            x[x > 0] = 0\n",
    "        # renormalize weights\n",
    "        x -= sumlogs(x)\n",
    "        # store tail index k\n",
    "        kss[i] = k\n",
    "\n",
    "    # If the provided input array is one dimensional, return kss as scalar.\n",
    "    if lw_out.ndim == 1:\n",
    "        kss = kss[0]\n",
    "\n",
    "    return lw_out, kss\n",
    "\n",
    "\n",
    "def gpdfitnew(x, sort=True, sort_in_place=False, return_quadrature=False):\n",
    "    \"\"\"Estimate the paramaters for the Generalized Pareto Distribution (GPD)\n",
    "\n",
    "    Returns empirical Bayes estimate for the parameters of the two-parameter\n",
    "    generalized Parato distribution given the data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        One dimensional data array\n",
    "\n",
    "    sort : bool or ndarray, optional\n",
    "        If known in advance, one can provide an array of indices that would\n",
    "        sort the input array `x`. If the input array is already sorted, provide\n",
    "        False. If True (default behaviour), the array is sorted internally.\n",
    "\n",
    "    sort_in_place : bool, optional\n",
    "        If `sort` is True and `sort_in_place` is True, the array is sorted\n",
    "        in-place (False by default).\n",
    "\n",
    "    return_quadrature : bool, optional\n",
    "        If True, quadrature points and weight `ks` and `w` of the marginal posterior distribution of k are also calculated and returned. False by\n",
    "        default.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    k, sigma : float\n",
    "        estimated parameter values\n",
    "\n",
    "    ks, w : ndarray\n",
    "        Quadrature points and weights of the marginal posterior distribution\n",
    "        of `k`. Returned only if `return_quadrature` is True.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function returns a negative of Zhang and Stephens's k, because it is\n",
    "    more common parameterisation.\n",
    "\n",
    "    \"\"\"\n",
    "    if x.ndim != 1 or len(x) <= 1:\n",
    "        raise ValueError(\"Invalid input array.\")\n",
    "\n",
    "    # check if x should be sorted\n",
    "    if sort is True:\n",
    "        if sort_in_place:\n",
    "            x.sort()\n",
    "            xsorted = True\n",
    "        else:\n",
    "            sort = np.argsort(x)\n",
    "            xsorted = False\n",
    "    elif sort is False:\n",
    "        xsorted = True\n",
    "    else:\n",
    "        xsorted = False\n",
    "\n",
    "    n = len(x)\n",
    "    PRIOR = 3\n",
    "    m = 30 + int(np.sqrt(n))\n",
    "\n",
    "    bs = np.arange(1, m + 1, dtype=float)\n",
    "    bs -= 0.5\n",
    "    np.divide(m, bs, out=bs)\n",
    "    np.sqrt(bs, out=bs)\n",
    "    np.subtract(1, bs, out=bs)\n",
    "    if xsorted:\n",
    "        bs /= PRIOR * x[int(n/4 + 0.5) - 1]\n",
    "        bs += 1 / x[-1]\n",
    "    else:\n",
    "        bs /= PRIOR * x[sort[int(n/4 + 0.5) - 1]]\n",
    "        bs += 1 / x[sort[-1]]\n",
    "\n",
    "    ks = np.negative(bs)\n",
    "    temp = ks[:,None] * x\n",
    "    np.log1p(temp, out=temp)\n",
    "    np.mean(temp, axis=1, out=ks)\n",
    "\n",
    "    L = bs / ks\n",
    "    np.negative(L, out=L)\n",
    "    np.log(L, out=L)\n",
    "    L -= ks\n",
    "    L -= 1\n",
    "    L *= n\n",
    "\n",
    "    temp = L - L[:,None]\n",
    "    np.exp(temp, out=temp)\n",
    "    w = np.sum(temp, axis=1)\n",
    "    np.divide(1, w, out=w)\n",
    "\n",
    "    # remove negligible weights\n",
    "    dii = w >= 10 * np.finfo(float).eps\n",
    "    if not np.all(dii):\n",
    "        w = w[dii]\n",
    "        bs = bs[dii]\n",
    "    # normalise w\n",
    "    w /= w.sum()\n",
    "\n",
    "    # posterior mean for b\n",
    "    b = np.sum(bs * w)\n",
    "    # Estimate for k, note that we return a negative of Zhang and\n",
    "    # Stephens's k, because it is more common parameterisation.\n",
    "    temp = (-b) * x\n",
    "    np.log1p(temp, out=temp)\n",
    "    k = np.mean(temp)\n",
    "    if return_quadrature:\n",
    "        np.negative(x, out=temp)\n",
    "        temp = bs[:, None] * temp\n",
    "        np.log1p(temp, out=temp)\n",
    "        ks = np.mean(temp, axis=1)\n",
    "    # estimate for sigma\n",
    "    sigma = -k / b * n / (n - 0)\n",
    "    # weakly informative prior for k\n",
    "    a = 10\n",
    "    k = k * n / (n+a) + a * 0.5 / (n+a)\n",
    "    if return_quadrature:\n",
    "        ks *= n / (n+a)\n",
    "        ks += a * 0.5 / (n+a)\n",
    "\n",
    "    if return_quadrature:\n",
    "        return k, sigma, ks, w\n",
    "    else:\n",
    "        return k, sigma\n",
    "\n",
    "\n",
    "def gpinv(p, k, sigma):\n",
    "    \"\"\"Inverse Generalised Pareto distribution function.\"\"\"\n",
    "    x = np.empty(p.shape)\n",
    "    x.fill(np.nan)\n",
    "    if sigma <= 0:\n",
    "        return x\n",
    "    ok = (p > 0) & (p < 1)\n",
    "    if np.all(ok):\n",
    "        if np.abs(k) < np.finfo(float).eps:\n",
    "            np.negative(p, out=x)\n",
    "            np.log1p(x, out=x)\n",
    "            np.negative(x, out=x)\n",
    "        else:\n",
    "            np.negative(p, out=x)\n",
    "            np.log1p(x, out=x)\n",
    "            x *= -k\n",
    "            np.expm1(x, out=x)\n",
    "            x /= k\n",
    "        x *= sigma\n",
    "    else:\n",
    "        if np.abs(k) < np.finfo(float).eps:\n",
    "            # x[ok] = - np.log1p(-p[ok])\n",
    "            temp = p[ok]\n",
    "            np.negative(temp, out=temp)\n",
    "            np.log1p(temp, out=temp)\n",
    "            np.negative(temp, out=temp)\n",
    "            x[ok] = temp\n",
    "        else:\n",
    "            # x[ok] = np.expm1(-k * np.log1p(-p[ok])) / k\n",
    "            temp = p[ok]\n",
    "            np.negative(temp, out=temp)\n",
    "            np.log1p(temp, out=temp)\n",
    "            temp *= -k\n",
    "            np.expm1(temp, out=temp)\n",
    "            temp /= k\n",
    "            x[ok] = temp\n",
    "        x *= sigma\n",
    "        x[p == 0] = 0\n",
    "        if k >= 0:\n",
    "            x[p == 1] = np.inf\n",
    "        else:\n",
    "            x[p == 1] = -sigma / k\n",
    "    return x\n",
    "\n",
    "\n",
    "def sumlogs(x, axis=None, out=None):\n",
    "    \"\"\"Sum of vector where numbers are represented by their logarithms.\n",
    "\n",
    "    Calculates ``np.log(np.sum(np.exp(x), axis=axis))`` in such a fashion that\n",
    "    it works even when elements have large magnitude.\n",
    "\n",
    "    \"\"\"\n",
    "    maxx = x.max(axis=axis, keepdims=True)\n",
    "    xnorm = x - maxx\n",
    "    np.exp(xnorm, out=xnorm)\n",
    "    out = np.sum(xnorm, axis=axis, out=out)\n",
    "    if isinstance(out, np.ndarray):\n",
    "        np.log(out, out=out)\n",
    "    else:\n",
    "        out = np.log(out)\n",
    "    out += np.squeeze(maxx)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_num = 62\n",
    "def read_data(n):\n",
    "    #数据文件在的位置\n",
    "    action = []\n",
    "    reward = []\n",
    "    reward_B = []\n",
    "    comparision = [] #r-r_b; 1:>=0, 0:<0\n",
    "    # num = str(220+n)\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    num = str(220+SUB[n])\n",
    "    file = pd.read_csv('E:/multi-bandit/task2v3/RLE2V3_data/' + num + '.csv')\n",
    "    name = 'sub (' +str(n) +').csv'\n",
    "    action_index = 0\n",
    "    for i in  range((file.shape[1])):\n",
    "        if file.columns[i] == 'choose_bandit.keys':\n",
    "            action_index = i\n",
    "    reward_index = 0\n",
    "    for i in  range((file.shape[1])):\n",
    "        if file.columns[i] == 'subchoose':\n",
    "            reward_index = i\n",
    "    for i in range((file.shape[0])):\n",
    "\n",
    "        if (file.iloc[i,0] == 1 or file.iloc[i,0] == 0) and file.iloc[i,action_index]!='None' :\n",
    "            if file.iloc[i,action_index] == 'r':\n",
    "                action.append(0)\n",
    "            elif file.iloc[i,action_index] == 'f':\n",
    "                action.append(1)\n",
    "            elif file.iloc[i,action_index] == 'i':\n",
    "                action.append(2)\n",
    "            elif file.iloc[i,action_index] == 'j':\n",
    "                action.append(3)\n",
    "            else:\n",
    "                print(file.iloc[i,action_index])\n",
    "                print(i)\n",
    "                raise ValueError('不能识别选项')\n",
    "            if int(file.iloc[i,reward_index])>100:\n",
    "                reward.append(100)\n",
    "            elif int(file.iloc[i,reward_index])<0:\n",
    "                reward.append(0)\n",
    "            else:\n",
    "                reward.append(int(file.iloc[i,reward_index]))\n",
    "\n",
    "            if int(file.iloc[i,reward_index+1])>100:\n",
    "                reward_B.append(100)\n",
    "            elif int(file.iloc[i,reward_index+1])<0:\n",
    "                reward_B.append(0)\n",
    "            else:\n",
    "                reward_B.append(int(file.iloc[i,reward_index+1]))\n",
    "            if int(file.iloc[i,reward_index]) >= int(file.iloc[i,reward_index+1]):\n",
    "                comparision.append(int(file.iloc[i,reward_index])-int(file.iloc[i,reward_index+1]))\n",
    "            else:\n",
    "                comparision.append(int(file.iloc[i,reward_index+1])-int(file.iloc[i,reward_index]))\n",
    "        elif (file.iloc[i,0] == 1 or file.iloc[i,0] == 0)  and file.iloc[i,action_index] =='None' :\n",
    "            action.append(4)\n",
    "            reward.append(0)\n",
    "            reward_B.append(0)\n",
    "            comparision.append(0)\n",
    "    return action,reward,reward_B,comparision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parameter_1_para(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    beta = np.array(beta)\n",
    "    return beta\n",
    "\n",
    "def read_parameter_2_para(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    phi = []\n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi.append(parameter_result.iloc[i+subject_num,1])\n",
    "    beta = np.array(beta)\n",
    "    phi = np.array(phi)\n",
    "    return beta,phi\n",
    "\n",
    "def read_parameter_3_para(file_name):\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    para1 = []\n",
    "    para2 = []\n",
    "    para3 = []\n",
    "    for i in range(subject_num):\n",
    "        para1.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        para2.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        para3.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    para1 = np.array(para1)\n",
    "    para2 = np.array(para2)\n",
    "    para3 = np.array(para3)\n",
    "    return para1,para2,para3\n",
    "\n",
    "def read_parameter_4_para(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    phi = []\n",
    "    persev = []\n",
    "    gamma = []\n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    beta = np.array(beta)\n",
    "    phi = np.array(phi)\n",
    "    persev = np.array(persev)\n",
    "    gamma = np.array(gamma)\n",
    "    return beta,phi,persev,gamma\n",
    "\n",
    "def read_parameter_5_para(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "    gamma_a = []\n",
    "    beta_b = []\n",
    "\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "\n",
    "\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "    gamma_a = np.array(gamma_a)\n",
    "    beta_b = np.array(beta_b)\n",
    "\n",
    "\n",
    "    return beta_a,phi_a,persev_a,gamma_a,beta_b\n",
    "\n",
    "def read_parameter_6_para(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "\n",
    "    beta_b = []\n",
    "    phi_b = []\n",
    "    persev_b = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_b.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_b.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "\n",
    "    beta_b = np.array(beta_b)\n",
    "    phi_b = np.array(phi_b)\n",
    "    persev_b = np.array(persev_b)\n",
    "\n",
    "    return beta_a,phi_a,persev_a,beta_b,phi_b,persev_b\n",
    "\n",
    "def read_parameter_7_para(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "    gamma_a = []\n",
    "    beta_b = []\n",
    "    phi_b = []\n",
    "    persev_b = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_b.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_b.append(parameter_result.iloc[i+subject_num*6,1])\n",
    "\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "    gamma_a = np.array(gamma_a)\n",
    "    beta_b = np.array(beta_b)\n",
    "    phi_b = np.array(phi_b)\n",
    "    persev_b = np.array(persev_b)\n",
    "\n",
    "    return beta_a,phi_a,persev_a,gamma_a,beta_b,phi_b,persev_b\n",
    "\n",
    "def read_parameter_8_para(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "    gamma_a = []\n",
    "    beta_b = []\n",
    "    phi_b = []\n",
    "    persev_b = []\n",
    "    gamma_b = []\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_b.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_b.append(parameter_result.iloc[i+subject_num*6,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_b.append(parameter_result.iloc[i+subject_num*7,1])\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "    gamma_a = np.array(gamma_a)\n",
    "    beta_b = np.array(beta_b)\n",
    "    phi_b = np.array(phi_b)\n",
    "    persev_b = np.array(persev_b)\n",
    "    gamma_b = np.array(gamma_b)\n",
    "    return beta_a,phi_a,persev_a,gamma_a,beta_b,phi_b,persev_b,gamma_b\n",
    "\n",
    "def read_parameter_9_para(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a_0 = []\n",
    "    phi_a_0 = []\n",
    "    persev_a_0 = []\n",
    "    gamma_a_0 = []\n",
    "    \n",
    "    beta_a_1 = []\n",
    "    phi_a_1 = []\n",
    "    persev_a_1 = []\n",
    "    gamma_a_1 = []\n",
    "    \n",
    "    beta_b = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a_0.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_0.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_0.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_0.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_a_1.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_1.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_1.append(parameter_result.iloc[i+subject_num*6,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_1.append(parameter_result.iloc[i+subject_num*7,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*8,1])\n",
    "\n",
    "        \n",
    "    beta_a_0 = np.array(beta_a_0)\n",
    "    phi_a_0 = np.array(phi_a_0)\n",
    "    persev_a_0 = np.array(persev_a_0)\n",
    "    gamma_a_0 = np.array(gamma_a_0)\n",
    "    \n",
    "    beta_a_1 = np.array(beta_a_1)\n",
    "    phi_a_1 = np.array(phi_a_1)\n",
    "    persev_a_1 = np.array(persev_a_1)\n",
    "    gamma_a_1 = np.array(gamma_a_1)\n",
    "    \n",
    "    beta_b = np.array(beta_b)\n",
    "\n",
    "    return beta_a_0,phi_a_0,persev_a_0,gamma_a_0,beta_a_1,phi_a_1,persev_a_1,gamma_a_1,beta_b\n",
    "\n",
    "def read_parameter_12_para(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a_0 = []\n",
    "    phi_a_0 = []\n",
    "    persev_a_0 = []\n",
    "    gamma_a_0 = []\n",
    "    \n",
    "    beta_a_1 = []\n",
    "    phi_a_1 = []\n",
    "    persev_a_1 = []\n",
    "    gamma_a_1 = []\n",
    "    \n",
    "    beta_b = []\n",
    "    phi_b = []\n",
    "    persev_b = []\n",
    "    gamma_b = []\n",
    "    for i in range(subject_num):\n",
    "        beta_a_0.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_0.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_0.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_0.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_a_1.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_1.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_1.append(parameter_result.iloc[i+subject_num*6,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_1.append(parameter_result.iloc[i+subject_num*7,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*8,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_b.append(parameter_result.iloc[i+subject_num*9,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_b.append(parameter_result.iloc[i+subject_num*10,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_b.append(parameter_result.iloc[i+subject_num*11,1])\n",
    "        \n",
    "    beta_a_0 = np.array(beta_a_0)\n",
    "    phi_a_0 = np.array(phi_a_0)\n",
    "    persev_a_0 = np.array(persev_a_0)\n",
    "    gamma_a_0 = np.array(gamma_a_0)\n",
    "    \n",
    "    beta_a_1 = np.array(beta_a_1)\n",
    "    phi_a_1 = np.array(phi_a_1)\n",
    "    persev_a_1 = np.array(persev_a_1)\n",
    "    gamma_a_1 = np.array(gamma_a_1)\n",
    "    \n",
    "    beta_b = np.array(beta_b)\n",
    "    phi_b = np.array(phi_b)\n",
    "    persev_b = np.array(persev_b)\n",
    "    gamma_b = np.array(gamma_b)\n",
    "    return beta_a_0,phi_a_0,persev_a_0,gamma_a_0,beta_a_1,phi_a_1,persev_a_1,gamma_a_1,beta_b,phi_b,persev_b,gamma_b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parameter_1_para_sample(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    beta_sd = []\n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_sd.append(parameter_result.iloc[i,3])\n",
    "    beta = np.array(beta)\n",
    "    beta_sd = np.array(beta_sd)\n",
    "    return beta,beta_sd\n",
    "\n",
    "def read_parameter_2_para_sample(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    phi = []\n",
    "    \n",
    "    beta_sd = []\n",
    "    phi_sd = []\n",
    "    \n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi.append(parameter_result.iloc[i+subject_num,1])\n",
    "        \n",
    "    for i in range(subject_num):\n",
    "        beta_sd.append(parameter_result.iloc[i,3])\n",
    "    for i in range(subject_num):\n",
    "        phi_sd.append(parameter_result.iloc[i+subject_num,3])\n",
    "        \n",
    "    beta = np.array(beta)\n",
    "    phi = np.array(phi)\n",
    "    \n",
    "    beta_sd = np.array(beta_sd)\n",
    "    phi_sd = np.array(phi_sd)\n",
    "    \n",
    "    return beta,phi,beta_sd,phi_sd\n",
    "\n",
    "def read_parameter_3_para_sample(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    phi = []\n",
    "    persev = []\n",
    "    \n",
    "    beta_sd = []\n",
    "    phi_sd = []\n",
    "    persev_sd = []\n",
    "    \n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "        \n",
    "    for i in range(subject_num):\n",
    "        beta_sd.append(parameter_result.iloc[i,3])\n",
    "    for i in range(subject_num):\n",
    "        phi_sd.append(parameter_result.iloc[i+subject_num,3])\n",
    "    for i in range(subject_num):\n",
    "        persev_sd.append(parameter_result.iloc[i+subject_num*2,3])\n",
    "        \n",
    "    beta_sd = np.array(beta_sd)\n",
    "    phi_sd = np.array(phi_sd)\n",
    "    persev_sd = np.array(persev_sd)\n",
    "    \n",
    "    beta = np.array(beta)\n",
    "    phi = np.array(phi)\n",
    "    persev = np.array(persev)\n",
    "    \n",
    "    return beta,phi,persev,beta_sd,phi_sd,persev_sd\n",
    "\n",
    "def read_parameter_4_para_sample(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    phi = []\n",
    "    persev = []\n",
    "    gamma = []\n",
    "    \n",
    "    beta_sd = []\n",
    "    phi_sd = []\n",
    "    persev_sd = []\n",
    "    gamma_sd = []\n",
    "    \n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "        \n",
    "    for i in range(subject_num):\n",
    "        beta_sd.append(parameter_result.iloc[i,3])\n",
    "    for i in range(subject_num):\n",
    "        phi_sd.append(parameter_result.iloc[i+subject_num,3])\n",
    "    for i in range(subject_num):\n",
    "        persev_sd.append(parameter_result.iloc[i+subject_num*2,3])\n",
    "    for i in range(subject_num):\n",
    "        gamma_sd.append(parameter_result.iloc[i+subject_num*3,3])\n",
    "    \n",
    "    beta = np.array(beta)\n",
    "    phi = np.array(phi)\n",
    "    persev = np.array(persev)\n",
    "    gamma = np.array(gamma)\n",
    "    \n",
    "    beta_sd = np.array(beta_sd)\n",
    "    phi_sd = np.array(phi_sd)\n",
    "    persev_sd = np.array(persev_sd)\n",
    "    gamma_sd = np.array(gamma_sd)\n",
    "    \n",
    "    return beta,phi,persev,gamma,beta_sd,phi_sd,persev_sd,gamma_sd\n",
    "\n",
    "def read_parameter_5_para_sample(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "    gamma_a = []\n",
    "    beta_b = []\n",
    "    \n",
    "    beta_a_sd = []\n",
    "    phi_a_sd = []\n",
    "    persev_a_sd = []\n",
    "    gamma_a_sd = []\n",
    "    beta_b_sd = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "        \n",
    "    for i in range(subject_num):\n",
    "        beta_a_sd.append(parameter_result.iloc[i,3])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_sd.append(parameter_result.iloc[i+subject_num,3])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_sd.append(parameter_result.iloc[i+subject_num*2,3])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_sd.append(parameter_result.iloc[i+subject_num*3,3])\n",
    "    for i in range(subject_num):\n",
    "        beta_b_sd.append(parameter_result.iloc[i+subject_num*4,3])\n",
    "\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "    gamma_a = np.array(gamma_a)\n",
    "    beta_b = np.array(beta_b)\n",
    "    \n",
    "    beta_a_sd = np.array(beta_a_sd)\n",
    "    phi_a_sd = np.array(phi_a_sd)\n",
    "    persev_a_sd = np.array(persev_a_sd)\n",
    "    gamma_a_sd = np.array(gamma_a_sd)\n",
    "    beta_b_sd = np.array(beta_b_sd)\n",
    "\n",
    "    return beta_a,phi_a,persev_a,gamma_a,beta_b,beta_a_sd,phi_a_sd,persev_a_sd,gamma_a_sd,beta_b_sd\n",
    "\n",
    "def read_parameter_6_para_sample(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "\n",
    "    beta_b = []\n",
    "    phi_b = []\n",
    "    persev_b = []\n",
    "    \n",
    "    beta_a_sd = []\n",
    "    phi_a_sd = []\n",
    "    persev_a_sd = []\n",
    "\n",
    "    beta_b_sd = []\n",
    "    phi_b_sd = []\n",
    "    persev_b_sd = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_b.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_b.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "        \n",
    "    for i in range(subject_num):\n",
    "        beta_a_sd.append(parameter_result.iloc[i,3])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_sd.append(parameter_result.iloc[i+subject_num,3])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_sd.append(parameter_result.iloc[i+subject_num*2,3])\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_b_sd.append(parameter_result.iloc[i+subject_num*3,3])\n",
    "    for i in range(subject_num):\n",
    "        phi_b_sd.append(parameter_result.iloc[i+subject_num*4,3])\n",
    "    for i in range(subject_num):\n",
    "        persev_b_sd.append(parameter_result.iloc[i+subject_num*5,3])\n",
    "\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "\n",
    "    beta_b = np.array(beta_b)\n",
    "    phi_b = np.array(phi_b)\n",
    "    persev_b = np.array(persev_b)\n",
    "    \n",
    "    beta_a_sd = np.array(beta_a_sd)\n",
    "    phi_a_sd = np.array(phi_a_sd)\n",
    "    persev_a_sd = np.array(persev_a_sd)\n",
    "\n",
    "    beta_b_sd = np.array(beta_b_sd)\n",
    "    phi_b_sd = np.array(phi_b_sd)\n",
    "    persev_b_sd = np.array(persev_b_sd)\n",
    "\n",
    "    return beta_a,phi_a,persev_a,beta_b,phi_b,persev_b,beta_a_sd,phi_a_sd,persev_a_sd,beta_b_sd,phi_b_sd,persev_b_sd\n",
    "\n",
    "def read_parameter_7_para_sample(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "    gamma_a = []\n",
    "    beta_b = []\n",
    "    phi_b = []\n",
    "    persev_b = []\n",
    "    \n",
    "    beta_a_sd = []\n",
    "    phi_a_sd = []\n",
    "    persev_a_sd = []\n",
    "    gamma_a_sd = []\n",
    "    beta_b_sd = []\n",
    "    phi_b_sd = []\n",
    "    persev_b_sd = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_b.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_b.append(parameter_result.iloc[i+subject_num*6,1])\n",
    "        \n",
    "    for i in range(subject_num):\n",
    "        beta_a_sd.append(parameter_result.iloc[i,3])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_sd.append(parameter_result.iloc[i+subject_num,3])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_sd.append(parameter_result.iloc[i+subject_num*2,3])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_sd.append(parameter_result.iloc[i+subject_num*3,3])\n",
    "    for i in range(subject_num):\n",
    "        beta_b_sd.append(parameter_result.iloc[i+subject_num*4,3])\n",
    "    for i in range(subject_num):\n",
    "        phi_b_sd.append(parameter_result.iloc[i+subject_num*5,3])\n",
    "    for i in range(subject_num):\n",
    "        persev_b_sd.append(parameter_result.iloc[i+subject_num*6,3])\n",
    "\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "    gamma_a = np.array(gamma_a)\n",
    "    beta_b = np.array(beta_b)\n",
    "    phi_b = np.array(phi_b)\n",
    "    persev_b = np.array(persev_b)\n",
    "    \n",
    "    beta_a_sd = np.array(beta_a_sd)\n",
    "    phi_a_sd = np.array(phi_a_sd)\n",
    "    persev_a_sd = np.array(persev_a_sd)\n",
    "    gamma_a_sd = np.array(gamma_a_sd)\n",
    "    beta_b_sd = np.array(beta_b_sd)\n",
    "    phi_b_sd = np.array(phi_b_sd)\n",
    "    persev_b_sd = np.array(persev_b_sd)\n",
    "\n",
    "    return beta_a,phi_a,persev_a,gamma_a,beta_b,phi_b,persev_b,beta_a_sd,phi_a_sd,persev_a_sd,gamma_a_sd,beta_b_sd,phi_b_sd,persev_b_sd\n",
    "\n",
    "def read_parameter_9_para_sample(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a_0 = []\n",
    "    phi_a_0 = []\n",
    "    persev_a_0 = []\n",
    "    gamma_a_0 = []\n",
    "    beta_a_1 = []\n",
    "    phi_a_1 = []\n",
    "    persev_a_1 = []\n",
    "    gamma_a_1 = []\n",
    "    beta_b = []\n",
    "    \n",
    "    beta_a_0_sd = []\n",
    "    phi_a_0_sd = []\n",
    "    persev_a_0_sd = []\n",
    "    gamma_a_0_sd = []\n",
    "    beta_a_1_sd = []\n",
    "    phi_a_1_sd = []\n",
    "    persev_a_1_sd = []\n",
    "    gamma_a_1_sd = []\n",
    "    beta_b_sd = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a_0.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_0.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_0.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_0.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_a_1.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_1.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_1.append(parameter_result.iloc[i+subject_num*6,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_1.append(parameter_result.iloc[i+subject_num*7,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*8,1])\n",
    "        \n",
    "    for i in range(subject_num):\n",
    "        beta_a_0_sd.append(parameter_result.iloc[i,3])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_0_sd.append(parameter_result.iloc[i+subject_num,3])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_0_sd.append(parameter_result.iloc[i+subject_num*2,3])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_0_sd.append(parameter_result.iloc[i+subject_num*3,3])\n",
    "    for i in range(subject_num):\n",
    "        beta_a_1_sd.append(parameter_result.iloc[i+subject_num*4,3])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_1_sd.append(parameter_result.iloc[i+subject_num*5,3])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_1_sd.append(parameter_result.iloc[i+subject_num*6,3])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_1_sd.append(parameter_result.iloc[i+subject_num*7,3])\n",
    "    for i in range(subject_num):\n",
    "        beta_b_sd.append(parameter_result.iloc[i+subject_num*8,3])\n",
    "\n",
    "        \n",
    "    beta_a_0 = np.array(beta_a_0)\n",
    "    phi_a_0 = np.array(phi_a_0)\n",
    "    persev_a_0 = np.array(persev_a_0)\n",
    "    gamma_a_0 = np.array(gamma_a_0)\n",
    "    beta_a_1 = np.array(beta_a_1)\n",
    "    phi_a_1 = np.array(phi_a_1)\n",
    "    persev_a_1 = np.array(persev_a_1)\n",
    "    gamma_a_1 = np.array(gamma_a_1)\n",
    "    beta_b = np.array(beta_b)\n",
    "    \n",
    "    beta_a_0_sd = np.array(beta_a_0_sd)\n",
    "    phi_a_0_sd = np.array(phi_a_0_sd)\n",
    "    persev_a_0_sd = np.array(persev_a_0_sd)\n",
    "    gamma_a_0_sd = np.array(gamma_a_0_sd)\n",
    "    beta_a_1_sd = np.array(beta_a_1_sd)\n",
    "    phi_a_1_sd = np.array(phi_a_1_sd)\n",
    "    persev_a_1_sd = np.array(persev_a_1_sd)\n",
    "    gamma_a_1_sd = np.array(gamma_a_1_sd)\n",
    "    beta_b_sd = np.array(beta_b_sd)\n",
    "\n",
    "    return beta_a_0,phi_a_0,persev_a_0,gamma_a_0,beta_a_1,phi_a_1,persev_a_1,gamma_a_1,beta_b,beta_a_0_sd,phi_a_0_sd,persev_a_0_sd,gamma_a_0_sd,beta_a_1_sd,phi_a_1_sd,persev_a_1_sd,gamma_a_1_sd,beta_b_sd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_probability(Q,action):\n",
    "    return np.log(np.exp(Q[action])/(np.exp(Q[0])+np.exp(Q[1])+np.exp(Q[2])+np.exp(Q[3])))\n",
    "\n",
    "def rewards2comparison_sqrt(action,reward,reward_B,gamma):\n",
    "    comparison = []\n",
    "    com = 0\n",
    "    for i in range(len(action)):\n",
    "        if action[i]!=4:\n",
    "            if com<0:\n",
    "                comparison.append(-np.sqrt(-com))\n",
    "            else:\n",
    "                comparison.append(np.sqrt(com))\n",
    "            com = reward[i] - reward_B[i] + gamma*com\n",
    "        else:\n",
    "            comparison.append(0)\n",
    "            com = gamma*com\n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def llh_vep(file_name):#nhb\n",
    "    beta_b,phi_b,persev_b = read_parameter_3_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = phi_b[s] * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev_b[s]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta_b[s]*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_ve(file_name):#nhb\n",
    "    beta_b,phi_b = read_parameter_2_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = phi_b[s] * re_sig\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta_b[s]*v+eb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_vp(file_name):#nhb\n",
    "    beta_b,persev_b = read_parameter_2_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev_b[s]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta_b[s]*v+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_v(file_name):#nhb\n",
    "    beta_b = read_parameter_1_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta_b[s]*v),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "\n",
    "def llh_glm_vep(file_name):\n",
    "    beta_a,phi_a,persev_a,beta_b,phi_b,persev_b = read_parameter_6_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                beta_t = beta_a[s]*comparision[t]+beta_b[s]\n",
    "                if beta_t < 0:\n",
    "                    beta_t = 0\n",
    "                loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm_ve(file_name):\n",
    "    beta_a,phi_a,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_b[s])\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                beta_t = beta_a[s]*comparision[t]+beta_b[s]\n",
    "                if beta_t < 0:\n",
    "                    beta_t = 0\n",
    "                loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm_vp(file_name):\n",
    "    beta_a,persev_a,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi_b[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                beta_t = beta_a[s]*comparision[t]+beta_b[s]\n",
    "                if beta_t < 0:\n",
    "                    beta_t = 0\n",
    "                loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm_ep(file_name):\n",
    "    phi_a,persev_a,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                beta_t = beta_b[s]\n",
    "                if beta_t < 0:\n",
    "                    beta_t = 0\n",
    "                loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm_v(file_name):#nhb\n",
    "    beta_a,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = phi_b[s] * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev_b[s]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                beta_t = beta_a[s]*comparision[t]+beta_b[s]\n",
    "                if beta_t < 0:\n",
    "                    beta_t = 0\n",
    "                loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm_e(file_name):#nhb\n",
    "    phi_a,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev_b[s]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta_b[s]*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm_p(file_name):#nhb\n",
    "    persev_a,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = phi_b[s] * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta_b[s]*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_s(file_name):#nhb\n",
    "    comparison_level,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = phi_b[s] * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                compare = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_b[s])\n",
    "                        compare[action[t-1]] = comparision[t]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta_b[s]*(v+comparison_level[s]*compare)+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm_v10(file_name):\n",
    "    beta_a,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = phi_b[s] * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev_b[s]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                beta_t = beta_a[s]*comparision[t]+beta_b[s]\n",
    "                if beta_t < 0:\n",
    "                    beta_t = 0\n",
    "                loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm_e10(file_name):\n",
    "    phi_a,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev_b[s]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta_b[s]*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm_p10(file_name):\n",
    "    persev_a,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.min(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = phi_b[s] * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta_b[s]*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "\n",
    "\n",
    "def llh_glm2_vep(file_name):\n",
    "    beta_a_1,phi_a_1,persev_a_1,beta_a_0,phi_a_0,persev_a_0,beta_b,phi_b,persev_b = read_parameter_9_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_0[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                else:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_ep(file_name):\n",
    "    phi_a_1,persev_a_1,phi_a_0,persev_a_0,beta_b,phi_b,persev_b = read_parameter_7_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                else:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_v(file_name):\n",
    "    beta_a_1,beta_a_0,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_0[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                elif comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_e(file_name):\n",
    "    phi_a_1,phi_a_0,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "                elif comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_p(file_name):\n",
    "    persev_a_1,persev_a_0,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "                elif comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "\n",
    "def llh_glm2_v1e1p1(file_name):\n",
    "    beta_a_1,phi_a_1,persev_a_1,beta_b,phi_b,persev_b = read_parameter_6_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_v0e0p0(file_name):\n",
    "    beta_a_0,phi_a_0,persev_a_0,beta_b,phi_b,persev_b = read_parameter_6_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_0[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_v1e1p0(file_name):\n",
    "    beta_a_1,phi_a_1,persev_a_0,beta_b,phi_b,persev_b = read_parameter_6_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "\n",
    "def llh_glm2_v1e1(file_name):\n",
    "    beta_a_1,phi_a_1,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_v1p1(file_name):\n",
    "    beta_a_1,persev_a_1,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_e1p1(file_name):\n",
    "    phi_a_1,persev_a_1,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_v0e0(file_name):\n",
    "    beta_a_0,phi_a_0,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_0[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_v0p0(file_name):\n",
    "    beta_a_0,persev_a_0,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_0[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_e0p0(file_name):\n",
    "    phi_a_0,persev_a_0,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "\n",
    "def llh_glm2_v1(file_name):\n",
    "    beta_a_1,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_v0(file_name):\n",
    "    beta_a_0,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a_0[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_e1(file_name):\n",
    "    phi_a_1,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_e0(file_name):\n",
    "    phi_a_0,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_p1(file_name):\n",
    "    persev_a_1,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_p0(file_name):\n",
    "    persev_a_0,beta_b,phi_b,persev_b = read_parameter_4_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def llh_glm2_e1p(file_name):\n",
    "    phi_a_1,persev_a,beta_b,phi_b,persev_b = read_parameter_5_para(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(s) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t < 0:\n",
    "                        beta_t = 0\n",
    "                    loglikelyhood += action_probability((beta_t*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loo_vep(file_name):#nhb\n",
    "    beta_b_mean,phi_b_mean,persev_b_mean,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_3_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "    \n",
    "        for s in range(sample_num):\n",
    "\n",
    "            sample_loglikelyhood = []\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = phi_b[s] * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = persev_b[s]\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    sample_loglikelyhood.append(action_probability((beta_b[s]*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_ve(file_name):#nhb\n",
    "    beta_b_mean,phi_b_mean,beta_b_sd,phi_b_sd = read_parameter_2_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "    \n",
    "        for s in range(sample_num):\n",
    "\n",
    "            sample_loglikelyhood = []\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = phi_b[s] * re_sig\n",
    "\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    sample_loglikelyhood.append(action_probability((beta_b[s]*v+eb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_vp(file_name):#nhb\n",
    "    beta_b_mean,persev_b_mean,beta_b_sd,persev_b_sd = read_parameter_2_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "    \n",
    "        for s in range(sample_num):\n",
    "\n",
    "            sample_loglikelyhood = []\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = persev_b[s]\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    sample_loglikelyhood.append(action_probability((beta_b[s]*v+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_v(file_name):#nhb\n",
    "    beta_b_mean,beta_b_sd = read_parameter_1_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "    \n",
    "        for s in range(sample_num):\n",
    "\n",
    "            sample_loglikelyhood = []\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    sample_loglikelyhood.append(action_probability((beta_b[s]*v),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "\n",
    "\n",
    "def loo_glm_vep(file_name):\n",
    "    beta_a_mean,phi_a_mean,persev_a_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_sd,phi_a_sd,persev_a_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_6_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_a = np.random.normal(beta_a_mean[i], beta_a_sd[i], size=sample_num)\n",
    "        phi_a = np.random.normal(phi_a_mean[i], phi_a_sd[i], size=sample_num)\n",
    "        persev_a = np.random.normal(persev_a_mean[i], persev_a_sd[i], size=sample_num)\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t<0:\n",
    "                        beta_t = 0\n",
    "                    sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm_ve(file_name):\n",
    "    beta_a_mean,phi_a_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_sd,phi_a_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_a = np.random.normal(beta_a_mean[i], beta_a_sd[i], size=sample_num)\n",
    "        phi_a = np.random.normal(phi_a_mean[i], phi_a_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t<0:\n",
    "                        beta_t = 0\n",
    "                    sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm_vp(file_name):\n",
    "    beta_a_mean,persev_a_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_sd,persev_a_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_a = np.random.normal(beta_a_mean[i], beta_a_sd[i], size=sample_num)\n",
    "        persev_a = np.random.normal(persev_a_mean[i], persev_a_sd[i], size=sample_num)\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t<0:\n",
    "                        beta_t = 0\n",
    "                    sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm_ep(file_name):\n",
    "    phi_a_mean,persev_a_mean,beta_b_mean,phi_b_mean,persev_b_mean,phi_a_sd,persev_a_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    for i in range(subjects):\n",
    "\n",
    "        phi_a = np.random.normal(phi_a_mean[i], phi_a_sd[i], size=sample_num)\n",
    "        persev_a = np.random.normal(persev_a_mean[i], persev_a_sd[i], size=sample_num)\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_b[s]\n",
    "                    if beta_t<0:\n",
    "                        beta_t = 0\n",
    "                    sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm_v(file_name):#nhb\n",
    "    beta_a_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_4_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_a = np.random.normal(beta_a_mean[i], beta_a_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "    \n",
    "        for s in range(sample_num):\n",
    "\n",
    "            sample_loglikelyhood = []\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = phi_b[s] * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = persev_b[s]\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    beta_t = beta_a[s]*comparision[t]+beta_b[s]\n",
    "                    if beta_t<0:\n",
    "                        beta_t = 0\n",
    "                    sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm_e(file_name):#nhb\n",
    "    phi_a_mean,beta_b_mean,phi_b_mean,persev_b_mean,phi_a_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_4_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    for i in range(subjects):\n",
    "        phi_a = np.random.normal(phi_a_mean[i], phi_a_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "    \n",
    "        for s in range(sample_num):\n",
    "\n",
    "            sample_loglikelyhood = []\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = persev_b[s]\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    sample_loglikelyhood.append(action_probability((beta_b[s]*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm_p(file_name):#nhb\n",
    "    persev_a_mean,beta_b_mean,phi_b_mean,persev_b_mean,persev_a_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_4_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    for i in range(subjects):\n",
    "        persev_a = np.random.normal(persev_a_mean[i], persev_a_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "    \n",
    "        for s in range(sample_num):\n",
    "\n",
    "            sample_loglikelyhood = []\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = phi_b[s] * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = persev_a[s]*comparision[t]+persev_b[s]\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    sample_loglikelyhood.append(action_probability((beta_b[s]*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_s(file_name):#nhb\n",
    "    comparison_level_mean,beta_b_mean,phi_b_mean,persev_b_mean,comparison_level_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_4_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    for i in range(subjects):\n",
    "        comparison_level = np.random.normal(comparison_level_mean[i], comparison_level_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "    \n",
    "        for s in range(sample_num):\n",
    "\n",
    "            sample_loglikelyhood = []\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.min(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = phi_b[s] * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    compare = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = persev_b[s]\n",
    "                            compare[action[t-1]] = comparision[t]\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    sample_loglikelyhood.append(action_probability((beta_b[s]*(v+comparison_level[s]*compare)+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "\n",
    "def loo_glm2_vep(file_name):\n",
    "    beta_a_1_mean,phi_a_1_mean,persev_a_1_mean,beta_a_0_mean,phi_a_0_mean,persev_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_1_sd,phi_a_1_sd,persev_a_1_sd,beta_a_0_sd,phi_a_0_sd,persev_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_9_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_a_0 = np.random.normal(beta_a_0_mean[i], beta_a_0_sd[i], size=sample_num)\n",
    "        phi_a_0 = np.random.normal(phi_a_0_mean[i], phi_a_0_sd[i], size=sample_num)\n",
    "        persev_a_0 = np.random.normal(persev_a_0_mean[i], persev_a_0_sd[i], size=sample_num)\n",
    "        beta_a_1 = np.random.normal(beta_a_1_mean[i], beta_a_1_sd[i], size=sample_num)\n",
    "        phi_a_1 = np.random.normal(phi_a_1_mean[i], phi_a_1_sd[i], size=sample_num)\n",
    "        persev_a_1 = np.random.normal(persev_a_1_mean[i], persev_a_1_sd[i], size=sample_num)\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                    \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_0[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_ep(file_name):\n",
    "    phi_a_1_mean,persev_a_1_mean,phi_a_0_mean,persev_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,phi_a_1_sd,persev_a_1_sd,phi_a_0_sd,persev_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_7_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "\n",
    "        phi_a_0 = np.random.normal(phi_a_0_mean[i], phi_a_0_sd[i], size=sample_num)\n",
    "        persev_a_0 = np.random.normal(persev_a_0_mean[i], persev_a_0_sd[i], size=sample_num)\n",
    "\n",
    "        phi_a_1 = np.random.normal(phi_a_1_mean[i], phi_a_1_sd[i], size=sample_num)\n",
    "        persev_a_1 = np.random.normal(persev_a_1_mean[i], persev_a_1_sd[i], size=sample_num)\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                    \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_v10(file_name):\n",
    "    beta_a_1_mean,beta_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_1_sd,beta_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_a_0 = np.random.normal(beta_a_0_mean[i], beta_a_0_sd[i], size=sample_num)\n",
    "\n",
    "        beta_a_1 = np.random.normal(beta_a_1_mean[i], beta_a_1_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_0[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_e10(file_name):\n",
    "    phi_a_1_mean,phi_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,phi_a_1_sd,phi_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "        phi_a_0 = np.random.normal(phi_a_0_mean[i], phi_a_0_sd[i], size=sample_num)\n",
    "\n",
    "        phi_a_1 = np.random.normal(phi_a_1_mean[i], phi_a_1_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                        \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        sample_loglikelyhood.append(action_probability(((beta_b[s])*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        sample_loglikelyhood.append(action_probability(((beta_b[s])*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_p10(file_name):\n",
    "    persev_a_1_mean,persev_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,persev_a_1_sd,persev_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "        persev_a_0 = np.random.normal(persev_a_0_mean[i], persev_a_0_sd[i], size=sample_num)\n",
    "\n",
    "        persev_a_1 = np.random.normal(persev_a_1_mean[i], persev_a_1_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                        \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        sample_loglikelyhood.append(action_probability(((beta_b[s])*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        sample_loglikelyhood.append(action_probability(((beta_b[s])*v+eb+pb),action[t]))\n",
    "                \n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "\n",
    "def loo_glm2_v1e1p1(file_name):\n",
    "    beta_a_1_mean,phi_a_1_mean,persev_a_1_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_1_sd,phi_a_1_sd,persev_a_1_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_6_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "\n",
    "        beta_a_1 = np.random.normal(beta_a_1_mean[i], beta_a_1_sd[i], size=sample_num)\n",
    "        phi_a_1 = np.random.normal(phi_a_1_mean[i], phi_a_1_sd[i], size=sample_num)\n",
    "        persev_a_1 = np.random.normal(persev_a_1_mean[i], persev_a_1_sd[i], size=sample_num)\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                    \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_v0e0p0(file_name):\n",
    "    beta_a_0_mean,phi_a_0_mean,persev_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_0_sd,phi_a_0_sd,persev_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_6_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_a_0 = np.random.normal(beta_a_0_mean[i], beta_a_0_sd[i], size=sample_num)\n",
    "        phi_a_0 = np.random.normal(phi_a_0_mean[i], phi_a_0_sd[i], size=sample_num)\n",
    "        persev_a_0 = np.random.normal(persev_a_0_mean[i], persev_a_0_sd[i], size=sample_num)\n",
    "      \n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                    \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_0[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_v1e1p0(file_name):\n",
    "    beta_a_1_mean,phi_a_1_mean,persev_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_1_sd,phi_a_1_sd,persev_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_6_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "\n",
    "        persev_a_0 = np.random.normal(persev_a_0_mean[i], persev_a_0_sd[i], size=sample_num)\n",
    "        beta_a_1 = np.random.normal(beta_a_1_mean[i], beta_a_1_sd[i], size=sample_num)\n",
    "        phi_a_1 = np.random.normal(phi_a_1_mean[i], phi_a_1_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                    \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "\n",
    "def loo_glm2_v1e1(file_name):\n",
    "    beta_a_1_mean,phi_a_1_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_1_sd,phi_a_1_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "\n",
    "        beta_a_1 = np.random.normal(beta_a_1_mean[i], beta_a_1_sd[i], size=sample_num)\n",
    "        phi_a_1 = np.random.normal(phi_a_1_mean[i], phi_a_1_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                    \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_v1p1(file_name):\n",
    "    beta_a_1_mean,persev_a_1_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_1_sd,persev_a_1_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "\n",
    "        beta_a_1 = np.random.normal(beta_a_1_mean[i], beta_a_1_sd[i], size=sample_num)\n",
    "\n",
    "        persev_a_1 = np.random.normal(persev_a_1_mean[i], persev_a_1_sd[i], size=sample_num)\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                    \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_e1p1(file_name):\n",
    "    phi_a_1_mean,persev_a_1_mean,beta_b_mean,phi_b_mean,persev_b_mean,phi_a_1_sd,persev_a_1_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "\n",
    "        phi_a_1 = np.random.normal(phi_a_1_mean[i], phi_a_1_sd[i], size=sample_num)\n",
    "        persev_a_1 = np.random.normal(persev_a_1_mean[i], persev_a_1_sd[i], size=sample_num)\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                    \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_v0e0(file_name):\n",
    "    beta_a_0_mean,phi_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_0_sd,phi_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_a_0 = np.random.normal(beta_a_0_mean[i], beta_a_0_sd[i], size=sample_num)\n",
    "        phi_a_0 = np.random.normal(phi_a_0_mean[i], phi_a_0_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                    \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_0[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_v0p0(file_name):\n",
    "    beta_a_0_mean,persev_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_0_sd,persev_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_a_0 = np.random.normal(beta_a_0_mean[i], beta_a_0_sd[i], size=sample_num)\n",
    "\n",
    "        persev_a_0 = np.random.normal(persev_a_0_mean[i], persev_a_0_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                    \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_0[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_e0p0(file_name):\n",
    "    phi_a_0_mean,persev_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,phi_a_0_sd,persev_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "\n",
    "        phi_a_0 = np.random.normal(phi_a_0_mean[i], phi_a_0_sd[i], size=sample_num)\n",
    "        persev_a_0 = np.random.normal(persev_a_0_mean[i], persev_a_0_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                    \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "\n",
    "def loo_glm2_v1(file_name):\n",
    "    beta_a_1_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_1_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_4_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "\n",
    "\n",
    "        beta_a_1 = np.random.normal(beta_a_1_mean[i], beta_a_1_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_1[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_v0(file_name):\n",
    "    beta_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,beta_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_4_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "        beta_a_0 = np.random.normal(beta_a_0_mean[i], beta_a_0_sd[i], size=sample_num)\n",
    "\n",
    "\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_a_0[s]*comparision[t]+beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_e1(file_name):\n",
    "    phi_a_1_mean,beta_b_mean,phi_b_mean,persev_b_mean,phi_a_1_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_4_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "\n",
    "\n",
    "        phi_a_1 = np.random.normal(phi_a_1_mean[i], phi_a_1_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                        \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        sample_loglikelyhood.append(action_probability(((beta_b[s])*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        sample_loglikelyhood.append(action_probability(((beta_b[s])*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_e0(file_name):\n",
    "    phi_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,phi_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_4_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "        phi_a_0 = np.random.normal(phi_a_0_mean[i], phi_a_0_sd[i], size=sample_num)\n",
    "\n",
    "\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                        \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        sample_loglikelyhood.append(action_probability(((beta_b[s])*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        sample_loglikelyhood.append(action_probability(((beta_b[s])*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_p1(file_name):\n",
    "    persev_a_1_mean,beta_b_mean,phi_b_mean,persev_b_mean,persev_a_1_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_4_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "\n",
    "\n",
    "        persev_a_1 = np.random.normal(persev_a_1_mean[i], persev_a_1_sd[i], size=sample_num)\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                        \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        sample_loglikelyhood.append(action_probability(((beta_b[s])*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        sample_loglikelyhood.append(action_probability(((beta_b[s])*v+eb+pb),action[t]))\n",
    "                \n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_p0(file_name):\n",
    "    persev_a_0_mean,beta_b_mean,phi_b_mean,persev_b_mean,persev_a_0_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_4_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "        persev_a_0 = np.random.normal(persev_a_0_mean[i], persev_a_0_sd[i], size=sample_num)\n",
    "\n",
    "\n",
    "\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                        \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        sample_loglikelyhood.append(action_probability(((beta_b[s])*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        sample_loglikelyhood.append(action_probability(((beta_b[s])*v+eb+pb),action[t]))\n",
    "                \n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n",
    "def loo_glm2_e1p(file_name):\n",
    "    phi_a_1_mean,persev_a_mean,beta_b_mean,phi_b_mean,persev_b_mean,phi_a_1_sd,persev_a_sd,beta_b_sd,phi_b_sd,persev_b_sd = read_parameter_5_para_sample(file_name)\n",
    "    subjects = 62\n",
    "    trials = 150\n",
    "    subject_loo = []\n",
    "    sample_num = 2000\n",
    "    \n",
    "    \n",
    "    for i in range(subjects):\n",
    "\n",
    "        phi_a_1 = np.random.normal(phi_a_1_mean[i], phi_a_1_sd[i], size=sample_num)\n",
    "        persev_a = np.random.normal(persev_a_mean[i], persev_a_sd[i], size=sample_num)\n",
    "        beta_b = np.random.normal(beta_b_mean[i], beta_b_sd[i], size=sample_num)\n",
    "        phi_b = np.random.normal(phi_b_mean[i], phi_b_sd[i], size=sample_num)\n",
    "        persev_b = np.random.normal(persev_b_mean[i], persev_b_sd[i], size=sample_num)\n",
    "        \n",
    "        action,reward,reward_B,_ =read_data(i) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        \n",
    "        subject_loglikelyhood = []\n",
    "\n",
    "        for s in range(sample_num):\n",
    "            sample_loglikelyhood = []\n",
    "            # loglikelyhood = 0\n",
    "            sig_o = 4\n",
    "            sig_d = 2.8\n",
    "            v = np.ones((4))*50\n",
    "            sig = np.ones((4))*4\n",
    "            for t in range(trials):\n",
    "                if action[t]!=4:\n",
    "                    if comparision[t]<0:\n",
    "                    \n",
    "                        #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    if comparision[t]>=0:\n",
    "                        min_sig = np.min(sig)*np.ones((4))\n",
    "                        re_sig = sig-min_sig\n",
    "                        eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                        pb = np.zeros((4))\n",
    "                        if t>0:\n",
    "                            if action[t-1]!=4:\n",
    "                                pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                        # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                        beta_t = beta_b[s]\n",
    "                        if beta_t<0:\n",
    "                            beta_t = 0\n",
    "                        sample_loglikelyhood.append(action_probability((beta_t*v+eb+pb),action[t]))\n",
    "                    pe = reward[t] - v[action[t]]\n",
    "                    Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                    v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                    sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                else:\n",
    "                    sample_loglikelyhood.append(0)\n",
    "                sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "            subject_loglikelyhood.append(sample_loglikelyhood)\n",
    "        subject_loglikelyhood = np.array(subject_loglikelyhood)\n",
    "        loo,_,_ = psisloo(subject_loglikelyhood)\n",
    "        subject_loo.append(loo)\n",
    "    return subject_loo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bic(log_likelihood, n_params):\n",
    "    return -2 * log_likelihood + n_params * np.log(9000)\n",
    "def calculate_aic(log_likelihood, n_params):\n",
    "    return 2 * n_params - 2 * log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_s llh:  -9927.329187322961\n"
     ]
    }
   ],
   "source": [
    "s_llh = llh_s('./fitting_result/model_s_exp2.csv')\n",
    "print('model_s llh: ',np.sum(s_llh))\n",
    "\n",
    "# glm2_e1p_llh = llh_glm2_e1p('./fitting_result/model_glm2_e1p_exp2.csv')\n",
    "# print('model_glm2_e1p llh: ',np.sum(glm2_e1p_llh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_s loo:  -10288.48696814375\n"
     ]
    }
   ],
   "source": [
    "s_loo = loo_s('./fitting_result/model_s_exp2.csv')\n",
    "print('model_s loo: ',np.sum(s_loo))\n",
    "\n",
    "# glm2_e1p_loo = loo_glm2_e1p('./fitting_result/model_glm2_e1p.csv')\n",
    "# print('model_glm2_e1p loo: ',np.sum(glm2_e1p_loo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_v loo:  -10753.555424336024\n",
      "model_ve loo:  -10354.722099567554\n",
      "model_vp loo:  -10286.514549484264\n",
      "model_vep loo:  -10298.245138329949\n"
     ]
    }
   ],
   "source": [
    "v_loo = loo_v('./fitting_result/model_v_exp2.csv')\n",
    "print('model_v loo: ',np.sum(v_loo))\n",
    "\n",
    "ve_loo = loo_ve('./fitting_result/model_ve_exp2.csv')\n",
    "print('model_ve loo: ',np.sum(ve_loo))\n",
    "\n",
    "vp_loo = loo_vp('./fitting_result/model_vp_exp2.csv')\n",
    "print('model_vp loo: ',np.sum(vp_loo))\n",
    "\n",
    "vep_loo = loo_vep('./fitting_result/model_vep_exp2.csv')\n",
    "print('model_vep loo: ',np.sum(vep_loo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_v llh:  -10693.70420824784\n",
      "model_ve llh:  -10176.548765822703\n",
      "model_vp llh:  -10153.292125954167\n",
      "model_vep llh:  -9937.52168937738\n"
     ]
    }
   ],
   "source": [
    "v_llh = llh_v('./fitting_result/model_v_exp2.csv')\n",
    "print('model_v llh: ',np.sum(v_llh))\n",
    "\n",
    "ve_llh = llh_ve('./fitting_result/model_ve_exp2.csv')\n",
    "print('model_ve llh: ',np.sum(ve_llh))\n",
    "\n",
    "vp_llh = llh_vp('./fitting_result/model_vp_exp2.csv')\n",
    "print('model_vp llh: ',np.sum(vp_llh))\n",
    "\n",
    "vep_llh = llh_vep('./fitting_result/model_vep_exp2.csv')\n",
    "print('model_vep llh: ',np.sum(vep_llh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_glm_v loo:  -10350.07646154536\n",
      "model_glm_e loo:  -10228.56700287743\n",
      "model_glm_p loo:  -10221.576229095663\n",
      "model_glm_ve loo:  -10444.232505929049\n",
      "model_glm_vp loo:  -10338.781315313097\n",
      "model_glm_ep loo:  -10495.795797716031\n",
      "model_glm_vep loo:  -10742.464936466218\n"
     ]
    }
   ],
   "source": [
    "glm_v_loo = loo_glm_v('./fitting_result/model_glm_v_exp2.csv')\n",
    "print('model_glm_v loo: ',np.sum(glm_v_loo))\n",
    "\n",
    "glm_e_loo = loo_glm_e('./fitting_result/model_glm_e_exp2.csv')\n",
    "print('model_glm_e loo: ',np.sum(glm_e_loo))\n",
    "\n",
    "glm_p_loo = loo_glm_p('./fitting_result/model_glm_p_exp2.csv')\n",
    "print('model_glm_p loo: ',np.sum(glm_p_loo))\n",
    "\n",
    "glm_ve_loo = loo_glm_ve('./fitting_result/model_glm_ve_exp2.csv')\n",
    "print('model_glm_ve loo: ',np.sum(glm_ve_loo))\n",
    "\n",
    "glm_vp_loo = loo_glm_vp('./fitting_result/model_glm_vp_exp2.csv')\n",
    "print('model_glm_vp loo: ',np.sum(glm_vp_loo))\n",
    "\n",
    "glm_ep_loo = loo_glm_ep('./fitting_result/model_glm_ep_exp2.csv')\n",
    "print('model_glm_ep loo: ',np.sum(glm_ep_loo))\n",
    "\n",
    "glm_vep_loo = loo_glm_vep('./fitting_result/model_glm_vep_exp2.csv')\n",
    "print('model_glm_vep loo: ',np.sum(glm_vep_loo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_glm_v llh:  -9843.078954471794\n",
      "model_glm_e llh:  -9724.64561846448\n",
      "model_glm_p llh:  -9735.413650829403\n",
      "model_glm_ve llh:  -9689.682445286902\n",
      "model_glm_vp llh:  -9687.699948185962\n",
      "model_glm_ep llh:  -9653.811963611528\n",
      "model_glm_vep llh:  -9617.309468032736\n"
     ]
    }
   ],
   "source": [
    "glm_v_llh = llh_glm_v('./fitting_result/model_glm_v_exp2.csv')\n",
    "print('model_glm_v llh: ',np.sum(glm_v_llh))\n",
    "\n",
    "glm_e_llh = llh_glm_e('./fitting_result/model_glm_e_exp2.csv')\n",
    "print('model_glm_e llh: ',np.sum(glm_e_llh))\n",
    "\n",
    "glm_p_llh = llh_glm_p('./fitting_result/model_glm_p_exp2.csv')\n",
    "print('model_glm_p llh: ',np.sum(glm_p_llh))\n",
    "\n",
    "glm_ve_llh = llh_glm_ve('./fitting_result/model_glm_ve_exp2.csv')\n",
    "print('model_glm_ve llh: ',np.sum(glm_ve_llh))\n",
    "\n",
    "glm_vp_llh = llh_glm_vp('./fitting_result/model_glm_vp_exp2.csv')\n",
    "print('model_glm_vp llh: ',np.sum(glm_vp_llh))\n",
    "\n",
    "glm_ep_llh = llh_glm_ep('./fitting_result/model_glm_ep_exp2.csv')\n",
    "print('model_glm_ep llh: ',np.sum(glm_ep_llh))\n",
    "\n",
    "glm_vep_llh = llh_glm_vep('./fitting_result/model_glm_vep_exp2.csv')\n",
    "print('model_glm_vep llh: ',np.sum(glm_vep_llh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_glm2_v loo:  -23529.09892644539\n",
      "model_glm2_e loo:  -11064.039525090566\n",
      "model_glm2_p loo:  -11011.894077617759\n",
      "model_glm2_vep loo:  -29693.650956873338\n"
     ]
    }
   ],
   "source": [
    "glm2_v_loo = loo_glm2_v10('./fitting_result/model_glm2_v_exp2.csv')\n",
    "print('model_glm2_v loo: ',np.sum(glm2_v_loo))\n",
    "\n",
    "glm2_e_loo = loo_glm2_e10('./fitting_result/model_glm2_e_exp2.csv')\n",
    "print('model_glm2_e loo: ',np.sum(glm2_e_loo))\n",
    "\n",
    "glm2_p_loo = loo_glm2_p10('./fitting_result/model_glm2_p_exp2.csv')\n",
    "print('model_glm2_p loo: ',np.sum(glm2_p_loo))\n",
    "\n",
    "glm2_vep_loo = loo_glm2_vep('./fitting_result/model_glm2_vep_exp2.csv')\n",
    "print('model_glm2_vep loo: ',np.sum(glm2_vep_loo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_glm_vep llh:  -9617.309468032736\n",
      "model_glm2_vep llh:  -9635.605663402275\n"
     ]
    }
   ],
   "source": [
    "glm_vep_llh = llh_glm_vep('./fitting_result/model_glm_vep_exp2.csv')\n",
    "print('model_glm_vep llh: ',np.sum(glm_vep_llh))\n",
    "glm2_vep_llh = llh_glm2_vep('./fitting_result/model_glm2_vep_exp2.csv')\n",
    "print('model_glm2_vep llh: ',np.sum(glm2_vep_llh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_s llh:  -9927.329 , BIC: 19891.078 , AIC: 19862.658 , loo: -10288.487\n"
     ]
    }
   ],
   "source": [
    "print('model_s llh: ',round(np.sum(s_llh),3),', BIC:', round(calculate_bic(np.sum(s_llh), 4),3), ', AIC:', round(calculate_aic(np.sum(s_llh), 4),3), ', loo:',round(np.sum( s_loo),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_glm2_ep llh:  -9592.349 , BIC: 19248.432 , AIC: 19198.697 , loo: -13607.501\n"
     ]
    }
   ],
   "source": [
    "glm2_ep_llh = llh_glm2_ep('./fitting_result/model_glm2_ep_exp2.csv')\n",
    "glm2_ep_loo = loo_glm2_ep('./fitting_result/model_glm2_ep_exp2.csv')\n",
    "print('model_glm2_ep llh: ',round(np.sum(glm2_ep_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_ep_llh), 7),3), ', AIC:', round(calculate_aic(np.sum(glm2_ep_llh), 7),3), ', loo:',round(np.sum( glm2_ep_loo),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_glm2_v llh:  -9886.582714976144\n",
      "model_glm2_e llh:  -9687.07095738404\n",
      "model_glm2_p llh:  -9711.859939046764\n",
      "model_glm2_vep llh:  -9638.53457243934\n"
     ]
    }
   ],
   "source": [
    "glm2_v_llh = llh_glm2_v('./fitting_result/model_glm2_v_exp2.csv')\n",
    "print('model_glm2_v llh: ',np.sum(glm2_v_llh))\n",
    "\n",
    "glm2_e_llh = llh_glm2_e('./fitting_result/model_glm2_e_exp2.csv')\n",
    "print('model_glm2_e llh: ',np.sum(glm2_e_llh))\n",
    "\n",
    "glm2_p_llh = llh_glm2_p('./fitting_result/model_glm2_p_exp2.csv')\n",
    "print('model_glm2_p llh: ',np.sum(glm2_p_llh))\n",
    "\n",
    "glm2_vep_llh = llh_glm2_vep('./fitting_result/model_glm2_vep_exp2.csv')\n",
    "print('model_glm2_vep llh: ',np.sum(glm2_vep_llh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_glm2_v0 loo:  -20340.685754525333\n",
      "model_glm2_v1 loo:  -13448.848208715732\n",
      "model_glm2_e0 loo:  -10417.06853619546\n",
      "model_glm2_e1 loo:  -10281.181193110522\n",
      "model_glm2_p0 loo:  -10360.627618263385\n",
      "model_glm2_p1 loo:  -10306.770118215905\n"
     ]
    }
   ],
   "source": [
    "glm2_v0_loo = loo_glm2_v0('./fitting_result/model_glm2_v0_exp2.csv')\n",
    "print('model_glm2_v0 loo: ',np.sum(glm2_v0_loo))\n",
    "\n",
    "glm2_v1_loo = loo_glm2_v1('./fitting_result/model_glm2_v1_exp2.csv')\n",
    "print('model_glm2_v1 loo: ',np.sum(glm2_v1_loo))\n",
    "\n",
    "glm2_e0_loo = loo_glm2_e0('./fitting_result/model_glm2_e0_exp2.csv')\n",
    "print('model_glm2_e0 loo: ',np.sum(glm2_e0_loo))\n",
    "\n",
    "glm2_e1_loo = loo_glm2_e1('./fitting_result/model_glm2_e1_exp2.csv')\n",
    "print('model_glm2_e1 loo: ',np.sum(glm2_e1_loo))\n",
    "\n",
    "glm2_p0_loo = loo_glm2_p0('./fitting_result/model_glm2_p0_exp2.csv')\n",
    "print('model_glm2_p0 loo: ',np.sum(glm2_p0_loo))\n",
    "\n",
    "glm2_p1_loo = loo_glm2_p1('./fitting_result/model_glm2_p1_exp2.csv')\n",
    "print('model_glm2_p1 loo: ',np.sum(glm2_p1_loo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_glm2_v0 llh:  -9901.431374853682\n",
      "model_glm2_v1 llh:  -9866.587017141006\n",
      "model_glm2_e0 llh:  -9757.43321986517\n",
      "model_glm2_e1 llh:  -9749.059907022962\n",
      "model_glm2_p0 llh:  -9766.202160604642\n",
      "model_glm2_p1 llh:  -9757.91856747437\n"
     ]
    }
   ],
   "source": [
    "glm2_v0_llh = llh_glm2_v0('./fitting_result/model_glm2_v0_exp2.csv')\n",
    "print('model_glm2_v0 llh: ',np.sum(glm2_v0_llh))\n",
    "\n",
    "glm2_v1_llh = llh_glm2_v1('./fitting_result/model_glm2_v1_exp2.csv')\n",
    "print('model_glm2_v1 llh: ',np.sum(glm2_v1_llh))\n",
    "\n",
    "glm2_e0_llh = llh_glm2_e0('./fitting_result/model_glm2_e0_exp2.csv')\n",
    "print('model_glm2_e0 llh: ',np.sum(glm2_e0_llh))\n",
    "\n",
    "glm2_e1_llh = llh_glm2_e1('./fitting_result/model_glm2_e1_exp2.csv')\n",
    "print('model_glm2_e1 llh: ',np.sum(glm2_e1_llh))\n",
    "\n",
    "glm2_p0_llh = llh_glm2_p0('./fitting_result/model_glm2_p0_exp2.csv')\n",
    "print('model_glm2_p0 llh: ',np.sum(glm2_p0_llh))\n",
    "\n",
    "glm2_p1_llh = llh_glm2_p1('./fitting_result/model_glm2_p1_exp2.csv')\n",
    "print('model_glm2_p1 llh: ',np.sum(glm2_p1_llh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_glm2_v0e0 loo:  -20148.90123352225\n",
      "model_glm2_v1e1 loo:  -14407.952963139554\n",
      "model_glm2_e0p0 loo:  -10929.823676911114\n",
      "model_glm2_e1p1 loo:  -10866.361793969872\n",
      "model_glm2_v0p0 loo:  -20385.3634059952\n",
      "model_glm2_v1p1 loo:  -14400.335078918633\n",
      "model_glm2_v0e0p0 loo:  -21691.656658126925\n",
      "model_glm2_v1e1p1 loo:  -15786.757896936093\n"
     ]
    }
   ],
   "source": [
    "glm2_v0e0_loo = loo_glm2_v0e0('./fitting_result/model_glm2_v0e0_exp2.csv')\n",
    "print('model_glm2_v0e0 loo: ',np.sum(glm2_v0e0_loo))\n",
    "\n",
    "glm2_v1e1_loo = loo_glm2_v1e1('./fitting_result/model_glm2_v1e1_exp2.csv')\n",
    "print('model_glm2_v1e1 loo: ',np.sum(glm2_v1e1_loo))\n",
    "\n",
    "glm2_e0p0_loo = loo_glm2_e0p0('./fitting_result/model_glm2_e0p0_exp2.csv')\n",
    "print('model_glm2_e0p0 loo: ',np.sum(glm2_e0p0_loo))\n",
    "\n",
    "glm2_e1p1_loo = loo_glm2_e1p1('./fitting_result/model_glm2_e1p1_exp2.csv')\n",
    "print('model_glm2_e1p1 loo: ',np.sum(glm2_e1p1_loo))\n",
    "\n",
    "glm2_v0p0_loo = loo_glm2_v0p0('./fitting_result/model_glm2_v0p0_exp2.csv')\n",
    "print('model_glm2_v0p0 loo: ',np.sum(glm2_v0p0_loo))\n",
    "\n",
    "glm2_v1p1_loo = loo_glm2_v1p1('./fitting_result/model_glm2_v1p1_exp2.csv')\n",
    "print('model_glm2_v1p1 loo: ',np.sum(glm2_v1p1_loo))\n",
    "\n",
    "glm2_v0e0p0_loo = loo_glm2_v0e0p0('./fitting_result/model_glm2_v0e0p0_exp2.csv')\n",
    "print('model_glm2_v0e0p0 loo: ',np.sum(glm2_v0e0p0_loo))\n",
    "\n",
    "glm2_v1e1p1_loo = loo_glm2_v1e1p1('./fitting_result/model_glm2_v1e1p1_exp2.csv')\n",
    "print('model_glm2_v1e1p1 loo: ',np.sum(glm2_v1e1p1_loo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_glm2_v0e0 llh:  -9773.494257853585\n",
      "model_glm2_v1e1 llh:  -9767.656335877558\n",
      "model_glm2_e0p0 llh:  -9685.113987411727\n",
      "model_glm2_e1p1 llh:  -9690.849338034746\n",
      "model_glm2_v0p0 llh:  -9758.147228125117\n",
      "model_glm2_v1p1 llh:  -9758.09974968653\n",
      "model_glm2_v0e0p0 llh:  -9695.603258515805\n",
      "model_glm2_v1e1p1 llh:  -9709.891515955429\n"
     ]
    }
   ],
   "source": [
    "glm2_v0e0_llh = llh_glm2_v0e0('./fitting_result/model_glm2_v0e0_exp2.csv')\n",
    "print('model_glm2_v0e0 llh: ',np.sum(glm2_v0e0_llh))\n",
    "\n",
    "glm2_v1e1_llh = llh_glm2_v1e1('./fitting_result/model_glm2_v1e1_exp2.csv')\n",
    "print('model_glm2_v1e1 llh: ',np.sum(glm2_v1e1_llh))\n",
    "\n",
    "glm2_e0p0_llh = llh_glm2_e0p0('./fitting_result/model_glm2_e0p0_exp2.csv')\n",
    "print('model_glm2_e0p0 llh: ',np.sum(glm2_e0p0_llh))\n",
    "\n",
    "glm2_e1p1_llh = llh_glm2_e1p1('./fitting_result/model_glm2_e1p1_exp2.csv')\n",
    "print('model_glm2_e1p1 llh: ',np.sum(glm2_e1p1_llh))\n",
    "\n",
    "glm2_v0p0_llh = llh_glm2_v0p0('./fitting_result/model_glm2_v0p0_exp2.csv')\n",
    "print('model_glm2_v0p0 llh: ',np.sum(glm2_v0p0_llh))\n",
    "\n",
    "glm2_v1p1_llh = llh_glm2_v1p1('./fitting_result/model_glm2_v1p1_exp2.csv')\n",
    "print('model_glm2_v1p1 llh: ',np.sum(glm2_v1p1_llh))\n",
    "\n",
    "glm2_v0e0p0_llh = llh_glm2_v0e0p0('./fitting_result/model_glm2_v0e0p0_exp2.csv')\n",
    "print('model_glm2_v0e0p0 llh: ',np.sum(glm2_v0e0p0_llh))\n",
    "\n",
    "glm2_v1e1p1_llh = llh_glm2_v1e1p1('./fitting_result/model_glm2_v1e1p1_exp2.csv')\n",
    "print('model_glm2_v1e1p1 llh: ',np.sum(glm2_v1e1p1_llh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glm2_v1e1p0_loo = loo_glm2_v1e1p0('./fitting_result/model_glm2_v1e1p0_exp2.csv')\n",
    "# print('model_glm2_v1e1p0 loo: ',np.sum(glm2_v1e1p0_loo))\n",
    "# glm2_v1e1p0_llh = llh_glm2_v1e1p0('./fitting_result/model_glm2_v1e1p0_exp2.csv')\n",
    "# print('model_glm2_v1e1p0 llh: ',np.sum(glm2_v1e1p0_llh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_v llh:  -10693.704 , BIC: 21396.513 , AIC: 21389.408 , loo: -10753.555\n",
      "model_ve llh:  -10176.549 , BIC: 20371.307 , AIC: 20357.098 , loo: -10354.722\n",
      "model_vp llh:  -10153.292 , BIC: 20324.794 , AIC: 20310.584 , loo: -10286.515\n",
      "model_vep llh:  -9937.522 , BIC: 19902.358 , AIC: 19881.043 , loo: -10298.245\n",
      "model_glm_v llh:  -9843.079 , BIC: 19722.578 , AIC: 19694.158 , loo: -10350.076\n",
      "model_glm_e llh:  -9724.646 , BIC: 19485.711 , AIC: 19457.291 , loo: -10228.567\n",
      "model_glm_p llh:  -9735.414 , BIC: 19507.247 , AIC: 19478.827 , loo: -10221.576\n",
      "model_glm_ve llh:  -9689.682 , BIC: 19424.89 , AIC: 19389.365 , loo: -10444.233\n",
      "model_glm_vp llh:  -9687.7 , BIC: 19420.925 , AIC: 19385.4 , loo: -10338.781\n",
      "model_glm_ep llh:  -9653.812 , BIC: 19353.149 , AIC: 19317.624 , loo: -10495.796\n",
      "model_glm_vep llh:  -9617.309 , BIC: 19289.249 , AIC: 19246.619 , loo: -10742.465\n",
      "model_glm2_v llh:  -9886.583 , BIC: 19818.69 , AIC: 19783.165 , loo: -23529.099\n",
      "model_glm2_e llh:  -9687.071 , BIC: 19419.667 , AIC: 19384.142 , loo: -11064.04\n",
      "model_glm2_p llh:  -9711.86 , BIC: 19469.245 , AIC: 19433.72 , loo: -11011.894\n",
      "model_glm2_vep llh:  -9635.606 , BIC: 19353.156 , AIC: 19289.211 , loo: -29693.651\n",
      "model_glm2_v1 llh:  -9866.587 , BIC: 19769.594 , AIC: 19741.174 , loo: -13448.848\n",
      "model_glm2_v0 llh:  -9901.431 , BIC: 19839.283 , AIC: 19810.863 , loo: -20340.686\n",
      "model_glm2_e1 llh:  -9749.06 , BIC: 19534.54 , AIC: 19506.12 , loo: -10281.181\n",
      "model_glm2_e0 llh:  -9757.433 , BIC: 19551.286 , AIC: 19522.866 , loo: -10417.069\n",
      "model_glm2_p1 llh:  -9757.919 , BIC: 19552.257 , AIC: 19523.837 , loo: -10306.77\n",
      "model_glm2_p0 llh:  -9766.202 , BIC: 19568.824 , AIC: 19540.404 , loo: -10360.628\n",
      "model_glm2_v1e1 llh:  -9767.656 , BIC: 19580.838 , AIC: 19545.313 , loo: -14407.953\n",
      "model_glm2_v0e0 llh:  -9773.494 , BIC: 19592.513 , AIC: 19556.989 , loo: -20148.901\n",
      "model_glm2_v1p1 llh:  -9758.1 , BIC: 19561.724 , AIC: 19526.199 , loo: -14400.335\n",
      "model_glm2_v0p0 llh:  -9758.147 , BIC: 19561.819 , AIC: 19526.294 , loo: -20385.363\n",
      "model_glm2_e1p1 llh:  -9690.849 , BIC: 19427.224 , AIC: 19391.699 , loo: -10866.362\n",
      "model_glm2_e0p0 llh:  -9685.114 , BIC: 19415.753 , AIC: 19380.228 , loo: -10929.824\n",
      "model_glm2_v1e1p1 llh:  -9709.892 , BIC: 19474.413 , AIC: 19431.783 , loo: -15786.758\n",
      "model_glm2_v0e0p0 llh:  -9695.603 , BIC: 19445.836 , AIC: 19403.207 , loo: -21691.657\n"
     ]
    }
   ],
   "source": [
    "print('model_v llh: ',round(np.sum(v_llh),3),', BIC:', round(calculate_bic(np.sum(v_llh), 1),3), ', AIC:', round(calculate_aic(np.sum(v_llh), 1),3), ', loo:',round(np.sum( v_loo),3))\n",
    "print('model_ve llh: ',round(np.sum(ve_llh),3),', BIC:', round(calculate_bic(np.sum(ve_llh), 2),3), ', AIC:', round(calculate_aic(np.sum(ve_llh), 2),3), ', loo:',round(np.sum( ve_loo),3))\n",
    "print('model_vp llh: ',round(np.sum(vp_llh),3),', BIC:', round(calculate_bic(np.sum(vp_llh), 2),3), ', AIC:', round(calculate_aic(np.sum(vp_llh), 2),3), ', loo:',round(np.sum( vp_loo),3))\n",
    "print('model_vep llh: ',round(np.sum(vep_llh),3),', BIC:', round(calculate_bic(np.sum(vep_llh), 3),3), ', AIC:', round(calculate_aic(np.sum(vep_llh), 3),3), ', loo:',round(np.sum( vep_loo),3))\n",
    "print('model_glm_v llh: ',round(np.sum(glm_v_llh),3),', BIC:', round(calculate_bic(np.sum(glm_v_llh), 4),3), ', AIC:', round(calculate_aic(np.sum(glm_v_llh), 4),3), ', loo:',round(np.sum( glm_v_loo),3))\n",
    "print('model_glm_e llh: ',round(np.sum(glm_e_llh),3),', BIC:', round(calculate_bic(np.sum(glm_e_llh), 4),3), ', AIC:', round(calculate_aic(np.sum(glm_e_llh), 4),3), ', loo:',round(np.sum( glm_e_loo),3))\n",
    "print('model_glm_p llh: ',round(np.sum(glm_p_llh),3),', BIC:', round(calculate_bic(np.sum(glm_p_llh), 4),3), ', AIC:', round(calculate_aic(np.sum(glm_p_llh), 4),3), ', loo:',round(np.sum( glm_p_loo),3))\n",
    "print('model_glm_ve llh: ',round(np.sum(glm_ve_llh),3),', BIC:', round(calculate_bic(np.sum(glm_ve_llh), 5),3), ', AIC:', round(calculate_aic(np.sum(glm_ve_llh), 5),3), ', loo:',round(np.sum( glm_ve_loo),3))\n",
    "print('model_glm_vp llh: ',round(np.sum(glm_vp_llh),3),', BIC:', round(calculate_bic(np.sum(glm_vp_llh), 5),3), ', AIC:', round(calculate_aic(np.sum(glm_vp_llh), 5),3), ', loo:',round(np.sum( glm_vp_loo),3))\n",
    "print('model_glm_ep llh: ',round(np.sum(glm_ep_llh),3),', BIC:', round(calculate_bic(np.sum(glm_ep_llh), 5),3), ', AIC:', round(calculate_aic(np.sum(glm_ep_llh), 5),3), ', loo:',round(np.sum( glm_ep_loo),3))\n",
    "print('model_glm_vep llh: ',round(np.sum(glm_vep_llh),3),', BIC:', round(calculate_bic(np.sum(glm_vep_llh), 6),3), ', AIC:', round(calculate_aic(np.sum(glm_vep_llh), 6),3), ', loo:',round(np.sum( glm_vep_loo),3))\n",
    "print('model_glm2_v llh: ',round(np.sum(glm2_v_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_v_llh), 5),3), ', AIC:', round(calculate_aic(np.sum(glm2_v_llh), 5),3), ', loo:',round(np.sum( glm2_v_loo),3))\n",
    "print('model_glm2_e llh: ',round(np.sum(glm2_e_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_e_llh), 5),3), ', AIC:', round(calculate_aic(np.sum(glm2_e_llh), 5),3), ', loo:',round(np.sum( glm2_e_loo),3))\n",
    "print('model_glm2_p llh: ',round(np.sum(glm2_p_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_p_llh), 5),3), ', AIC:', round(calculate_aic(np.sum(glm2_p_llh), 5),3), ', loo:',round(np.sum( glm2_p_loo),3))\n",
    "print('model_glm2_vep llh: ',round(np.sum(glm2_vep_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_vep_llh), 9),3), ', AIC:', round(calculate_aic(np.sum(glm2_vep_llh), 9),3), ', loo:',round(np.sum( glm2_vep_loo),3))\n",
    "print('model_glm2_v1 llh: ',round(np.sum(glm2_v1_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_v1_llh), 4),3), ', AIC:', round(calculate_aic(np.sum(glm2_v1_llh), 4),3), ', loo:',round(np.sum( glm2_v1_loo),3))\n",
    "print('model_glm2_v0 llh: ',round(np.sum(glm2_v0_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_v0_llh), 4),3), ', AIC:', round(calculate_aic(np.sum(glm2_v0_llh), 4),3), ', loo:',round(np.sum( glm2_v0_loo),3))\n",
    "print('model_glm2_e1 llh: ',round(np.sum(glm2_e1_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_e1_llh), 4),3), ', AIC:', round(calculate_aic(np.sum(glm2_e1_llh), 4),3), ', loo:',round(np.sum( glm2_e1_loo),3))\n",
    "print('model_glm2_e0 llh: ',round(np.sum(glm2_e0_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_e0_llh), 4),3), ', AIC:', round(calculate_aic(np.sum(glm2_e0_llh), 4),3), ', loo:',round(np.sum( glm2_e0_loo),3))\n",
    "print('model_glm2_p1 llh: ',round(np.sum(glm2_p1_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_p1_llh), 4),3), ', AIC:', round(calculate_aic(np.sum(glm2_p1_llh), 4),3), ', loo:',round(np.sum( glm2_p1_loo),3))\n",
    "print('model_glm2_p0 llh: ',round(np.sum(glm2_p0_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_p0_llh), 4),3), ', AIC:', round(calculate_aic(np.sum(glm2_p0_llh), 4),3), ', loo:',round(np.sum( glm2_p0_loo),3))\n",
    "print('model_glm2_v1e1 llh: ',round(np.sum(glm2_v1e1_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_v1e1_llh), 5),3), ', AIC:', round(calculate_aic(np.sum(glm2_v1e1_llh), 5),3), ', loo:',round(np.sum( glm2_v1e1_loo),3))\n",
    "print('model_glm2_v0e0 llh: ',round(np.sum(glm2_v0e0_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_v0e0_llh), 5),3), ', AIC:', round(calculate_aic(np.sum(glm2_v0e0_llh), 5),3), ', loo:',round(np.sum( glm2_v0e0_loo),3))\n",
    "print('model_glm2_v1p1 llh: ',round(np.sum(glm2_v1p1_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_v1p1_llh), 5),3), ', AIC:', round(calculate_aic(np.sum(glm2_v1p1_llh), 5),3), ', loo:',round(np.sum( glm2_v1p1_loo),3))\n",
    "print('model_glm2_v0p0 llh: ',round(np.sum(glm2_v0p0_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_v0p0_llh), 5),3), ', AIC:', round(calculate_aic(np.sum(glm2_v0p0_llh), 5),3), ', loo:',round(np.sum( glm2_v0p0_loo),3))\n",
    "print('model_glm2_e1p1 llh: ',round(np.sum(glm2_e1p1_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_e1p1_llh), 5),3), ', AIC:', round(calculate_aic(np.sum(glm2_e1p1_llh), 5),3), ', loo:',round(np.sum( glm2_e1p1_loo),3))\n",
    "print('model_glm2_e0p0 llh: ',round(np.sum(glm2_e0p0_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_e0p0_llh), 5),3), ', AIC:', round(calculate_aic(np.sum(glm2_e0p0_llh), 5),3), ', loo:',round(np.sum( glm2_e0p0_loo),3))\n",
    "print('model_glm2_v1e1p1 llh: ',round(np.sum(glm2_v1e1p1_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_v1e1p1_llh), 6),3), ', AIC:', round(calculate_aic(np.sum(glm2_v1e1p1_llh), 6),3), ', loo:',round(np.sum( glm2_v1e1p1_loo),3))\n",
    "print('model_glm2_v0e0p0 llh: ',round(np.sum(glm2_v0e0p0_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_v0e0p0_llh), 6),3), ', AIC:', round(calculate_aic(np.sum(glm2_v0e0p0_llh), 6),3), ', loo:',round(np.sum( glm2_v0e0p0_loo),3))\n",
    "# print('model_glm2_v1e1p0 llh: ',round(np.sum(glm2_v1e1p0_llh),3),', BIC:', round(calculate_bic(np.sum(glm2_v1e1p0_llh), 6),3), ', AIC:', round(calculate_aic(np.sum(glm2_v1e1p0_llh), 6),3), ', loo:',round(np.sum( glm2_v1e1p0_loo),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_a,phi_a,persev_a,beta_b,phi_b,persev_b = read_parameter_6_para('./fitting_result/model_glm_vep_exp2.csv')\n",
    "\n",
    "beta_norm = np.divide(beta_a,beta_b)\n",
    "phi_norm = np.divide(phi_a,phi_b)\n",
    "persev_norm = np.divide(persev_a,persev_b)\n",
    "\n",
    "beta_norm_abs = np.divide(beta_a,np.abs(beta_b))\n",
    "phi_norm_abs = np.divide(phi_a,np.abs(phi_b))\n",
    "persev_norm_abs = np.divide(persev_a,np.abs(persev_b))\n",
    "\n",
    "data_glm_vep = {'beta_a':beta_a,'phi_a':phi_a,'persev_a':persev_a,\n",
    "        'beta_b':beta_b,'phi_b':phi_b,'persev_b':persev_b,\n",
    "        'beta_norm':beta_norm,'phi_norm':phi_norm,'persev_norm':persev_norm,\n",
    "        'beta_norm_abs':beta_norm_abs,'phi_norm_abs':phi_norm_abs,'persev_norm_abs':persev_norm_abs}\n",
    "\n",
    "df_glm_vep = pd.DataFrame(data_glm_vep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_a:  0.000893595485689395 0.0008265511741161 3.228985539978525e-05 1.2282105783054071 0.22408584567934917\n",
      "phi_a:  -0.013112180314773533 -0.0108210234996748 0.0005953948595233775 -4.196983772438046 8.926822731739974e-05\n",
      "persev_a:  0.07248304192152892 0.0465581375004038 0.017827974169875877 4.239848423582408 7.706788563537114e-05\n",
      "beta_norm_abs:  0.0460830237975851 0.023502697563886905 0.050884263346658444 1.5955636726422886 0.11575463619225061\n",
      "phi_norm_abs:  -0.35603702027243733 -0.11258597258501246 1.288157916452707 -2.4500532402265116 0.017168284317786435\n",
      "persev_norm_abs:  0.30517334349845776 0.08233111326362683 0.9943163283139339 2.3902824770974314 0.019938756641936426\n"
     ]
    }
   ],
   "source": [
    "print('beta_a: ', np.mean(beta_a), np.median(beta_a), np.var(beta_a),ttest_1samp(df_glm_vep[\"beta_a\"], 0)[0], ttest_1samp(df_glm_vep[\"beta_a\"], 0)[1])\n",
    "print('phi_a: ', np.mean(phi_a), np.median(phi_a), np.var(phi_a),ttest_1samp(df_glm_vep[\"phi_a\"], 0)[0], ttest_1samp(df_glm_vep[\"phi_a\"], 0)[1])\n",
    "print('persev_a: ', np.mean(persev_a), np.median(persev_a), np.var(persev_a),ttest_1samp(df_glm_vep[\"persev_a\"], 0)[0], ttest_1samp(df_glm_vep[\"persev_a\"], 0)[1])\n",
    "\n",
    "print('beta_norm_abs: ', np.mean(beta_norm_abs), np.median(beta_norm_abs), np.var(beta_norm_abs),ttest_1samp(df_glm_vep[\"beta_norm_abs\"], 0)[0], ttest_1samp(df_glm_vep[\"beta_norm_abs\"], 0)[1])\n",
    "print('phi_norm_abs: ', np.mean(phi_norm_abs), np.median(phi_norm_abs), np.var(phi_norm_abs),ttest_1samp(df_glm_vep[\"phi_norm_abs\"], 0)[0], ttest_1samp(df_glm_vep[\"phi_norm_abs\"], 0)[1])\n",
    "print('persev_norm_abs: ', np.mean(persev_norm_abs), np.median(persev_norm_abs), np.var(persev_norm_abs),ttest_1samp(df_glm_vep[\"persev_norm_abs\"], 0)[0], ttest_1samp(df_glm_vep[\"persev_norm_abs\"], 0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_a分布与0没有显著差异\n",
      "T-statistic: 1.2282, P-value: 0.2241\n",
      "phi_a 分布与0有显著差异\n",
      "T-statistic: -4.1970, P-value: 0.0001\n",
      "persev_a 分布与0有显著差异\n",
      "T-statistic: 4.2398, P-value: 0.0001\n",
      "beta_norm_abs分布与0没有显著差异\n",
      "T-statistic: 1.5956, P-value: 0.1158\n",
      "phi_norm_abs 分布与0有显著差异\n",
      "T-statistic: -2.4501, P-value: 0.0172\n",
      "persev_norm_abs 分布与0有显著差异\n",
      "T-statistic: 2.3903, P-value: 0.0199\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_value = ttest_1samp(df_glm_vep[\"beta_a\"], 0)\n",
    "if p_value < 0.05:\n",
    "    print(\"beta_a 分布与0有显著差异\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "else:\n",
    "    print(\"beta_a分布与0没有显著差异\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "t_stat, p_value = ttest_1samp(df_glm_vep[\"phi_a\"], 0)\n",
    "if p_value < 0.05:\n",
    "    print(\"phi_a 分布与0有显著差异\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "else:\n",
    "    print(\"phi_a分布与0没有显著差异\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "t_stat, p_value = ttest_1samp(df_glm_vep[\"persev_a\"], 0)\n",
    "if p_value < 0.05:\n",
    "    print(\"persev_a 分布与0有显著差异\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "else:\n",
    "    print(\"persev_a分布与0没有显著差异\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "t_stat, p_value = ttest_1samp(df_glm_vep[\"beta_norm_abs\"], 0)\n",
    "if p_value < 0.05:\n",
    "    print(\"beta_norm_abs 分布与0有显著差异\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "else:\n",
    "    print(\"beta_norm_abs分布与0没有显著差异\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "t_stat, p_value = ttest_1samp(df_glm_vep[\"phi_norm_abs\"], 0)\n",
    "if p_value < 0.05:\n",
    "    print(\"phi_norm_abs 分布与0有显著差异\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "else:\n",
    "    print(\"phi_norm_abs分布与0没有显著差异\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "t_stat, p_value = ttest_1samp(df_glm_vep[\"persev_norm_abs\"], 0)\n",
    "if p_value < 0.05:\n",
    "    print(\"persev_norm_abs 分布与0有显著差异\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "else:\n",
    "    print(\"persev_norm_abs分布与0没有显著差异\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_a:  0.000893595485689395 0.0008265511741161 3.228985539978525e-05 1.2282105783054071 0.22408584567934917\n",
      "phi_a:  -0.013112180314773533 -0.0108210234996748 0.0005953948595233775 -4.196983772438046 8.926822731739974e-05\n",
      "persev_a:  0.07248304192152892 0.0465581375004038 0.017827974169875877 4.239848423582408 7.706788563537114e-05\n",
      "beta_norm_abs:  0.0460830237975851 0.023502697563886905 0.050884263346658444 1.5955636726422886 0.11575463619225061\n",
      "phi_norm_abs:  -0.35603702027243733 -0.11258597258501246 1.288157916452707 -2.4500532402265116 0.017168284317786435\n",
      "persev_norm_abs:  0.30517334349845776 0.08233111326362683 0.9943163283139339 2.3902824770974314 0.019938756641936426\n"
     ]
    }
   ],
   "source": [
    "print('beta_a: ', np.mean(beta_a), np.median(beta_a), np.var(beta_a),ttest_1samp(beta_a, 0)[0], ttest_1samp(beta_a, 0)[1])\n",
    "print('phi_a: ', np.mean(phi_a), np.median(phi_a), np.var(phi_a),ttest_1samp(phi_a, 0)[0], ttest_1samp(phi_a, 0)[1])\n",
    "print('persev_a: ', np.mean(persev_a), np.median(persev_a), np.var(persev_a),ttest_1samp(persev_a, 0)[0], ttest_1samp(persev_a, 0)[1])\n",
    "\n",
    "print('beta_norm_abs: ', np.mean(beta_norm_abs), np.median(beta_norm_abs), np.var(beta_norm_abs),ttest_1samp(beta_norm_abs, 0)[0], ttest_1samp(beta_norm_abs, 0)[1])\n",
    "print('phi_norm_abs: ', np.mean(phi_norm_abs), np.median(phi_norm_abs), np.var(phi_norm_abs),ttest_1samp(phi_norm_abs, 0)[0], ttest_1samp(phi_norm_abs, 0)[1])\n",
    "print('persev_norm_abs: ', np.mean(persev_norm_abs), np.median(persev_norm_abs), np.var(persev_norm_abs),ttest_1samp(persev_norm_abs, 0)[0], ttest_1samp(persev_norm_abs, 0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_bic = calculate_bic(np.sum(v_llh),1)\n",
    "ve_bic = calculate_bic(np.sum(ve_llh),2)\n",
    "vep_bic = calculate_bic(np.sum(vep_llh),3)\n",
    "\n",
    "glm_v_bic = calculate_bic(np.sum(glm_v_llh),4)\n",
    "glm_e_bic = calculate_bic(np.sum(glm_e_llh),4)\n",
    "glm_p_bic = calculate_bic(np.sum(glm_p_llh),4)\n",
    "\n",
    "glm_vep_bic = calculate_bic(np.sum(glm_vep_llh),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-160.28260789318355 19902.358318323713\n",
      "-155.1178946456893 19289.24881520338\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(vep_llh),vep_bic)\n",
    "print(np.mean(glm_vep_llh),glm_vep_bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "width = 0.2\n",
    "b=6\n",
    "c=4.5\n",
    "\n",
    "(81/255, 214/255, 255/255)\n",
    "plt.gca().invert_yaxis()\n",
    "# plt.bar(width*1,np.mean(nhb_ru_c)/150,width=width,color='dimgray')\n",
    "plt.bar(width*(1),(v_bic)/(150*62),width=width,color='indigo')\n",
    "plt.bar(width*(2),(ve_bic)/(150*62),width=width,color='mediumorchid')\n",
    "plt.bar(width*(3),(vep_bic)/(150*62),width=width,color='plum')\n",
    "\n",
    "plt.bar(width*(c+1),(glm_v_bic)/(150*62),width=width,color='royalblue')\n",
    "plt.bar(width*(c+2),(glm_e_bic)/(150*62),width=width,color=(81/255, 214/255, 255/255))\n",
    "plt.bar(width*(c+3),(glm_p_bic)/(150*62),width=width,color='skyblue')\n",
    "plt.bar(width*(c+4),(glm_vep_bic)/(150*62),width=width,color='lightblue')\n",
    "# plt.bar(width*(c+5),np.mean(nhb_glm_ru_c_vep)/150,width=width,color='lightcyan',label='GLM:DUP')\n",
    "# plt.yticks([-0.8,-0.85,-0.9,-0.95,-1])\n",
    "plt.ylim(2.42,1.5)\n",
    "plt.xticks([])\n",
    "plt.ylabel('Log-likelihood')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 86.4x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = (np.random.random((62))-np.ones((62))*0.5)*0.6\n",
    "plt.figure(figsize=(1.2,6))\n",
    "sns.boxplot(data=df_glm_vep[\"beta_a\"],linewidth=2,fliersize=0,color='white')\n",
    "plt.scatter(x,df_glm_vep[\"beta_a\"],s=30,color='royalblue',linewidths=0.5,alpha=0.8)\n",
    "# plt.yticks([-3,-2,-1,0,1,2])\n",
    "plt.xticks([])\n",
    "# plt.ylim([-4,2])\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 86.4x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = (np.random.random((62))-np.ones((62))*0.5)*0.6\n",
    "plt.figure(figsize=(1.2,6))\n",
    "sns.boxplot(data=df_glm_vep[\"phi_a\"],linewidth=2,fliersize=0,color='white')\n",
    "plt.scatter(x,df_glm_vep[\"phi_a\"],s=30,color=(81/255, 214/255, 255/255),linewidths=0.5,alpha=0.8)\n",
    "# plt.yticks([-3,-2,-1,0,1,2])\n",
    "plt.xticks([])\n",
    "# plt.ylim([-4,2])\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 86.4x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = (np.random.random((62))-np.ones((62))*0.5)*0.6\n",
    "plt.figure(figsize=(1.2,7))\n",
    "sns.boxplot(data=df_glm_vep[\"persev_a\"],linewidth=2,fliersize=0,color='white')\n",
    "plt.scatter(x,df_glm_vep[\"persev_a\"],s=30,color='skyblue',linewidths=0.5,alpha=0.8)\n",
    "# plt.yticks([-3,-2,-1,0,1,2])\n",
    "plt.xticks([])\n",
    "# plt.ylim([-4,2])\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制直方图\n",
    "plt.hist(df_glm_vep[\"persev_a\"], bins=20, color='skyblue', edgecolor='black')  # bins控制分箱数\n",
    "# plt.title(\"Histogram of Data Distribution\")\n",
    "# plt.xlabel(\"Value Range\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)  # 添加网格线\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
