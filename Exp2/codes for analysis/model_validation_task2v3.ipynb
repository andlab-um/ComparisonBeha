{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_num = 62\n",
    "\n",
    "def read_data(n):  #read behavioral data; no action: action[i]=4\n",
    "    #数据文件在的位置\n",
    "    action = []\n",
    "    reward = []\n",
    "    reward_B = []\n",
    "    comparision = [] #r-r_b; 1:>=0, 0:<0\n",
    "    num = str(220+n)\n",
    "    file = pd.read_csv('E:/multi-bandit/task2v3/RLE2V3_data/' + num + '.csv')\n",
    "    name = 'sub (' +str(n) +').csv'\n",
    "    action_index = 0\n",
    "    for i in  range((file.shape[1])):\n",
    "        if file.columns[i] == 'choose_bandit.keys':\n",
    "            action_index = i\n",
    "    reward_index = 0\n",
    "    for i in  range((file.shape[1])):\n",
    "        if file.columns[i] == 'subchoose':\n",
    "            reward_index = i\n",
    "    for i in range((file.shape[0])):\n",
    "\n",
    "        if (file.iloc[i,0] == 1 or file.iloc[i,0] == 0) and file.iloc[i,action_index]!='None' :\n",
    "            if file.iloc[i,action_index] == 'r':\n",
    "                action.append(0)\n",
    "            elif file.iloc[i,action_index] == 'f':\n",
    "                action.append(1)\n",
    "            elif file.iloc[i,action_index] == 'i':\n",
    "                action.append(2)\n",
    "            elif file.iloc[i,action_index] == 'j':\n",
    "                action.append(3)\n",
    "            else:\n",
    "                print(file.iloc[i,action_index])\n",
    "                print(i)\n",
    "                raise ValueError('不能识别选项')\n",
    "            reward.append(int(file.iloc[i,reward_index]))\n",
    "            reward_B.append(int(file.iloc[i,reward_index+1]))\n",
    "            if int(file.iloc[i,reward_index]) >= int(file.iloc[i,reward_index+1]):\n",
    "                comparision.append(int(file.iloc[i,reward_index])-int(file.iloc[i,reward_index+1]))\n",
    "            else:\n",
    "                comparision.append(int(file.iloc[i,reward_index+1])-int(file.iloc[i,reward_index]))\n",
    "        elif (file.iloc[i,0] == 1 or file.iloc[i,0] == 0)  and file.iloc[i,action_index] =='None' :\n",
    "            action.append(4)\n",
    "            reward.append(0)\n",
    "            reward_B.append(0)\n",
    "            comparision.append(0)\n",
    "    return action,reward,reward_B,comparision\n",
    "\n",
    "def read_data_task2(n):  #read behavioral data; no action: action[i]=4\n",
    "    num = str(220+n)\n",
    "    n_wrong = 0\n",
    "    #数据文件在的位置\n",
    "    action = []\n",
    "    reward = []\n",
    "    reward_B = []\n",
    "    comparision = [] #r-r_b; 1:>=0, 0:<0\n",
    "    expect_arm = []\n",
    "    expect_reward = []\n",
    "    expect_confidence = []\n",
    "    ask = []\n",
    "       \n",
    "    file = pd.read_csv('E:/multi-bandit/task2v3/RLE2V3_data/' + num + '.csv')\n",
    "\n",
    "    action_index = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'choose_bandit.keys':\n",
    "            action_index = i\n",
    "    reward_index = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'subchoose':\n",
    "            reward_index = i\n",
    "            \n",
    "    ask_reward_choose_index = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'expectself.text':\n",
    "            ask_reward_choose_index = i\n",
    "    ask_reward_random_index = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'expect_random_3.text':\n",
    "            ask_reward_random_index = i\n",
    "    ask_reward_confidence = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'slider_2.response':\n",
    "            ask_reward_confidence = i\n",
    "\n",
    "    whether_ask = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'whether_ask':\n",
    "            whether_ask = i        \n",
    "    ask_random_arm = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'random_whicharm':\n",
    "            ask_random_arm = i  \n",
    "        \n",
    "    for i in range((file.shape[0])):\n",
    "        if (file.iloc[i,0] == 1 or file.iloc[i,0] == 0) and file.iloc[i,action_index]!='None' :\n",
    "            # print(i)\n",
    "            if file.iloc[i,action_index] == 'r':\n",
    "                action.append(0)\n",
    "            elif file.iloc[i,action_index] == 'f':\n",
    "                action.append(1)\n",
    "            elif file.iloc[i,action_index] == 'i':\n",
    "                action.append(2)\n",
    "            elif file.iloc[i,action_index] == 'j':\n",
    "                action.append(3)\n",
    "            else:\n",
    "                print(file.iloc[i,action_index])\n",
    "                print(i)\n",
    "                raise ValueError('不能识别选项')\n",
    "            reward.append(int(file.iloc[i,reward_index]))\n",
    "            reward_B.append(int(file.iloc[i,reward_index+1]))\n",
    "            if int(file.iloc[i,reward_index]) >= int(file.iloc[i,reward_index+1]):\n",
    "                comparision.append(int(file.iloc[i,reward_index])-int(file.iloc[i,reward_index+1]))\n",
    "            else:\n",
    "                comparision.append(int(file.iloc[i,reward_index+1])-int(file.iloc[i,reward_index]))\n",
    "            \n",
    "            if int(file.iloc[i,whether_ask])==0:\n",
    "                if np.isnan(file.iloc[i,ask_reward_choose_index]):\n",
    "                    n_wrong+=1\n",
    "                    ask.append(2)\n",
    "                    expect_arm.append(4)\n",
    "                    expect_reward.append(0)\n",
    "                    expect_confidence.append(1)\n",
    "                else: \n",
    "                    ask.append(0)\n",
    "                    expect_arm.append(action[len(action)-1])\n",
    "                # if np.isnan(file.iloc[i,ask_reward_choose_index]):\n",
    "                #     print(n,i)\n",
    "                    expect_reward.append(int(file.iloc[i,ask_reward_choose_index]))\n",
    "                    expect_confidence.append(float(file.iloc[i,ask_reward_confidence]))\n",
    "            elif int(file.iloc[i,whether_ask])==1:\n",
    "                if np.isnan(file.iloc[i,ask_reward_random_index]):\n",
    "                    n_wrong+=1\n",
    "                    ask.append(2)\n",
    "                    expect_arm.append(4)\n",
    "                    expect_reward.append(0)\n",
    "                    expect_confidence.append(1)\n",
    "                else: \n",
    "                    ask.append(1)\n",
    "                    if float(file.iloc[i,ask_random_arm])==-0.6:\n",
    "                        expect_arm.append(0)\n",
    "                    elif float(file.iloc[i,ask_random_arm])==-0.2:\n",
    "                        expect_arm.append(1)\n",
    "                    elif float(file.iloc[i,ask_random_arm])==0.2:\n",
    "                        expect_arm.append(2)\n",
    "                    elif float(file.iloc[i,ask_random_arm])==0.6:\n",
    "                        expect_arm.append(3)\n",
    "                    else:\n",
    "                        print('ERROR expect_arm')\n",
    "                    expect_reward.append(int(file.iloc[i,ask_reward_random_index]))\n",
    "                    expect_confidence.append(float(file.iloc[i,ask_reward_confidence]))\n",
    "            elif int(file.iloc[i,whether_ask])==2 or int(file.iloc[i,whether_ask])==3:\n",
    "                ask.append(2)\n",
    "                expect_arm.append(4)\n",
    "                expect_reward.append(0)\n",
    "                expect_confidence.append(1)\n",
    "            else:\n",
    "                print('ERROR ask whether_whicharm')\n",
    "                \n",
    "                \n",
    "        elif (file.iloc[i,0] == 1 or file.iloc[i,0] == 0)  and file.iloc[i,action_index] =='None' :\n",
    "            action.append(4)\n",
    "            reward.append(0)\n",
    "            reward_B.append(0)\n",
    "            comparision.append(0)\n",
    "            expect_arm.append(4)\n",
    "            expect_reward.append(0)\n",
    "            expect_confidence.append(1)\n",
    "            ask.append(2)\n",
    "    print('subject: ',n,' n_wrong: ',n_wrong)\n",
    "    return action,reward,reward_B,comparision,expect_arm,expect_reward,expect_confidence,ask\n",
    "\n",
    "def read_data_task2_happiness(n):\n",
    "    num = str(220+n)\n",
    "    file = pd.read_csv('E:/multi-bandit/task2v3/RLE2V3_data/' + num + '.csv')\n",
    "    action_index = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'choose_bandit.keys':\n",
    "            action_index = i\n",
    "    happiness_index = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'slider.response':\n",
    "            happiness_index = i\n",
    "    whether_ask = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'whether_ask':\n",
    "            whether_ask = i \n",
    "    action = []\n",
    "    reward = []\n",
    "    reward_B = []\n",
    "\n",
    "    reward_index = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'subchoose':\n",
    "            reward_index = i\n",
    "    \n",
    "    happiness = []\n",
    "    \n",
    "    for i in range((file.shape[0])):\n",
    "        if (file.iloc[i,0] == 1 or file.iloc[i,0] == 0) and file.iloc[i,action_index]!='None' and (int(file.iloc[i,whether_ask])==2 or int(file.iloc[i,whether_ask])==3) :\n",
    "            \n",
    "            # print(i)\n",
    "            \n",
    "            if file.iloc[i,action_index] == 'r':\n",
    "                action.append(0)\n",
    "            elif file.iloc[i,action_index] == 'f':\n",
    "                action.append(1)\n",
    "            elif file.iloc[i,action_index] == 'i':\n",
    "                action.append(2)\n",
    "            elif file.iloc[i,action_index] == 'j':\n",
    "                action.append(3)\n",
    "            else:\n",
    "                print(file.iloc[i,action_index])\n",
    "                print(i)\n",
    "                raise ValueError('不能识别选项')\n",
    "            reward.append(int(file.iloc[i,reward_index]))\n",
    "            reward_B.append(int(file.iloc[i,reward_index+1]))\n",
    "\n",
    "            happiness.append(int(float(file.iloc[i,happiness_index])))\n",
    "    return action,reward,reward_B,happiness\n",
    "\n",
    "def read_true_reward_distribution(n):\n",
    "    num = str(220+n)\n",
    "    file = pd.read_csv('E:/multi-bandit/task2v3/RLE2V3_data/' + num + '.csv')\n",
    "    reward_0 = []\n",
    "    reward_1 = []\n",
    "    reward_2 = []\n",
    "    reward_3 = []\n",
    "    \n",
    "    yellow_index = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'rewardyellow':\n",
    "            yellow_index = i\n",
    "    red_index = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'rewardred':\n",
    "            red_index = i\n",
    "    blue_index = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'rewardblue':\n",
    "            blue_index = i\n",
    "    green_index = 0\n",
    "    for i in range((file.shape[1])):\n",
    "        if file.columns[i] == 'rewardgreen':\n",
    "            green_index = i        \n",
    "    \n",
    "    for i in range((file.shape[0])):\n",
    "        if (file.iloc[i,0] == 1 or file.iloc[i,0] == 0):\n",
    "            reward_0.append(int(file.iloc[i,yellow_index]))\n",
    "            reward_1.append(int(file.iloc[i,red_index]))\n",
    "            reward_2.append(int(file.iloc[i,blue_index]))\n",
    "            reward_3.append(int(file.iloc[i,green_index]))\n",
    "    reward_true = np.array([reward_0,reward_1,reward_2,reward_3]).transpose()\n",
    "    return reward_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewards2comparison(action,reward,reward_B,gamma):\n",
    "    comparison = []\n",
    "    com = 0\n",
    "    for i in range(len(action)):\n",
    "        if action[i]!=4:\n",
    "            comparison.append(com)\n",
    "            com = reward[i] - reward_B[i] + gamma*com\n",
    "        else:\n",
    "            comparison.append(0)\n",
    "            com = gamma*com\n",
    "    return comparison\n",
    "\n",
    "def rewards2comparison_sqrt(action,reward,reward_B,gamma):\n",
    "    comparison = []\n",
    "    com = 0\n",
    "    for i in range(len(action)):\n",
    "        if action[i]!=4:\n",
    "            if com<0:\n",
    "                comparison.append(-np.sqrt(-com))\n",
    "            else:\n",
    "                comparison.append(np.sqrt(com))\n",
    "            com = reward[i] - reward_B[i] + gamma*com\n",
    "        else:\n",
    "            comparison.append(0)\n",
    "            com = gamma*com\n",
    "    return comparison\n",
    "\n",
    "def rewards2comparison_sqrt_competition_learn(action,reward,reward_B,gamma):\n",
    "    comparison = []\n",
    "    com = 0\n",
    "    for i in range(len(action)):\n",
    "        if action[i]!=4:\n",
    "            com = reward[i] - reward_B[i] + gamma*com\n",
    "            if com<0:\n",
    "                comparison.append(-np.sqrt(-com))\n",
    "            else:\n",
    "                comparison.append(np.sqrt(com))\n",
    "        else:\n",
    "            comparison.append(0)\n",
    "            com = gamma*com\n",
    "    return comparison\n",
    "\n",
    "def subjective_normative():\n",
    "    # subjects = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32]\n",
    "    subjects = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    \n",
    "    v_subjective = []\n",
    "    v_normative = []\n",
    "    v_true = []\n",
    "    uncer_subject = []\n",
    "    uncer_normative = []\n",
    "    \n",
    "    regression_reward = []\n",
    "    regression_playerb = []\n",
    "    regression_comparison = []\n",
    "    \n",
    "    arm = []\n",
    "    for s in subjects:\n",
    "        action,reward,reward_B,_,expect_arm,expect_reward,expect_confidence,ask =read_data_task2(s)\n",
    "        reward_true = read_true_reward_distribution(s)\n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        v_subjective_sub = []\n",
    "        v_normative_sub = []\n",
    "        v_true_sub = []\n",
    "        uncer_subject_sub = []\n",
    "        uncer_normative_sub = []\n",
    "        regression_reward_sub = []\n",
    "        regression_comparison_sub = []\n",
    "        expect_arm_sub = []\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                if ask[t]!=2 :\n",
    "                    v_normative_sub.append(v)\n",
    "                    uncer_normative_sub.append(sig)\n",
    "                    v_true_sub.append(reward_true[t])\n",
    "                    regression_reward_sub.append(reward[t])\n",
    "                    regression_comparison_sub.append(comparision[t])\n",
    "                    \n",
    "                    \n",
    "                    v_subjective_sub.append(expect_reward[t])\n",
    "                    uncer_subject_sub.append(1/expect_confidence[t])\n",
    "                    expect_arm_sub.append(expect_arm[t])\n",
    "                \n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        v_subjective.append(v_subjective_sub)\n",
    "        v_normative.append(v_normative_sub)\n",
    "        v_true.append(v_true_sub)\n",
    "        uncer_subject.append(uncer_subject_sub)\n",
    "        uncer_normative.append(uncer_normative_sub)\n",
    "        \n",
    "        arm.append(expect_arm_sub)\n",
    "        \n",
    "        regression_reward.append(regression_reward_sub)\n",
    "\n",
    "        regression_comparison.append(regression_comparison_sub)\n",
    "    return v_subjective,v_normative,v_true,uncer_subject,uncer_normative,regression_reward,regression_playerb,regression_comparison,arm\n",
    "\n",
    "def subjective_true():\n",
    "    subjects = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    \n",
    "    v_subjective = []\n",
    "    v_normative = []\n",
    "    v_true = []\n",
    "    regression_comparison = []\n",
    "    \n",
    "    arm = []\n",
    "    for s in subjects:\n",
    "        action,reward,reward_B,_,expect_arm,expect_reward,expect_confidence,ask =read_data_task2(s)\n",
    "        reward_true = read_true_reward_distribution(s)\n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        \n",
    "        v_subjective_sub = []\n",
    "        v_normative_sub = []\n",
    "        v_true_sub = []\n",
    "\n",
    "        regression_comparison_sub = []\n",
    "        expect_arm_sub = []\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                \n",
    "                if ask[t]!=1 and ask[t]!=2:\n",
    "                    v_normative_sub.append(v)\n",
    "                    v_true_sub.append(reward_true[t])\n",
    "                    v_subjective_sub.append(expect_reward[t])\n",
    "                    regression_comparison_sub.append(comparision[t])\n",
    "                    expect_arm_sub.append(expect_arm[t])             \n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        v_subjective.append(v_subjective_sub)\n",
    "        v_normative.append(v_normative_sub)\n",
    "        v_true.append(v_true_sub)\n",
    "        \n",
    "        arm.append(expect_arm_sub)\n",
    "        regression_comparison.append(regression_comparison_sub)\n",
    "    return v_subjective,v_true,regression_comparison,arm\n",
    "\n",
    "def subjective_true_random():\n",
    "    subjects = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    \n",
    "    v_subjective = []\n",
    "    v_normative = []\n",
    "    v_true = []\n",
    "    regression_comparison = []\n",
    "    \n",
    "    arm = []\n",
    "    for s in subjects:\n",
    "        action,reward,reward_B,_,expect_arm,expect_reward,expect_confidence,ask =read_data_task2(s)\n",
    "        reward_true = read_true_reward_distribution(s)\n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        \n",
    "        v_subjective_sub = []\n",
    "        v_normative_sub = []\n",
    "        v_true_sub = []\n",
    "\n",
    "        regression_comparison_sub = []\n",
    "        expect_arm_sub = []\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "                \n",
    "                if ask[t]!=0 and ask[t]!=2:\n",
    "                    v_normative_sub.append(v)\n",
    "                    v_true_sub.append(reward_true[t])\n",
    "                    v_subjective_sub.append(expect_reward[t])\n",
    "                    regression_comparison_sub.append(comparision[t])\n",
    "                    expect_arm_sub.append(expect_arm[t])             \n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        v_subjective.append(v_subjective_sub)\n",
    "        v_normative.append(v_normative_sub)\n",
    "        v_true.append(v_true_sub)\n",
    "        \n",
    "        arm.append(expect_arm_sub)\n",
    "        regression_comparison.append(regression_comparison_sub)\n",
    "    return v_subjective,v_true,regression_comparison,arm\n",
    "\n",
    "def happiness_reward():\n",
    "    subjects = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    Reward = []\n",
    "    Reward_b = []\n",
    "    Happiness = []\n",
    "    for s in subjects:\n",
    "        action,reward,reward_B,happiness = read_data_task2_happiness(s)\n",
    "        Reward.append(reward)\n",
    "        Reward_b.append(reward_B)\n",
    "        Happiness.append(happiness)\n",
    "    return Reward,Reward_b,Happiness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward,reward_B,happiness = happiness_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_r = []\n",
    "beta_r_b = []\n",
    "subjects = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,\n",
    "            46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61]\n",
    "for j in subjects:\n",
    "    happy = happiness[j]\n",
    "    r = reward[j]\n",
    "    r_b = reward_B[j]\n",
    "    data = {'happy':happy,'r':r,'r_b':r_b}\n",
    "    data = pd.DataFrame(data)\n",
    "    lm = ols('happy ~ r + r_b',data=data).fit()\n",
    "    beta_r.append(lm.params['r'])\n",
    "    beta_r_b.append(lm.params['r_b'])\n",
    "    # if lm.pvalues['r']<=0.05:\n",
    "    #     beta_r.append(lm.params['r'])\n",
    "    # if lm.pvalues['r_b']<=0.05:\n",
    "        # beta_r_b.append(lm.params['r_b'])\n",
    "        \n",
    "        \n",
    "# data = {'happiness':happy,'r':r,'r_b':r_b}\n",
    "# data = pd.DataFrame(data)\n",
    "# lm = ols('happy ~ r + r_b',data=data).fit()\n",
    "# lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all\n",
    "beta_r_task1 = [0.054200900755109804, 0.016928377355788, 0.054129272015211914, 0.03842224749864165, 0.09002636807914127, 0.08322765628353507, 0.0857949338894024, 0.017004220187376812, 0.10604751139645588, 0.045818030904746405, 0.1459860809613021, 0.0845284684187779, 0.012282640332357927, 0.06336002820330605, 0.0317633626983589, 0.034796115148707715, 0.06678597409903697, 0.07376262509263383, 0.09218386855926215, 0.03289925546939472, 0.053997156861578154, 0.05473467285118387, 0.021508180747108224, -0.009154385385404239, 0.05683374230580252, 0.03316011601374983, 0.05257124041782069, 0.06507508608603171, 0.05444568842565955, 0.09748031073703235, 0.05994802385441444, 0.09269968360969606, 0.06602327181641561, 0.05988044621726425, 0.07749734707628962, 0.06453865311400292, 0.07210695956645766, 0.03550021717954521, 0.08254882303799611, 0.02107492300382408, 0.07421690058278622, 0.061149237147041735, 0.11502487407834072, 0.0880829196711449, 0.09160573273206696, 0.059362926235522515]\n",
    "beta_r_b_task1 = [-0.06154415675316256, -0.02973334723060366, -0.04548800912073197, -0.039149020950217585, -0.07909018904860879, -0.06736666759647811, -0.08041273932038125, -0.014562683008340526, -0.08308311656004588, -0.039974446162977885, -0.061546915364747, -0.05023060201389075, -0.017279109531628718, -0.04202876413316782, -0.018633254572803456, -0.03796790748094179, -0.008862316608134104, -0.060188035466495655, 0.024358991855473286, 0.009604762514747687, -0.03419591258550405, -0.029636295956225592, -0.026066048556814332, 0.013157280874847802, -0.03137498155843436, -0.015986761405698456, -0.06342845532852674, -0.06301888085740522, -0.031102603680815646, -0.05663270771071374, -8.51697158008478e-05, -0.06597728281631379, -0.062470063361421864, -0.022735347707345758, -0.030369069290405032, -0.06197134726857786, -0.024545047017916783, -0.0026962011438785363, -0.03487805471192636, 0.031044242134733557, -0.03165186165850915, -0.042788277228797605, -0.05178717024484023, -0.08114467706111923, -0.06598847059245964, -0.005684238179156698]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p<=0.05\n",
    "beta_r_task1 = [0.054200900755109804, 0.016928377355788, 0.054129272015211914, 0.03842224749864165, 0.09002636807914127, 0.08322765628353507, 0.0857949338894024, 0.017004220187376812, 0.10604751139645588, 0.045818030904746405, 0.1459860809613021, 0.0845284684187779, 0.012282640332357927, 0.06336002820330605, 0.0317633626983589, 0.034796115148707715, 0.06678597409903697, 0.07376262509263383, 0.09218386855926215, 0.03289925546939472, 0.053997156861578154, 0.05473467285118387, 0.021508180747108224, 0.05683374230580252, 0.03316011601374983, 0.05257124041782069, 0.06507508608603171, 0.05444568842565955, 0.09748031073703235, 0.05994802385441444, 0.09269968360969606, 0.06602327181641561, 0.05988044621726425, 0.07749734707628962, 0.06453865311400292, 0.07210695956645766, 0.03550021717954521, 0.08254882303799611, 0.02107492300382408, 0.07421690058278622, 0.061149237147041735, 0.11502487407834072, 0.0880829196711449, 0.09160573273206696, 0.059362926235522515]\n",
    "beta_r_b_task1 = [-0.06154415675316256, -0.02973334723060366, -0.04548800912073197, -0.039149020950217585, -0.07909018904860879, -0.06736666759647811, -0.08041273932038125, -0.014562683008340526, -0.08308311656004588, -0.039974446162977885, -0.061546915364747, -0.05023060201389075, -0.017279109531628718, -0.04202876413316782, -0.018633254572803456, -0.03796790748094179, -0.060188035466495655, 0.024358991855473286, -0.03419591258550405, -0.029636295956225592, -0.026066048556814332, 0.013157280874847802, -0.03137498155843436, -0.015986761405698456, -0.06342845532852674, -0.06301888085740522, -0.031102603680815646, -0.05663270771071374, -0.06597728281631379, -0.062470063361421864, -0.022735347707345758, -0.030369069290405032, -0.06197134726857786, -0.024545047017916783, -0.03487805471192636, 0.031044242134733557, -0.03165186165850915, -0.042788277228797605, -0.05178717024484023, -0.08114467706111923, -0.06598847059245964]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward,reward_B,happiness = happiness_reward()\n",
    "beta_r = []\n",
    "beta_c = []\n",
    "subjects = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,\n",
    "            46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61]\n",
    "for j in subjects:\n",
    "    happy = happiness[j]\n",
    "    r = reward[j]\n",
    "    c= []\n",
    "    for i in range(len(reward[j])):\n",
    "        c.append(reward[j][i]-reward_B[j][i])\n",
    "    data = {'happy':happy,'r':r,'c':c}\n",
    "    data = pd.DataFrame(data)\n",
    "    lm = ols('happy ~ r + c',data=data).fit()\n",
    "    # beta_r.append(lm.params['r'])\n",
    "    # beta_c.append(lm.params['c'])\n",
    "    if lm.pvalues['r']<=0.05:\n",
    "        beta_r.append(lm.params['r'])\n",
    "    if lm.pvalues['c']<=0.05:\n",
    "        beta_c.append(lm.params['c'])\n",
    "data = {'happiness':happy,'r':r,'c':c}\n",
    "# data = pd.DataFrame(data)\n",
    "# lm = ols('happy ~ r + r_b',data=data).fit()\n",
    "# lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward,reward_B,happiness = happiness_reward()\n",
    "beta_r = []\n",
    "subjects = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,\n",
    "            46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61]\n",
    "for j in subjects:\n",
    "    happy = happiness[j]\n",
    "    r = reward[j]\n",
    "    data = {'happy':happy,'r':r}\n",
    "    data = pd.DataFrame(data)\n",
    "    lm = ols('happy ~ r',data=data).fit()\n",
    "    # beta_r.append(lm.params['r'])\n",
    "    if lm.pvalues['r']<=0.05:\n",
    "        beta_r.append(lm.params['r'])\n",
    "# data = pd.DataFrame(data)\n",
    "# lm = ols('happy ~ r + r_b',data=data).fit()\n",
    "# lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward,reward_B,happiness = happiness_reward()\n",
    "beta_c = []\n",
    "subjects = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,\n",
    "            46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61]\n",
    "for j in subjects:\n",
    "    happy = happiness[j]\n",
    "    c= []\n",
    "    for i in range(len(reward[j])):\n",
    "        c.append(reward[j][i]-reward_B[j][i])\n",
    "    data = {'happy':happy,'c':c}\n",
    "    data = pd.DataFrame(data)\n",
    "    lm = ols('happy ~ c',data=data).fit()\n",
    "    # beta_r.append(lm.params['r'])\n",
    "    # beta_c.append(lm.params['c'])\n",
    "    if lm.pvalues['c']<=0.05:\n",
    "        beta_c.append(lm.params['c'])\n",
    "# data = pd.DataFrame(data)\n",
    "# lm = ols('happy ~ r + r_b',data=data).fit()\n",
    "# lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all\n",
    "beta_r_task1 = [-0.007343255998052816, -0.012804969874815645, 0.008641262894479914, -0.0007267734515759641, 0.010936179030532556, 0.015860988687056717, 0.005382194569021203, 0.0024415371790362256, 0.022964394836410013, 0.0058435847417685535, 0.08443916559655519, 0.03429786640488712, -0.004996469199270761, 0.021331264070138238, 0.01313010812555547, -0.003171792332234062, 0.057923657490902995, 0.01357458962613814, 0.11654286041473529, 0.0425040179841424, 0.01980124427607409, 0.025098376894958266, -0.004557867809706083, 0.004002895489443627, 0.02545876074736814, 0.01717335460805135, -0.010857214910706124, 0.0020562052286265927, 0.023343084744843888, 0.040847603026318645, 0.05986285413861356, 0.02672240079338139, 0.0035532084549937002, 0.03714509850991847, 0.04712827778588459, 0.0025673058454251446, 0.04756191254854096, 0.03280401603566673, 0.047670768326069694, 0.05211916513855763, 0.04256503892427707, 0.01836095991824411, 0.06323770383350057, 0.0069382426100257615, 0.025617262139607362, 0.05367868805636586, -0.0001848416502321249, 0.0047556323998691665, 0.005219187736138395, 0.007898398439044576, 0.006528245847602866, -0.017566604870757643, 0.06509078637712826, 0.05678037982803379, -0.0014651819921018142, 0.05707680836613902, 0.02657192758619595, -0.022972181511582743, 0.002685085107420224, 0.008722144111164109]\n",
    "beta_c_task1 = [0.061544156753162584, 0.029733347230603675, 0.0454880091207321, 0.03914902095021758, 0.07909018904860876, 0.06736666759647816, 0.08041273932038132, 0.014562683008340554, 0.0830831165600458, 0.039974446162977836, 0.061546915364746914, 0.05023060201389076, 0.01727910953162866, 0.04202876413316782, 0.018633254572803556, 0.037967907480941726, 0.008862316608133997, 0.06018803546649567, -0.024358991855473206, -0.009604762514747657, 0.03419591258550402, 0.029636295956225585, 0.02606604855681437, -0.01315728087484782, 0.031374981558434364, 0.01598676140569852, 0.06342845532852685, 0.06301888085740517, 0.031102603680815622, 0.056632707710713666, 8.516971580090332e-05, 0.06597728281631418, 0.06247006336142182, 0.02273534770734579, 0.03036906929040489, 0.061971347268577774, 0.024545047017916738, 0.0026962011438785224, 0.034878054711926315, -0.031044242134733533, 0.03165186165850915, 0.042788277228797626, 0.05178717024484033, 0.0811446770611191, 0.0659884705924598, 0.005684238179156691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p<=0.05\n",
    "beta_r_task1 = [0.015860988687056717, 0.022964394836410013, 0.08443916559655519, 0.03429786640488712, 0.021331264070138238, 0.057923657490902995, 0.01357458962613814, 0.11654286041473529, 0.0425040179841424, 0.01980124427607409, 0.025098376894958266, 0.02545876074736814, 0.01717335460805135, 0.023343084744843888, 0.040847603026318645, 0.05986285413861356, 0.02672240079338139, 0.03714509850991847, 0.04712827778588459, 0.04756191254854096, 0.03280401603566673, 0.047670768326069694, 0.05211916513855763, 0.04256503892427707, 0.06323770383350057, 0.025617262139607362, 0.05367868805636586, 0.06509078637712826, 0.05678037982803379, 0.05707680836613902, 0.02657192758619595]\n",
    "beta_c_task1 = [0.061544156753162584, 0.029733347230603675, 0.0454880091207321, 0.03914902095021758, 0.07909018904860876, 0.06736666759647816, 0.08041273932038132, 0.014562683008340554, 0.0830831165600458, 0.039974446162977836, 0.061546915364746914, 0.05023060201389076, 0.01727910953162866, 0.04202876413316782, 0.018633254572803556, 0.037967907480941726, 0.06018803546649567, -0.024358991855473206, 0.03419591258550402, 0.029636295956225585, 0.02606604855681437, -0.01315728087484782, 0.031374981558434364, 0.01598676140569852, 0.06342845532852685, 0.06301888085740517, 0.031102603680815622, 0.056632707710713666, 0.06597728281631418, 0.06247006336142182, 0.02273534770734579, 0.03036906929040489, 0.061971347268577774, 0.024545047017916738, 0.034878054711926315, -0.031044242134733533, 0.03165186165850915, 0.042788277228797626, 0.05178717024484033, 0.0811446770611191, 0.0659884705924598]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single varible p<=0.05\n",
    "beta_r_task1 = [0.05594754822369834, 0.02504336935358145, 0.06690377516044907, 0.0388828959080581, 0.09255547602004294, 0.08880143281330995, 0.09091213266941846, 0.019048905560238045, 0.09877500563249703, 0.047862580278879185, 0.14287661721076234, 0.07033924037352855, 0.012393383640115281, 0.07112573941204262, 0.029896833357214506, 0.03040620345846431, 0.06744041201444849, 0.067045238100532, 0.09460612108034946, 0.03368003544773852, 0.05756612145782165, 0.05407755408085139, 0.021072608827927698, 0.054150242243017566, 0.03162031427404478, 0.06797391613464653, 0.07208273199078631, 0.05767286619285421, 0.10501010039871983, 0.05993887796112641, 0.08778148514955975, 0.06529787606929294, 0.05983590582440814, 0.07324004226529536, 0.05853356718001686, 0.07873221477668739, 0.03535113395173634, 0.07984430620240418, 0.02215816355027089, 0.08012732810614097, 0.0625173018992201, 0.11227078583127276, 0.08486894991146042, 0.10204477536995205, 0.0594998585394989]\n",
    "beta_b_task1 = [0.054200900755109804, 0.016928377355788, 0.054129272015211914, 0.03842224749864165, 0.09002636807914127, 0.08322765628353507, 0.0857949338894024, 0.017004220187376812, 0.10604751139645588, 0.045818030904746405, 0.1459860809613021, 0.0845284684187779, 0.012282640332357927, 0.06336002820330605, 0.0317633626983589, 0.034796115148707715, 0.06678597409903697, 0.07376262509263383, 0.09218386855926215, 0.03289925546939472, 0.053997156861578154, 0.05473467285118387, 0.021508180747108224, -0.009154385385404239, 0.05683374230580252, 0.03316011601374983, 0.05257124041782069, 0.06507508608603171, 0.05444568842565955, 0.09748031073703235, 0.05994802385441444, 0.09269968360969606, 0.06602327181641561, 0.05988044621726425, 0.07749734707628962, 0.06453865311400292, 0.07210695956645766, 0.03550021717954521, 0.08254882303799611, 0.02107492300382408, 0.07421690058278622, 0.061149237147041735, 0.11502487407834072, 0.0880829196711449, 0.09160573273206696, 0.059362926235522515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all beta_r beta_b\n",
    "beta_r_task1 = [0.054200900755109804, 0.016928377355788, 0.054129272015211914, 0.03842224749864165, 0.09002636807914127, 0.08322765628353507, 0.0857949338894024, 0.017004220187376812, 0.10604751139645588, 0.045818030904746405, 0.1459860809613021, 0.0845284684187779, 0.012282640332357927, 0.06336002820330605, 0.0317633626983589, 0.034796115148707715, 0.06678597409903697, 0.07376262509263383, 0.09218386855926215, 0.03289925546939472, 0.053997156861578154, 0.05473467285118387, 0.021508180747108224, -0.009154385385404239, 0.05683374230580252, 0.03316011601374983, 0.05257124041782069, 0.06507508608603171, 0.05444568842565955, 0.09748031073703235, 0.05994802385441444, 0.09269968360969606, 0.06602327181641561, 0.05988044621726425, 0.07749734707628962, 0.06453865311400292, 0.07210695956645766, 0.03550021717954521, 0.08254882303799611, 0.02107492300382408, 0.07421690058278622, 0.061149237147041735, 0.11502487407834072, 0.0880829196711449, 0.09160573273206696, 0.059362926235522515, 0.04948312192391225, 0.02916342468746113, 0.018973158637804285, 0.04397415333341222, 0.051588662475751265, 0.08977257118040534, 0.09370212507016781, 0.08656664093560895, 0.10944172592928887, 0.09634365628483142, 0.05167562395019069, 0.08717760498980447, 0.06458034389582372, 0.05446492167414249]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single varible all\n",
    "beta_r_task1 = [0.05594754822369834, 0.02504336935358145, 0.06690377516044907, 0.0388828959080581, 0.09255547602004294, 0.08880143281330995, 0.09091213266941846, 0.019048905560238045, 0.09877500563249703, 0.047862580278879185, 0.14287661721076234, 0.07033924037352855, 0.012393383640115281, 0.07112573941204262, 0.029896833357214506, 0.03040620345846431, 0.06744041201444849, 0.067045238100532, 0.09460612108034946, 0.03368003544773852, 0.05756612145782165, 0.05407755408085139, 0.021072608827927698, -0.0070652635893518785, 0.054150242243017566, 0.03162031427404478, 0.06797391613464653, 0.07208273199078631, 0.05767286619285421, 0.10501010039871983, 0.05993887796112641, 0.08778148514955975, 0.06529787606929294, 0.05983590582440814, 0.07324004226529536, 0.05853356718001686, 0.07873221477668739, 0.03535113395173634, 0.07984430620240418, 0.02215816355027089, 0.08012732810614097, 0.0625173018992201, 0.11227078583127276, 0.08486894991146042, 0.10204477536995205, 0.0594998585394989]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_value(arrA, arrB):\n",
    "    a = np.array(arrA)\n",
    "    b = np.array(arrB)\n",
    "    t, p = stats.ttest_ind(a,b)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.177817849369797e-06\n"
     ]
    }
   ],
   "source": [
    "print(get_p_value(beta_r, beta_r_task1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward,reward_B,happiness = happiness_reward()\n",
    "beta_r = []\n",
    "subjects = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,\n",
    "            46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61]\n",
    "for j in subjects:\n",
    "    happy = happiness[j]\n",
    "    r = reward[j]\n",
    "    data = {'happy':happy,'r':r}\n",
    "    data = pd.DataFrame(data)\n",
    "    lm = ols('happy ~ r',data=data).fit()\n",
    "    # beta_r.append(lm.params['r'])\n",
    "    if lm.pvalues['r']<=0.05:\n",
    "        beta_r.append(lm.params['r'])\n",
    "# data = pd.DataFrame(data)\n",
    "# lm = ols('happy ~ r + r_b',data=data).fit()\n",
    "# lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.05594754822369834, 0.02504336935358145, 0.06690377516044907, 0.0388828959080581, 0.09255547602004294, 0.08880143281330995, 0.09091213266941846, 0.019048905560238045, 0.09877500563249703, 0.047862580278879185, 0.14287661721076234, 0.07033924037352855, 0.012393383640115281, 0.07112573941204262, 0.029896833357214506, 0.03040620345846431, 0.06744041201444849, 0.067045238100532, 0.09460612108034946, 0.03368003544773852, 0.05756612145782165, 0.05407755408085139, 0.021072608827927698, 0.054150242243017566, 0.03162031427404478, 0.06797391613464653, 0.07208273199078631, 0.05767286619285421, 0.10501010039871983, 0.05993887796112641, 0.08778148514955975, 0.06529787606929294, 0.05983590582440814, 0.07324004226529536, 0.05853356718001686, 0.07873221477668739, 0.03535113395173634, 0.07984430620240418, 0.02215816355027089, 0.08012732810614097, 0.0625173018992201, 0.11227078583127276, 0.08486894991146042, 0.10204477536995205, 0.0594998585394989, 0.04524243269075282, 0.027250451307349093, 0.022183889913286802, 0.0505107277259176, 0.05166424281807469, 0.09515651572887589, 0.0914956125975743, 0.08168826835653717, 0.10707922104163767, 0.09183290621365339, 0.054970644053264225, 0.09123144659057483, 0.07511158431871415, 0.053771593628966066]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1114655837421971\n"
     ]
    }
   ],
   "source": [
    "print(get_p_value(beta_r, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05822307298622761\n",
      "0.6926876575160936\n"
     ]
    }
   ],
   "source": [
    "print(get_p_value(beta_r, beta_r_task1))\n",
    "print(get_p_value(beta_c, beta_c_task1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06828298170951579\n",
      "0.6926876575160932\n"
     ]
    }
   ],
   "source": [
    "print(get_p_value(beta_r, beta_r_task1))\n",
    "print(get_p_value(beta_r_b, beta_r_b_task1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>happy</td>      <th>  R-squared:         </th> <td>   0.425</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.424</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1231.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 27 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:32:07</td>     <th>  Log-Likelihood:    </th> <td> -5859.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3339</td>      <th>  AIC:               </th> <td>1.173e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3336</td>      <th>  BIC:               </th> <td>1.174e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.7672</td> <td>    0.125</td> <td>   22.222</td> <td> 0.000</td> <td>    2.523</td> <td>    3.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>r</th>         <td>    0.0655</td> <td>    0.002</td> <td>   43.589</td> <td> 0.000</td> <td>    0.063</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>c</th>         <td>   -0.0380</td> <td>    0.002</td> <td>  -24.122</td> <td> 0.000</td> <td>   -0.041</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.438</td> <th>  Durbin-Watson:     </th> <td>   1.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.109</td> <th>  Jarque-Bera (JB):  </th> <td>   4.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.088</td> <th>  Prob(JB):          </th> <td>   0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.028</td> <th>  Cond. No.          </th> <td>    418.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  happy   R-squared:                       0.425\n",
       "Model:                            OLS   Adj. R-squared:                  0.424\n",
       "Method:                 Least Squares   F-statistic:                     1231.\n",
       "Date:                Mon, 27 Mar 2023   Prob (F-statistic):               0.00\n",
       "Time:                        14:32:07   Log-Likelihood:                -5859.9\n",
       "No. Observations:                3339   AIC:                         1.173e+04\n",
       "Df Residuals:                    3336   BIC:                         1.174e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.7672      0.125     22.222      0.000       2.523       3.011\n",
       "r              0.0655      0.002     43.589      0.000       0.063       0.068\n",
       "c             -0.0380      0.002    -24.122      0.000      -0.041      -0.035\n",
       "==============================================================================\n",
       "Omnibus:                        4.438   Durbin-Watson:                   1.097\n",
       "Prob(Omnibus):                  0.109   Jarque-Bera (JB):                4.392\n",
       "Skew:                          -0.088   Prob(JB):                        0.111\n",
       "Kurtosis:                       3.028   Cond. No.                         418.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = []\n",
    "c = []\n",
    "happy = []\n",
    "subjects = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,\n",
    "            46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61]\n",
    "for j in subjects:\n",
    "    subject = j\n",
    "    for i in range(len(happiness[subject])):\n",
    "        r.append(reward[subject][i])\n",
    "        c.append(reward_B[subject][i])\n",
    "        happy.append(happiness[subject][i])\n",
    "data = {'happiness':happy,'r':r,'c':c}\n",
    "data = pd.DataFrame(data)\n",
    "lm = ols('happy ~ r + c',data=data).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>happy</td>      <th>  R-squared:         </th> <td>   0.425</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.424</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1231.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 27 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:28:49</td>     <th>  Log-Likelihood:    </th> <td> -5859.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3339</td>      <th>  AIC:               </th> <td>1.173e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3336</td>      <th>  BIC:               </th> <td>1.174e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.7672</td> <td>    0.125</td> <td>   22.222</td> <td> 0.000</td> <td>    2.523</td> <td>    3.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>r</th>         <td>    0.0655</td> <td>    0.002</td> <td>   43.589</td> <td> 0.000</td> <td>    0.063</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>r_b</th>       <td>   -0.0380</td> <td>    0.002</td> <td>  -24.122</td> <td> 0.000</td> <td>   -0.041</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.438</td> <th>  Durbin-Watson:     </th> <td>   1.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.109</td> <th>  Jarque-Bera (JB):  </th> <td>   4.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.088</td> <th>  Prob(JB):          </th> <td>   0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.028</td> <th>  Cond. No.          </th> <td>    418.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  happy   R-squared:                       0.425\n",
       "Model:                            OLS   Adj. R-squared:                  0.424\n",
       "Method:                 Least Squares   F-statistic:                     1231.\n",
       "Date:                Mon, 27 Mar 2023   Prob (F-statistic):               0.00\n",
       "Time:                        14:28:49   Log-Likelihood:                -5859.9\n",
       "No. Observations:                3339   AIC:                         1.173e+04\n",
       "Df Residuals:                    3336   BIC:                         1.174e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.7672      0.125     22.222      0.000       2.523       3.011\n",
       "r              0.0655      0.002     43.589      0.000       0.063       0.068\n",
       "r_b           -0.0380      0.002    -24.122      0.000      -0.041      -0.035\n",
       "==============================================================================\n",
       "Omnibus:                        4.438   Durbin-Watson:                   1.097\n",
       "Prob(Omnibus):                  0.109   Jarque-Bera (JB):                4.392\n",
       "Skew:                          -0.088   Prob(JB):                        0.111\n",
       "Kurtosis:                       3.028   Cond. No.                         418.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = []\n",
    "r_b = []\n",
    "happy = []\n",
    "subjects = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,\n",
    "            46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61]\n",
    "for j in subjects:\n",
    "    subject = j\n",
    "    for i in range(len(happiness[subject])):\n",
    "        r.append(reward[subject][i])\n",
    "        r_b.append(reward_B[subject][i])\n",
    "        happy.append(happiness[subject][i])\n",
    "data = {'happiness':happy,'r':r,'r_b':r_b}\n",
    "data = pd.DataFrame(data)\n",
    "lm = ols('happy ~ r + r_b',data=data).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  1  n_wrong:  0\n",
      "subject:  2  n_wrong:  0\n",
      "subject:  3  n_wrong:  0\n",
      "subject:  4  n_wrong:  0\n",
      "subject:  5  n_wrong:  3\n",
      "subject:  7  n_wrong:  0\n",
      "subject:  8  n_wrong:  1\n",
      "subject:  9  n_wrong:  0\n",
      "subject:  10  n_wrong:  0\n",
      "subject:  11  n_wrong:  0\n",
      "subject:  12  n_wrong:  0\n",
      "subject:  13  n_wrong:  0\n",
      "subject:  14  n_wrong:  0\n",
      "subject:  15  n_wrong:  0\n",
      "subject:  16  n_wrong:  0\n",
      "subject:  17  n_wrong:  0\n",
      "subject:  18  n_wrong:  0\n",
      "subject:  19  n_wrong:  0\n",
      "subject:  20  n_wrong:  0\n",
      "subject:  21  n_wrong:  0\n",
      "subject:  22  n_wrong:  0\n",
      "subject:  23  n_wrong:  0\n",
      "subject:  24  n_wrong:  0\n",
      "subject:  25  n_wrong:  0\n",
      "subject:  26  n_wrong:  0\n",
      "subject:  27  n_wrong:  0\n",
      "subject:  28  n_wrong:  0\n",
      "subject:  29  n_wrong:  0\n",
      "subject:  30  n_wrong:  0\n",
      "subject:  31  n_wrong:  0\n",
      "subject:  32  n_wrong:  0\n",
      "subject:  33  n_wrong:  0\n",
      "subject:  34  n_wrong:  0\n",
      "subject:  35  n_wrong:  0\n",
      "subject:  37  n_wrong:  0\n",
      "subject:  38  n_wrong:  0\n",
      "subject:  39  n_wrong:  0\n",
      "subject:  40  n_wrong:  0\n",
      "subject:  41  n_wrong:  0\n",
      "subject:  42  n_wrong:  0\n",
      "subject:  43  n_wrong:  0\n",
      "subject:  44  n_wrong:  0\n",
      "subject:  45  n_wrong:  0\n",
      "subject:  46  n_wrong:  0\n",
      "subject:  47  n_wrong:  0\n",
      "subject:  48  n_wrong:  0\n",
      "subject:  49  n_wrong:  0\n",
      "subject:  50  n_wrong:  0\n",
      "subject:  51  n_wrong:  0\n",
      "subject:  52  n_wrong:  0\n",
      "subject:  53  n_wrong:  0\n",
      "subject:  54  n_wrong:  0\n",
      "subject:  55  n_wrong:  0\n",
      "subject:  56  n_wrong:  0\n",
      "subject:  57  n_wrong:  0\n",
      "subject:  58  n_wrong:  0\n",
      "subject:  59  n_wrong:  0\n",
      "subject:  60  n_wrong:  0\n",
      "subject:  61  n_wrong:  0\n",
      "subject:  62  n_wrong:  0\n",
      "subject:  63  n_wrong:  0\n",
      "subject:  64  n_wrong:  0\n"
     ]
    }
   ],
   "source": [
    "v_subjective,v_normative,v_true,uncer_subject,uncer_normative,regression_reward,regression_playerb,regression_comparison,arm = subjective_normative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all subjects 'v_subjective ~ v_normative(b:0.3340 p:0.000) + comparison(b:0.0957 p:0.000)' \n",
    "# subject1  'v_subjective ~ v_normative(b:0.0278 p:0.749) + comparison(b:0.0271 p:0.768)' \n",
    "# subject2  'v_subjective ~ v_normative(b:0.4913 p:0.001) + comparison(b:0.1255 p:0.074)' \n",
    "# subject3  'v_subjective ~ v_normative(b:0.0197 p:0.866) + comparison(b:-0.120 p:0.078)' \n",
    "# subject4  'v_subjective ~ v_normative(b:0.4994 p:0.000) + comparison(b:0.0071 p:0.904)' \n",
    "# subject5  'v_subjective ~ v_normative(b:0.0182 p:0.939) + comparison(b:0.2263 p:0.071)' \n",
    "# subject6  'v_subjective ~ v_normative(b:-0.163 p:0.226) + comparison(b:-0.044 p:0.515)' \n",
    "# subject7  'v_subjective ~ v_normative(b:0.0146 p:0.957) + comparison(b:0.2535 p:0.043)' \n",
    "# subject8  'v_subjective ~ v_normative(b:0.9893 p:0.001) + comparison(b:0.2450 p:0.002)' \n",
    "# subject9  'v_subjective ~ v_normative(b:0.1831 p:0.572) + comparison(b:0.1471 p:0.183)' \n",
    "# subject10  'v_subjective ~ v_normative(b:0.3788 p:0.000) + comparison(b:-0.136 p:0.101)' \n",
    "# subject11  'v_subjective ~ v_normative(b:0.9686 p:0.000) + comparison(b:-0.018 p:0.856)' \n",
    "# subject12  'v_subjective ~ v_normative(b:0.8231 p:0.000) + comparison(b:0.1089 p:0.246)' \n",
    "# subject13  'v_subjective ~ v_normative(b:0.1358 p:0.168) + comparison(b:0.4778 p:0.000)' \n",
    "# subject14  'v_subjective ~ v_normative(b:0.6578 p:0.000) + comparison(b:0.1905 p:0.002)' \n",
    "# subject15  'v_subjective ~ v_normative(b:-0.246 p:0.011) + comparison(b:0.0362 p:0.615)' \n",
    "# subject16  'v_subjective ~ v_normative(b:0.5067 p:0.001) + comparison(b:0.0572 p:0.601)' \n",
    "# subject17  'v_subjective ~ v_normative(b:0.2033 p:0.047) + comparison(b:0.4622 p:0.000)' \n",
    "# subject18  'v_subjective ~ v_normative(b:0.1579 p:0.612) + comparison(b:0.2002 p:0.131)' \n",
    "# subject19  'v_subjective ~ v_normative(b:0.0697 p:0.617) + comparison(b:0.1252 p:0.070)'\n",
    "# subject  'v_subjective ~ v_normative(b: p:) + comparison(b: p:)' \n",
    "# subject  'v_subjective ~ v_normative(b: p:) + comparison(b: p:)' \n",
    "# subject  'v_subjective ~ v_normative(b: p:) + comparison(b: p:)' \n",
    "# subject  'v_subjective ~ v_normative(b: p:) + comparison(b: p:)' \n",
    "# subject  'v_subjective ~ v_normative(b: p:) + comparison(b: p:)' \n",
    "# subject  'v_subjective ~ v_normative(b: p:) + comparison(b: p:)' \n",
    "# subject  'v_subjective ~ v_normative(b: p:) + comparison(b: p:)' \n",
    "# subject  'v_subjective ~ v_normative(b: p:) + comparison(b: p:)' \n",
    "# subject  'v_subjective ~ v_normative(b: p:) + comparison(b: p:)' \n",
    "# subject  'v_subjective ~ v_normative(b: p:) + comparison(b: p:)' \n",
    "# subject  'v_subjective ~ v_normative(b: p:) + comparison(b: p:)' \n",
    "# subject  'v_subjective ~ v_normative(b: p:) + comparison(b: p:)' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>v_subjective</td>   <th>  R-squared:         </th> <td>   0.016</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.016</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   76.62</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 08 Apr 2023</td> <th>  Prob (F-statistic):</th> <td>2.84e-18</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:02:06</td>     <th>  Log-Likelihood:    </th> <td> -20378.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4711</td>      <th>  AIC:               </th> <td>4.076e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4709</td>      <th>  BIC:               </th> <td>4.077e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   56.7864</td> <td>    0.267</td> <td>  212.731</td> <td> 0.000</td> <td>   56.263</td> <td>   57.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>comparison</th> <td>    0.1059</td> <td>    0.012</td> <td>    8.753</td> <td> 0.000</td> <td>    0.082</td> <td>    0.130</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 8.505</td> <th>  Durbin-Watson:     </th> <td>   1.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.014</td> <th>  Jarque-Bera (JB):  </th> <td>   7.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.056</td> <th>  Prob(JB):          </th> <td>  0.0208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.836</td> <th>  Cond. No.          </th> <td>    22.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           v_subjective   R-squared:                       0.016\n",
       "Model:                            OLS   Adj. R-squared:                  0.016\n",
       "Method:                 Least Squares   F-statistic:                     76.62\n",
       "Date:                Sat, 08 Apr 2023   Prob (F-statistic):           2.84e-18\n",
       "Time:                        09:02:06   Log-Likelihood:                -20378.\n",
       "No. Observations:                4711   AIC:                         4.076e+04\n",
       "Df Residuals:                    4709   BIC:                         4.077e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     56.7864      0.267    212.731      0.000      56.263      57.310\n",
       "comparison     0.1059      0.012      8.753      0.000       0.082       0.130\n",
       "==============================================================================\n",
       "Omnibus:                        8.505   Durbin-Watson:                   1.485\n",
       "Prob(Omnibus):                  0.014   Jarque-Bera (JB):                7.747\n",
       "Skew:                          -0.056   Prob(JB):                       0.0208\n",
       "Kurtosis:                       2.836   Cond. No.                         22.1\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_subject = []\n",
    "comparison = []\n",
    "subjects = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,\n",
    "            46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61]\n",
    "for j in subjects:\n",
    "    subject = j\n",
    "    for i in range(len(v_subjective[subject])):\n",
    "        V_subject.append(v_subjective[subject][i])\n",
    "        comparison.append(regression_comparison[subject][i])\n",
    "data = {'v_subjective':V_subject,'comparison':comparison}\n",
    "data = pd.DataFrame(data)\n",
    "lm = ols('v_subjective ~ comparison',data=data).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>v_subjective</td>   <th>  R-squared:         </th> <td>   0.072</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.072</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   183.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 08 Apr 2023</td> <th>  Prob (F-statistic):</th> <td>1.61e-77</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:03:41</td>     <th>  Log-Likelihood:    </th> <td> -20239.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4711</td>      <th>  AIC:               </th> <td>4.048e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4708</td>      <th>  BIC:               </th> <td>4.050e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>   40.5297</td> <td>    0.996</td> <td>   40.709</td> <td> 0.000</td> <td>   38.578</td> <td>   42.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_normative</th> <td>    0.3095</td> <td>    0.018</td> <td>   16.912</td> <td> 0.000</td> <td>    0.274</td> <td>    0.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>comparison</th>  <td>    0.0817</td> <td>    0.012</td> <td>    6.901</td> <td> 0.000</td> <td>    0.058</td> <td>    0.105</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.099</td> <th>  Durbin-Watson:     </th> <td>   1.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.047</td> <th>  Jarque-Bera (JB):  </th> <td>   6.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.082</td> <th>  Prob(JB):          </th> <td>  0.0486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.061</td> <th>  Cond. No.          </th> <td>    209.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           v_subjective   R-squared:                       0.072\n",
       "Model:                            OLS   Adj. R-squared:                  0.072\n",
       "Method:                 Least Squares   F-statistic:                     183.6\n",
       "Date:                Sat, 08 Apr 2023   Prob (F-statistic):           1.61e-77\n",
       "Time:                        09:03:41   Log-Likelihood:                -20239.\n",
       "No. Observations:                4711   AIC:                         4.048e+04\n",
       "Df Residuals:                    4708   BIC:                         4.050e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept      40.5297      0.996     40.709      0.000      38.578      42.482\n",
       "v_normative     0.3095      0.018     16.912      0.000       0.274       0.345\n",
       "comparison      0.0817      0.012      6.901      0.000       0.058       0.105\n",
       "==============================================================================\n",
       "Omnibus:                        6.099   Durbin-Watson:                   1.503\n",
       "Prob(Omnibus):                  0.047   Jarque-Bera (JB):                6.048\n",
       "Skew:                          -0.082   Prob(JB):                       0.0486\n",
       "Kurtosis:                       3.061   Cond. No.                         209.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_subject = []\n",
    "V_normative = []\n",
    "comparison = []\n",
    "subjects = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,\n",
    "            46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61]\n",
    "for j in subjects:\n",
    "    subject = j\n",
    "    for i in range(len(v_subjective[subject])):\n",
    "        V_subject.append(v_subjective[subject][i])\n",
    "        V_normative.append(v_normative[subject][i][arm[subject][i]])\n",
    "        comparison.append(regression_comparison[subject][i])\n",
    "data = {'v_subjective':V_subject,'v_normative':V_normative,'comparison':comparison}\n",
    "data = pd.DataFrame(data)\n",
    "lm = ols('v_subjective ~ v_normative + comparison',data=data).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_subjects 'v_subjective ~ v_true(b:0.5889 p:0.000) + comparison(b:-0.005 p:0.717)' \n",
    "# subject1  'v_subjective ~ v_true(b:0.2257 p:0.073) + comparison(b:0.0153 p:0.864)' \n",
    "# subject2  'v_subjective ~ v_true(b:0.4017 p:0.000) + comparison(b:0.0513 p:0.466)' \n",
    "# subject3  'v_subjective ~ v_true(b:0.0940 p:0.491) + comparison(b:-0.124 p:0.066)' \n",
    "# subject4  'v_subjective ~ v_true(b:0.7685 p:0.000) + comparison(b:-0.049 p:0.323)' \n",
    "# subject5  'v_subjective ~ v_true(b:0.2687 p:0.115) + comparison(b:0.1812 p:0.143)' \n",
    "# subject7  'v_subjective ~ v_true(b:-0.027 p:0.771) + comparison(b:-0.047 p:0.492)' \n",
    "# subject8  'v_subjective ~ v_true(b:0.0686 p:0.726) + comparison(b:0.2489 p:0.047)' \n",
    "# subject9  'v_subjective ~ v_true(b:0.9224 p:0.000) + comparison(b:0.0004 p:0.993)' \n",
    "# subject10  'v_subjective ~ v_true(b:0.3871 p:0.004) + comparison(b:0.0675 p:0.528)' \n",
    "# subject11  'v_subjective ~ v_true(b:0.6681 p:0.000) + comparison(b:-0.114 p:0.068)' \n",
    "# subject12  'v_subjective ~ v_true(b:0.5621 p:0.000) + comparison(b:-0.060 p:0.530)' \n",
    "# subject13  'v_subjective ~ v_true(b:0.5940 p:0.000) + comparison(b:0.1392 p:0.150)' \n",
    "# subject14  'v_subjective ~ v_true(b:0.7349 p:0.000) + comparison(b:0.1877 p:0.016)' \n",
    "# subject15  'v_subjective ~ v_true(b:0.9035 p:0.000) + comparison(b:0.0737 p:0.097)' \n",
    "# subject16  'v_subjective ~ v_true(b:0.6849 p:0.000) + comparison(b:0.0079 p:0.888)' \n",
    "# subject17  'v_subjective ~ v_true(b:0.9173 p:0.000) + comparison(b:-0.042 p:0.576)' \n",
    "# subject18  'v_subjective ~ v_true(b:0.9873 p:0.000) + comparison(b:0.0851 p:0.263)' \n",
    "# subject19  'v_subjective ~ v_true(b:0.2928 p:0.259) + comparison(b:0.1976 p:0.133)' \n",
    "# subject20  'v_subjective ~ v_true(b:0.6861 p:0.000) + comparison(b:0.0749 p:0.044)' \n",
    "# subject21  'v_subjective ~ v_true(b:0.4808 p:0.000) + comparison(b:0.2859 p:0.006)' \n",
    "# subject22  'v_subjective ~ v_true(b:0.6781 p:0.000) + comparison(b:0.0003 p:0.995)' \n",
    "# subject23  'v_subjective ~ v_true(b:0.8487 p:0.000) + comparison(b:0.0706 p:0.145)' \n",
    "# subject24  'v_subjective ~ v_true(b:0.7057 p:0.000) + comparison(b:-0.014 p:0.893)' \n",
    "# subject25  'v_subjective ~ v_true(b:0.8044 p:0.000) + comparison(b:-0.012 p:0.859)' \n",
    "# subject26  'v_subjective ~ v_true(b:0.6288 p:0.000) + comparison(b:0.0618 p:0.373)' \n",
    "# subject27  'v_subjective ~ v_true(b:0.9369 p:0.000) + comparison(b:-0.100 p:0.199)' \n",
    "# subject28  'v_subjective ~ v_true(b:0.6470 p:0.000) + comparison(b:-0.060 p:0.287)' \n",
    "# subject29  'v_subjective ~ v_true(b:0.7041 p:0.000) + comparison(b:-0.029 p:0.750)' \n",
    "# subject30  'v_subjective ~ v_true(b:0.1422 p:0.141) + comparison(b:0.0238 p:0.702)' \n",
    "# subject31  'v_subjective ~ v_true(b:0.6245 p:0.000) + comparison(b:0.0170 p:0.688)' \n",
    "# subject32  'v_subjective ~ v_true(b:0.6652 p:0.000) + comparison(b:0.0018 p:0.023)' \n",
    "# subject33  'v_subjective ~ v_true(b:0.8811 p:0.000) + comparison(b:-0.060 p:0.102)' \n",
    "# subject34  'v_subjective ~ v_true(b:0.6513 p:0.000) + comparison(b:-0.006 p:0.954)' \n",
    "# subject35  'v_subjective ~ v_true(b:0.5567 p:0.009) + comparison(b:-0.073 p:0.618)' \n",
    "# subject36  'v_subjective ~ v_true(b:0.7342 p:0.000) + comparison(b:0.0252 p:0.634)' \n",
    "# subject37  'v_subjective ~ v_true(b:0.2529 p:0.076) + comparison(b:0.0157 p:0.899)' \n",
    "# subject38  'v_subjective ~ v_true(b:0.2373 p:0.139) + comparison(b:0.2040 p:0.070)' \n",
    "# subject39  'v_subjective ~ v_true(b:0.8125 p:0.000) + comparison(b:0.0331 p:0.628)' \n",
    "# subject40  'v_subjective ~ v_true(b:0.2782 p:0.010) + comparison(b:0.1324 p:0.092)' \n",
    "# subject41  'v_subjective ~ v_true(b:0.4845 p:0.000) + comparison(b:0.0089 p:0.910)' \n",
    "# subject42  'v_subjective ~ v_true(b:0.8096 p:0.000) + comparison(b:0.0328 p:0.322)' \n",
    "# subject43  'v_subjective ~ v_true(b:0.2578 p:0.183) + comparison(b:-0.026 p:0.848)' \n",
    "# subject44  'v_subjective ~ v_true(b:0.5166 p:0.000) + comparison(b:0.1101 p:0.136)' \n",
    "# subject45  'v_subjective ~ v_true(b:0.8264 p:0.000) + comparison(b:-0.364 p:0.014)' \n",
    "# subject46  'v_subjective ~ v_true(b:0.6220 p:0.011) + comparison(b:0.1915 p:0.153)' \n",
    "# subject47  'v_subjective ~ v_true(b:0.3581 p:0.005) + comparison(b:0.0177 p:0.823)' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>v_subjective</td>   <th>  R-squared:         </th> <td>   0.294</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.293</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   978.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 10 Apr 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:59:40</td>     <th>  Log-Likelihood:    </th> <td> -19597.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4711</td>      <th>  AIC:               </th> <td>3.920e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4708</td>      <th>  BIC:               </th> <td>3.922e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   23.1186</td> <td>    0.815</td> <td>   28.376</td> <td> 0.000</td> <td>   21.521</td> <td>   24.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_true</th>     <td>    0.6327</td> <td>    0.015</td> <td>   43.015</td> <td> 0.000</td> <td>    0.604</td> <td>    0.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>comparison</th> <td>   -0.0056</td> <td>    0.011</td> <td>   -0.527</td> <td> 0.598</td> <td>   -0.026</td> <td>    0.015</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>287.140</td> <th>  Durbin-Watson:     </th> <td>   1.509</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 674.939</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.376</td>  <th>  Prob(JB):          </th> <td>2.75e-147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.695</td>  <th>  Cond. No.          </th> <td>    200.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           v_subjective   R-squared:                       0.294\n",
       "Model:                            OLS   Adj. R-squared:                  0.293\n",
       "Method:                 Least Squares   F-statistic:                     978.5\n",
       "Date:                Mon, 10 Apr 2023   Prob (F-statistic):               0.00\n",
       "Time:                        22:59:40   Log-Likelihood:                -19597.\n",
       "No. Observations:                4711   AIC:                         3.920e+04\n",
       "Df Residuals:                    4708   BIC:                         3.922e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     23.1186      0.815     28.376      0.000      21.521      24.716\n",
       "v_true         0.6327      0.015     43.015      0.000       0.604       0.662\n",
       "comparison    -0.0056      0.011     -0.527      0.598      -0.026       0.015\n",
       "==============================================================================\n",
       "Omnibus:                      287.140   Durbin-Watson:                   1.509\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              674.939\n",
       "Skew:                           0.376   Prob(JB):                    2.75e-147\n",
       "Kurtosis:                       4.695   Cond. No.                         200.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_subject,V_true,comparison = [],[],[]\n",
    "subjects = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,\n",
    "            46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61]\n",
    "for j in subjects:\n",
    "    subject = j\n",
    "    for i in range(len(v_subjective[subject])):\n",
    "        V_subject.append(v_subjective[subject][i])\n",
    "        V_true.append(v_true[subject][i][arm[subject][i]])\n",
    "        comparison.append(regression_comparison[subject][i])\n",
    "data = {'v_subjective':V_subject,'v_true':V_true,'comparison':comparison}\n",
    "data = pd.DataFrame(data)\n",
    "lm = ols('v_subjective ~ v_true + comparison',data=data).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>v_di</td>       <th>  R-squared:         </th> <td>   0.009</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.009</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   41.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 10 Apr 2023</td> <th>  Prob (F-statistic):</th> <td>1.28e-10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:01:00</td>     <th>  Log-Likelihood:    </th> <td> -19890.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4711</td>      <th>  AIC:               </th> <td>3.978e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4709</td>      <th>  BIC:               </th> <td>3.980e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   -3.5722</td> <td>    0.241</td> <td>  -14.842</td> <td> 0.000</td> <td>   -4.044</td> <td>   -3.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>comparison</th> <td>    0.0703</td> <td>    0.011</td> <td>    6.444</td> <td> 0.000</td> <td>    0.049</td> <td>    0.092</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>572.664</td> <th>  Durbin-Watson:     </th> <td>   1.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1803.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.626</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.761</td>  <th>  Cond. No.          </th> <td>    22.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   v_di   R-squared:                       0.009\n",
       "Model:                            OLS   Adj. R-squared:                  0.009\n",
       "Method:                 Least Squares   F-statistic:                     41.53\n",
       "Date:                Mon, 10 Apr 2023   Prob (F-statistic):           1.28e-10\n",
       "Time:                        23:01:00   Log-Likelihood:                -19890.\n",
       "No. Observations:                4711   AIC:                         3.978e+04\n",
       "Df Residuals:                    4709   BIC:                         3.980e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -3.5722      0.241    -14.842      0.000      -4.044      -3.100\n",
       "comparison     0.0703      0.011      6.444      0.000       0.049       0.092\n",
       "==============================================================================\n",
       "Omnibus:                      572.664   Durbin-Watson:                   1.572\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1803.721\n",
       "Skew:                          -0.626   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.761   Cond. No.                         22.1\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_subject,V_true,comparison = [],[],[]\n",
    "v_di = []\n",
    "subjects = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,\n",
    "            46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61]\n",
    "for j in subjects:\n",
    "    subject = j\n",
    "    for i in range(len(v_subjective[subject])):\n",
    "        v_di.append(v_true[subject][i][arm[subject][i]]-v_subjective[subject][i])\n",
    "        # V_subject.append(v_subjective[subject][i])\n",
    "        # V_true.append(v_true[subject][i][arm[subject][i]])\n",
    "        comparison.append(regression_comparison[subject][i])\n",
    "data = {'v_di':v_di,'comparison':comparison}\n",
    "data = pd.DataFrame(data)\n",
    "lm = ols('v_di ~ comparison',data=data).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_subject ('uncer_subjective ~ uncer_normative(b:0.0039 p:0.000) + comparison(b:-0.002 p:0.000)')\n",
    "# subject1 ('uncer_subjective ~ uncer_normative(b:0.0176 p:0.093) + comparison(b:-0.001 p:0.483)')\n",
    "# subject2 ('uncer_subjective ~ uncer_normative(b:0.0000 p:0.963) + comparison(b:-0.000 p:0.497)')\n",
    "# subject3 ('uncer_subjective ~ uncer_normative(b:0.0115 p:0.000) + comparison(b:-0.001 p:0.093)')\n",
    "# subject4 ('uncer_subjective ~ uncer_normative(b:-0.000 p:0.835) + comparison(b:-0.001 p:0.000)')\n",
    "# subject5 ('uncer_subjective ~ uncer_normative(b:0.0134 p:0.000) + comparison(b:-0.002 p:0.054)')\n",
    "# subject6 ('uncer_subjective ~ uncer_normative(b:-0.004 p:0.844) + comparison(b:-0.001 p:0.162)')\n",
    "# subject7 ('uncer_subjective ~ uncer_normative(b:-0.002 p:0.097) + comparison(b:-0.000 p:0.582)')\n",
    "# subject8 ('uncer_subjective ~ uncer_normative(b:0.0098 p:0.119) + comparison(b:-0.002 p:0.006)')\n",
    "# subject9 ('uncer_subjective ~ uncer_normative(b:-0.006 p:0.584) + comparison(b:0.0051 p:0.000)')\n",
    "# subject10 ('uncer_subjective ~ uncer_normative(b:0.0004 p:0.902) + comparison(b:-0.003 p:0.000)')\n",
    "# subject11 ('uncer_subjective ~ uncer_normative(b:0.0024 p:0.002) + comparison(b:-0.000 p:0.672)')\n",
    "# subject12 ('uncer_subjective ~ uncer_normative(b:0.0043 p:0.232) + comparison(b:0.0022 p:0.006)')\n",
    "# subject13 ('uncer_subjective ~ uncer_normative(b:0.0346 p:0.000) + comparison(b:-0.001 p:0.346)')\n",
    "# subject14 ('uncer_subjective ~ uncer_normative(b:0.0026 p:0.012) + comparison(b:-0.001 p:0.029)')\n",
    "# subject15 ('uncer_subjective ~ uncer_normative(b:0.0009 p:0.060) + comparison(b:-0.000 p:0.027)')\n",
    "# subject16 ('uncer_subjective ~ uncer_normative(b:0.0002 p:0.844) + comparison(b:-0.001 p:0.094)')\n",
    "# subject17 ('uncer_subjective ~ uncer_normative(b:-0.006 p:0.476) + comparison(b:-0.001 p:0.325)')\n",
    "# subject18 ('uncer_subjective ~ uncer_normative(b:0.0032 p:0.090) + comparison(b:-0.001 p:0.011)')\n",
    "# subject19 ('uncer_subjective ~ uncer_normative(b:0.0075 p:0.631) + comparison(b:-0.001 p:0.239)')\n",
    "# subject20 ('uncer_subjective ~ uncer_normative(b:0.0211 p:0.000) + comparison(b:0.0000 p:0.750)')\n",
    "# subject ('uncer_subjective ~ uncer_normative(b: p:) + comparison(b: p:)')\n",
    "# subject ('uncer_subjective ~ uncer_normative(b: p:) + comparison(b: p:)')\n",
    "# subject ('uncer_subjective ~ uncer_normative(b: p:) + comparison(b: p:)')\n",
    "# subject ('uncer_subjective ~ uncer_normative(b: p:) + comparison(b: p:)')\n",
    "# subject ('uncer_subjective ~ uncer_normative(b: p:) + comparison(b: p:)')\n",
    "# subject ('uncer_subjective ~ uncer_normative(b: p:) + comparison(b: p:)')\n",
    "# subject ('uncer_subjective ~ uncer_normative(b: p:) + comparison(b: p:)')\n",
    "# subject ('uncer_subjective ~ uncer_normative(b: p:) + comparison(b: p:)')\n",
    "# subject ('uncer_subjective ~ uncer_normative(b: p:) + comparison(b: p:)')\n",
    "# subject ('uncer_subjective ~ uncer_normative(b: p:) + comparison(b: p:)')\n",
    "# subject ('uncer_subjective ~ uncer_normative(b: p:) + comparison(b: p:)')\n",
    "# subject ('uncer_subjective ~ uncer_normative(b: p:) + comparison(b: p:)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22741297795644677\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(u_subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0043093882684735\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(u_normative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.19863208891422\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(c_abs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>uncer_subjective</td> <th>  R-squared:         </th> <td>   0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   68.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 11 Apr 2023</td> <th>  Prob (F-statistic):</th> <td>7.39e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:39:25</td>     <th>  Log-Likelihood:    </th> <td>  871.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4711</td>      <th>  AIC:               </th> <td>  -1736.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4708</td>      <th>  BIC:               </th> <td>  -1717.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>    0.2008</td> <td>    0.005</td> <td>   37.977</td> <td> 0.000</td> <td>    0.190</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>uncer_normative</th> <td>    0.0042</td> <td>    0.001</td> <td>    4.762</td> <td> 0.000</td> <td>    0.002</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>comparison</th>      <td>   -0.0015</td> <td>    0.000</td> <td>  -11.151</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2542.976</td> <th>  Durbin-Watson:     </th> <td>   0.851</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>14381.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.662</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 9.702</td>  <th>  Cond. No.          </th> <td>    40.2</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       uncer_subjective   R-squared:                       0.028\n",
       "Model:                            OLS   Adj. R-squared:                  0.028\n",
       "Method:                 Least Squares   F-statistic:                     68.04\n",
       "Date:                Tue, 11 Apr 2023   Prob (F-statistic):           7.39e-30\n",
       "Time:                        09:39:25   Log-Likelihood:                 871.04\n",
       "No. Observations:                4711   AIC:                            -1736.\n",
       "Df Residuals:                    4708   BIC:                            -1717.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept           0.2008      0.005     37.977      0.000       0.190       0.211\n",
       "uncer_normative     0.0042      0.001      4.762      0.000       0.002       0.006\n",
       "comparison         -0.0015      0.000    -11.151      0.000      -0.002      -0.001\n",
       "==============================================================================\n",
       "Omnibus:                     2542.976   Durbin-Watson:                   0.851\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14381.138\n",
       "Skew:                           2.662   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.702   Cond. No.                         40.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_subject,u_normative,comparison,c_abs = [],[],[],[]\n",
    "subjects = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,\n",
    "            46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61]\n",
    "for j in subjects:\n",
    "    subject = j\n",
    "    for i in range(len(v_subjective[subject])):\n",
    "        u_subject.append(uncer_subject[subject][i])\n",
    "        u_normative.append(uncer_normative[subject][i][arm[subject][i]])\n",
    "        comparison.append(regression_comparison[subject][i])\n",
    "        c_abs.append(np.abs(regression_comparison[subject][i]))\n",
    "data = {'uncer_subjective':u_subject,'uncer_normative':u_normative,'comparison':comparison}\n",
    "data = pd.DataFrame(data)\n",
    "lm = ols('uncer_subjective ~ uncer_normative + comparison',data=data).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parameter_3_para(file_name):\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    para1 = []\n",
    "    para2 = []\n",
    "    para3 = []\n",
    "    for i in range(subject_num):\n",
    "        para1.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        para2.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        para3.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    para1 = np.array(para1)\n",
    "    para2 = np.array(para2)\n",
    "    para3 = np.array(para3)\n",
    "    return para1,para2,para3\n",
    "    \n",
    "def read_parameter(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    phi = []\n",
    "    persev = []\n",
    "    gamma = []\n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    beta = np.array(beta)\n",
    "    phi = np.array(phi)\n",
    "    persev = np.array(persev)\n",
    "    gamma = np.array(gamma)\n",
    "    return beta,phi,persev,gamma\n",
    "\n",
    "def read_parameter_glm_no_gamma_para(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    phi = []\n",
    "    persev = []\n",
    "    gamma = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "\n",
    "    beta = np.array(beta)\n",
    "    phi = np.array(phi)\n",
    "    persev = np.array(persev)\n",
    "    gamma = np.array(gamma)\n",
    "\n",
    "    return beta,phi,persev,gamma\n",
    "\n",
    "def read_parameter_glm_para(file_name): # read fitted parameters: beta,phi,persev,gamma\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    phi = []\n",
    "    persev = []\n",
    "    gamma = []\n",
    "    glm_a = []\n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        glm_a.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    beta = np.array(beta)\n",
    "    phi = np.array(phi)\n",
    "    persev = np.array(persev)\n",
    "    gamma = np.array(gamma)\n",
    "    glm_a = np.array(glm_a)\n",
    "    return beta,phi,persev,gamma,glm_a\n",
    "\n",
    "def read_parameter_glm_3_para(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "\n",
    "    beta_b = []\n",
    "    phi_b = []\n",
    "    persev_b = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_b.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_b.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "\n",
    "    beta_b = np.array(beta_b)\n",
    "    phi_b = np.array(phi_b)\n",
    "    persev_b = np.array(persev_b)\n",
    "\n",
    "    return beta_a,phi_a,persev_a,beta_b,phi_b,persev_b\n",
    "\n",
    "def read_parameter_glm(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "    gamma_a = []\n",
    "    beta_b = []\n",
    "    phi_b = []\n",
    "    persev_b = []\n",
    "    gamma_b = []\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_b.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_b.append(parameter_result.iloc[i+subject_num*6,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_b.append(parameter_result.iloc[i+subject_num*7,1])\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "    gamma_a = np.array(gamma_a)\n",
    "    beta_b = np.array(beta_b)\n",
    "    phi_b = np.array(phi_b)\n",
    "    persev_b = np.array(persev_b)\n",
    "    gamma_b = np.array(gamma_b)\n",
    "    return beta_a,phi_a,persev_a,gamma_a,beta_b,phi_b,persev_b,gamma_b\n",
    "\n",
    "def read_parameter_sup(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "    gamma_a = []\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "    gamma_a = np.array(gamma_a)\n",
    "    return beta_a,phi_a,persev_a,gamma_a\n",
    "\n",
    "def read_parameter_sup_dual(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "    gamma_a = []\n",
    "    beta_b = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "    gamma_a = np.array(gamma_a)\n",
    "    beta_b = np.array(beta_b)\n",
    "    return beta_a,phi_a,persev_a,gamma_a,beta_b\n",
    "\n",
    "def read_parameter_no_gamma(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "    return beta_a,phi_a,persev_a\n",
    "\n",
    "def read_parameter_no_gamma_no_persev(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "\n",
    "    return beta_a,phi_a\n",
    "\n",
    "def read_parameter_no_gamma_no_persev_no_phi(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "\n",
    "    beta_a = np.array(beta_a)\n",
    "\n",
    "    return beta_a\n",
    "\n",
    "def read_parameter_glm2(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a_0 = []\n",
    "    phi_a_0 = []\n",
    "    persev_a_0 = []\n",
    "    gamma_a_0 =[]\n",
    "    \n",
    "    beta_a_1 = []\n",
    "    phi_a_1 = []\n",
    "    persev_a_1 = []\n",
    "    gamma_a_1 = []\n",
    "\n",
    "    \n",
    "    beta_b = []\n",
    "    phi_b = []\n",
    "    persev_b = []\n",
    "    gamma_b = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a_0.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_0.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_0.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_0.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_a_1.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_1.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_1.append(parameter_result.iloc[i+subject_num*6,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_1.append(parameter_result.iloc[i+subject_num*7,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*8,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_b.append(parameter_result.iloc[i+subject_num*9,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_b.append(parameter_result.iloc[i+subject_num*10,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_b.append(parameter_result.iloc[i+subject_num*11,1])\n",
    "        \n",
    "    beta_a_0 = np.array(beta_a_0)\n",
    "    phi_a_0 = np.array(phi_a_0)\n",
    "    persev_a_0 = np.array(persev_a_0)\n",
    "    gamma_a_0 = np.array(gamma_a_0)\n",
    "    \n",
    "    beta_a_1 = np.array(beta_a_1)\n",
    "    phi_a_1 = np.array(phi_a_1)\n",
    "    persev_a_1 = np.array(persev_a_1)\n",
    "    gamma_a_1 = np.array(gamma_a_1)\n",
    "    \n",
    "    beta_b = np.array(beta_b)\n",
    "    phi_b = np.array(phi_b)\n",
    "    persev_b = np.array(persev_b)\n",
    "    gamma_b = np.array(gamma_b)\n",
    "    return beta_a_0,phi_a_0,persev_a_0,gamma_a_0,beta_a_1,phi_a_1,persev_a_1,gamma_a_1,beta_b,phi_b,persev_b,gamma_b\n",
    "\n",
    "def read_parameter_glm2_no_gamma(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a_0 = []\n",
    "    phi_a_0 = []\n",
    "    persev_a_0 = []\n",
    "    gamma_a_0 = []\n",
    "    \n",
    "    beta_a_1 = []\n",
    "    phi_a_1 = []\n",
    "    persev_a_1 = []\n",
    "    gamma_a_1 = []\n",
    "\n",
    "    \n",
    "    beta_b = []\n",
    "    phi_b = []\n",
    "    persev_b = []\n",
    "    gamma_b = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a_0.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_0.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_0.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_0.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_a_1.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a_1.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a_1.append(parameter_result.iloc[i+subject_num*6,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a_1.append(parameter_result.iloc[i+subject_num*7,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*8,1])\n",
    "\n",
    "        \n",
    "    beta_a_0 = np.array(beta_a_0)\n",
    "    phi_a_0 = np.array(phi_a_0)\n",
    "    persev_a_0 = np.array(persev_a_0)\n",
    "    gamma_a_0 = np.array(gamma_a_0)\n",
    "    \n",
    "    beta_a_1 = np.array(beta_a_1)\n",
    "    phi_a_1 = np.array(phi_a_1)\n",
    "    persev_a_1 = np.array(persev_a_1)\n",
    "    gamma_a_1 = np.array(gamma_a_1)\n",
    "    \n",
    "    beta_b = np.array(beta_b)\n",
    "\n",
    "    return beta_a_0,phi_a_0,persev_a_0,gamma_a_0,beta_a_1,phi_a_1,persev_a_1,gamma_a_1,beta_b\n",
    "\n",
    "def read_parameter_glm2_no_gamma_para(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a_0 = []\n",
    "    beta_a_1 = []\n",
    "    beta_b = []\n",
    "    phi_b = []\n",
    "    persev_b = []\n",
    "    for i in range(subject_num):\n",
    "        beta_a_0.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_a_1.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_b.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_b.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "       \n",
    "    beta_a_0 = np.array(beta_a_0)\n",
    "    beta_a_1 = np.array(beta_a_1)\n",
    "\n",
    "    \n",
    "    beta_b = np.array(beta_b)\n",
    "    phi_b = np.array(phi_b)\n",
    "    persev_b = np.array(persev_b)\n",
    "\n",
    "    return beta_a_0,beta_a_1,beta_b,phi_b,persev_b\n",
    "\n",
    "def read_parameter_glm_7_para(file_name): # read fitted parameters: beta_a,b;phi_a,b;persev_,b;gamma_a,b\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta_a = []\n",
    "    phi_a = []\n",
    "    persev_a = []\n",
    "    gamma_a = []\n",
    "    beta_b = []\n",
    "    phi_b = []\n",
    "    persev_b = []\n",
    "\n",
    "    for i in range(subject_num):\n",
    "        beta_a.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_a.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_a.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma_a.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        beta_b.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    for i in range(subject_num):\n",
    "        phi_b.append(parameter_result.iloc[i+subject_num*5,1])\n",
    "    for i in range(subject_num):\n",
    "        persev_b.append(parameter_result.iloc[i+subject_num*6,1])\n",
    "\n",
    "    beta_a = np.array(beta_a)\n",
    "    phi_a = np.array(phi_a)\n",
    "    persev_a = np.array(persev_a)\n",
    "    gamma_a = np.array(gamma_a)\n",
    "    beta_b = np.array(beta_b)\n",
    "    phi_b = np.array(phi_b)\n",
    "    persev_b = np.array(persev_b)\n",
    "\n",
    "    return beta_a,phi_a,persev_a,gamma_a,beta_b,phi_b,persev_b\n",
    "\n",
    "def read_parameter_happiness(file_name): #read fitted parameters: beta,phi,persev,gamma,comparison_level\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    phi = []\n",
    "    persev = []\n",
    "    gamma = []\n",
    "    comparison_level = []\n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        comparison_level.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    beta = np.array(beta)\n",
    "    phi = np.array(phi)\n",
    "    persev = np.array(persev)\n",
    "    gamma = np.array(gamma)\n",
    "    comparison_level = np.array(comparison_level)\n",
    "    return beta,phi,persev,gamma,comparison_level\n",
    "def read_parameter_learning(file_name): #read fitted parameters: beta,phi,persev,gamma,comparison_level\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    phi = []\n",
    "    persev = []\n",
    "    gamma = []\n",
    "    comparison_level = []\n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        comparison_level.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    beta = np.array(beta)\n",
    "    phi = np.array(phi)\n",
    "    persev = np.array(persev)\n",
    "    gamma = np.array(gamma)\n",
    "    comparison_level = np.array(comparison_level)\n",
    "    return beta,phi,persev,gamma,comparison_level\n",
    "def read_parameter_nhb_delta(file_name): #read fitted parameters: beta,phi,persev,gamma,learning_rate\n",
    "    parameter_result = pd.read_csv(file_name)\n",
    "    subject_num = 62\n",
    "    beta = []\n",
    "    phi = []\n",
    "    persev = []\n",
    "    gamma = []\n",
    "    learning_rate = []\n",
    "    for i in range(subject_num):\n",
    "        beta.append(parameter_result.iloc[i,1])\n",
    "    for i in range(subject_num):\n",
    "        phi.append(parameter_result.iloc[i+subject_num,1])\n",
    "    for i in range(subject_num):\n",
    "        persev.append(parameter_result.iloc[i+subject_num*2,1])\n",
    "    for i in range(subject_num):\n",
    "        gamma.append(parameter_result.iloc[i+subject_num*3,1])\n",
    "    for i in range(subject_num):\n",
    "        learning_rate.append(parameter_result.iloc[i+subject_num*4,1])\n",
    "    beta = np.array(beta)\n",
    "    phi = np.array(phi)\n",
    "    persev = np.array(persev)\n",
    "    gamma = np.array(gamma)\n",
    "    learning_rate = np.array(learning_rate)\n",
    "    return beta,phi,persev,gamma,learning_rate\n",
    "# calculate the log likelyhood\n",
    "def action_probability(Q,action):\n",
    "    return np.log(np.exp(Q[action])/(np.exp(Q[0])+np.exp(Q[1])+np.exp(Q[2])+np.exp(Q[3])))\n",
    "\n",
    "\n",
    "def log_likelyhood_ru_c(file_name):#nhb\n",
    "    beta,phi,persev,gamma = read_parameter(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        \n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                re = gamma[s] * np.ones((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev[s]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta[s]*v+eb+pb+re),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "\n",
    "def log_likelyhood_nhb_glm_ru_c(file_name):#nhb\n",
    "    beta_a,phi_a,persev_a,gamma_a,beta_b,phi_b,persev_b,gamma_b = read_parameter_glm(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                re = (gamma_a[s]*comparision[t]+gamma_b[s]) * np.ones((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability(((beta_a[s]*comparision[t]+beta_b[s])*v+eb+pb+re),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_glm2_ru_c(file_name):#nhb\n",
    "    beta_a_0,phi_a_0,persev_a_0,gamma_a_0,beta_a_1,phi_a_1,persev_a_1,gamma_a_1,beta_b,phi_b,persev_b,gamma_b = read_parameter_glm2(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.mean(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    re = (gamma_a_0[s]*comparision[t]+gamma_b[s]) * np.ones((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_a_0[s]*comparision[t]+beta_b[s])*v+eb+pb+re),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.mean(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    re = (gamma_a_1[s]*comparision[t]+gamma_b[s]) * np.ones((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_a_1[s]*comparision[t]+beta_b[s])*v+eb+pb+re),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "\n",
    "def log_likelyhood_nhb_glm_ru_no_gamma(file_name):#nhb\n",
    "    beta_a,phi_a,persev_a,beta_b,phi_b,persev_b = read_parameter_glm_3_para(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability(((beta_a[s]*comparision[t]+beta_b[s])*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_ru_no_gamma(file_name):#nhb\n",
    "    beta,phi,persev = read_parameter_3_para(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev[s]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta[s]*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_ru_no_gamma_no_persev(file_name):#nhb\n",
    "    beta,phi = read_parameter_no_gamma_no_persev(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi[s]) * re_sig\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta[s]*v+eb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_ru_no_gamma_no_persev_no_phi(file_name):#nhb\n",
    "    beta = read_parameter_no_gamma_no_persev_no_phi(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta[s]*v),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_sup_delta(file_name):#nhb\n",
    "    beta,phi,persev,alpha = read_parameter_sup(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev[s]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta[s]*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + alpha[s] * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_sup_dual_delta(file_name):#nhb\n",
    "    beta,phi,persev,pos_alpha,neg_alpha = read_parameter_sup_dual(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev[s]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta[s]*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                if pe>0:\n",
    "                    v[action[t]] = v[action[t]] + pos_alpha[s] * pe\n",
    "                else:\n",
    "                    v[action[t]] = v[action[t]] + neg_alpha[s] * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_sup_elife(file_name):#nhb\n",
    "    beta,phi,persev = read_parameter_3_para(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev[s]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability(beta[s]*(v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_sup_gamma(file_name):#nhb\n",
    "    beta,phi,persev,gamma = read_parameter_sup(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                re = gamma[s] * v / np.sum(sig)\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev[s]\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability((beta[s]*v+eb+pb+re),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_glm_ru_no_gamma_sqrt(file_name):#nhb\n",
    "    beta_a,phi_a,persev_a,beta_b,phi_b,persev_b = read_parameter_glm_3_para(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability(((beta_a[s]*comparision[t]+beta_b[s])*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_glm2_ru_no_gamma_task2(file_name):#nhb\n",
    "    beta_a_0,phi_a_0,persev_a_0,beta_a_1,phi_a_1,persev_a_1,beta_b,phi_b,persev_b = read_parameter_glm2_no_gamma(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.mean(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_a_0[s]*comparision[t]+beta_b[s])*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.mean(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_a_1[s]*comparision[t]+beta_b[s])*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_glm2_ru_no_gamma_sqrt_task2(file_name):#nhb\n",
    "    beta_a_0,phi_a_0,persev_a_0,beta_a_1,phi_a_1,persev_a_1,beta_b,phi_b,persev_b = read_parameter_glm2_no_gamma(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.mean(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_a_0[s]*comparision[t]+beta_b[s])*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.mean(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_a_1[s]*comparision[t]+beta_b[s])*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_glm_ru_no_gamma_beta_sqrt(file_name):#nhb\n",
    "    beta_a,beta_b,phi_b,persev_b = read_parameter_glm_no_gamma_para(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi_b[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_b[s])\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability(((beta_a[s]*comparision[t]+beta_b[s])*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_glm_ru_no_gamma_phi_sqrt(file_name):#nhb\n",
    "    phi_a,beta_b,phi_b,persev_b = read_parameter_glm_no_gamma_para(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi_a[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_b[s])\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_glm_ru_no_gamma_persev_sqrt(file_name):#nhb\n",
    "    persev_a,beta_b,phi_b,persev_b = read_parameter_glm_no_gamma_para(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi_b[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = (persev_a[s]*comparision[t]+persev_b[s])\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_glm2_ru_no_gamma_beta_sqrt_task2(file_name):#nhb\n",
    "    beta_a_0,beta_a_1,beta_b,phi_b,persev_b = read_parameter_glm2_no_gamma_para(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.mean(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_a_0[s]*comparision[t]+beta_b[s])*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.mean(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_a_1[s]*comparision[t]+beta_b[s])*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_glm2_ru_no_gamma_phi_sqrt_task2(file_name):#nhb\n",
    "    phi_a_0,phi_a_1,beta_b,phi_b,persev_b = read_parameter_glm2_no_gamma_para(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.mean(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_0[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.mean(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_a_1[s]*comparision[t]+phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_glm2_ru_no_gamma_persev_sqrt_task2(file_name):#nhb\n",
    "    persev_a_0,persev_a_1,beta_b,phi_b,persev_b = read_parameter_glm2_no_gamma_para(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,\n",
    "           11,12,13,14,15,16,17,18,19,20,\n",
    "           21,22,23,24,25,26,27,28,29,30,\n",
    "           31,32,33,34,35,37,38,39,40,\n",
    "           41,42,43,44,45,46,47,48,49,50,\n",
    "           51,52,53,54,55,56,57,58,59,60,\n",
    "           61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                if comparision[t]<0:\n",
    "                    \n",
    "                    #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                    min_sig = np.mean(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_0[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "                if comparision[t]>=0:\n",
    "                    min_sig = np.mean(sig)*np.ones((4))\n",
    "                    re_sig = sig-min_sig\n",
    "                    eb = (phi_b[s]) * re_sig\n",
    "                    pb = np.zeros((4))\n",
    "                    if t>0:\n",
    "                        if action[t-1]!=4:\n",
    "                            pb[action[t-1]] = (persev_a_1[s]*comparision[t]+persev_b[s])\n",
    "                    # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                    loglikelyhood += action_probability(((beta_b[s])*v+eb+pb),action[t])\n",
    "            \n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_competition_action(file_name):#nhb\n",
    "    beta,phi,persev,level = read_parameter_sup(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison_sqrt(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                compare = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev[s]\n",
    "                        compare[action[t-1]] = comparision[t]\n",
    "                happy = v + level[s]*compare\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability(((beta[s])*happy+eb+pb),action[t])\n",
    "                pe = reward[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n",
    "def log_likelyhood_nhb_competition_learn(file_name):#nhb\n",
    "    beta,phi,persev,level = read_parameter_sup(file_name)\n",
    "    subjects = 62\n",
    "    SUB = [1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,\n",
    "                50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]\n",
    "    trials = 150\n",
    "    subject_loglikelyhood = []\n",
    "    for s in range(subjects):\n",
    "        action,reward,reward_B,_ =read_data(SUB[s]) \n",
    "        comparision = rewards2comparison_sqrt_competition_learn(action,reward,reward_B,0)\n",
    "        loglikelyhood = 0\n",
    "        sig_o = 4\n",
    "        sig_d = 2.8\n",
    "        v = np.ones((4))*50\n",
    "        sig = np.ones((4))*4\n",
    "        for t in range(trials):\n",
    "            if action[t]!=4:\n",
    "                #beta:temperature; v:action value; eb:exploration bonus; pb: perseverance bonus; re: random exploration\n",
    "                min_sig = np.mean(sig)*np.ones((4))\n",
    "                re_sig = sig-min_sig\n",
    "                eb = (phi[s]) * re_sig\n",
    "                pb = np.zeros((4))\n",
    "                if t>0:\n",
    "                    if action[t-1]!=4:\n",
    "                        pb[action[t-1]] = persev[s]\n",
    "\n",
    "                # elife: beta[s]*(v+eb+pb+re); nhb: (beta[s]*v+eb+pb+re)\n",
    "                loglikelyhood += action_probability(((beta[s])*v+eb+pb),action[t])\n",
    "                pe = reward[t] + level[s]*comparision[t] - v[action[t]]\n",
    "                Kgain = np.square(sig[action[t]])/(np.square(sig[action[t]])+np.square(sig_o))\n",
    "                v[action[t]] = v[action[t]] + Kgain * pe\n",
    "                sig[action[t]] = np.sqrt((1-Kgain)*np.square(sig[action[t]]))\n",
    "            sig = np.sqrt(np.square(sig)+np.square(sig_d))\n",
    "        subject_loglikelyhood.append(loglikelyhood)\n",
    "    return subject_loglikelyhood\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "llh_task1 = [-140.440182402817, -173.579071128985, -184.41056672322637, -157.913167561772, -101.88246083646419, -182.77338790122153, -109.95947201455104, -172.4229758983203, -83.0063287899313, -147.8295505691502, -66.96056462579404, -117.16450793200084, -176.28664201271548, -142.79077280952293, -151.84457550822657, -86.49562154240448, -23.762131140435635, -91.48209446740982, -44.78796683585311, -111.95431879637106, -193.41009252666544, -159.9530187162133, -119.07973255703872, -159.72738482042573, -91.8379326440826, -29.917419972474917, -169.57222065653875, -167.14064458747495, -78.83941547304522, -134.6153318765231, -193.93623741358664, -86.88111843405268, -195.35123851076045, -134.29675480445752, -79.48462788508068, -166.97034082578102, -92.95421059197318, -76.36791348523606, -131.38941779261074, -60.126838105863044, -105.52428005634064, -174.17854646151343, -119.20925377969157, -104.80781095556712, -103.21543417806556, -47.69156029524072]\n",
    "llh_task2 = [-190.1399960355843, -143.4513384530129, -195.74791259080118, -174.20538814812028, -174.08222154500893, -201.77957710057288, -102.35151106367056, -105.10411577025214, -186.62275384203994, -106.45727880014117, -194.34306806314063, -133.77147565731576, -70.14944835346147, -116.8445138220269, -114.12941983319992, -160.14651832176554, -121.43235549325289, -196.70353366228503, -163.50629536545526, -113.33481927589972, -71.9426224141661, -170.43901231379274, -158.76775069631267, -153.12831450953666, -172.65215309143957, -132.79351073315692, -173.7583116862848, -155.9042056552798, -198.1117732467097, -146.67388134895975, -182.29238162337464, -116.25636216985272, -155.1905673818731, -199.7208448463437, -186.04134714237892, -203.28313333572595, -204.99734407085333, -115.36357661690724, -173.73209252108128, -88.70677573858946, -67.72330575913792, -207.45731260686114, -181.16674507148588, -89.39361365790018, -195.383139654264, -171.31023482337898]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00134353832318534\n"
     ]
    }
   ],
   "source": [
    "print(get_p_value(llh_task1,llh_task2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-190.1399960355843, -143.4513384530129, -195.74791259080118, -174.20538814812028, -174.08222154500893, -201.77957710057288, -102.35151106367056, -105.10411577025214, -186.62275384203994, -106.45727880014117, -194.34306806314063, -133.77147565731576, -70.14944835346147, -116.8445138220269, -114.12941983319992, -160.14651832176554, -121.43235549325289, -196.70353366228503, -163.50629536545526, -113.33481927589972, -71.9426224141661, -170.43901231379274, -158.76775069631267, -153.12831450953666, -172.65215309143957, -132.79351073315692, -173.7583116862848, -155.9042056552798, -198.1117732467097, -146.67388134895975, -182.29238162337464, -116.25636216985272, -155.1905673818731, -199.7208448463437, -186.04134714237892, -203.28313333572595, -204.99734407085333, -115.36357661690724, -173.73209252108128, -88.70677573858946, -67.72330575913792, -207.45731260686114, -181.16674507148588, -89.39361365790018, -195.383139654264, -171.31023482337898]\n"
     ]
    }
   ],
   "source": [
    "print(glm_sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-156.99593542294357\n"
     ]
    }
   ],
   "source": [
    "glm_sqrt = log_likelyhood_nhb_glm_ru_no_gamma_sqrt('./nhb_glm_ru_no_gamma_sqrt_task2v3.csv')\n",
    "print(np.mean(glm_sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_competition_action = log_likelyhood_nhb_competition_action('./nhb_competition_action_task2v3.csv')\n",
    "nhb_competition_learn = log_likelyhood_nhb_competition_learn('./nhb_competition_learn_task2v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9912.27915798596\n",
      "-10003.930321886042\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(nhb_competition_action))\n",
    "print(np.sum(nhb_competition_learn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_ru_no_gamma = log_likelyhood_nhb_ru_no_gamma('./nhb_ru_no_gamma_sqrt_task2v3.csv')\n",
    "nhb_ru_no_gamma_no_persev = log_likelyhood_nhb_ru_no_gamma_no_persev('./nhb_ru_no_gamma_no_persev_task2v3.csv')\n",
    "nhb_ru_no_gamma_no_persev_no_phi = log_likelyhood_nhb_ru_no_gamma_no_persev_no_phi('./nhb_ru_no_gamma_no_persev_no_phi_task2v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10058.432353977749\n",
      "-10602.554221449207\n",
      "-10694.098777090354\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(nhb_ru_no_gamma))\n",
    "print(np.sum(nhb_ru_no_gamma_no_persev))\n",
    "print(np.sum(nhb_ru_no_gamma_no_persev_no_phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_delta = log_likelyhood_sup_delta('./sup_delta_task2v3.csv')\n",
    "sup_dual_delta = log_likelyhood_sup_dual_delta('./sup_dual_delta_task2v3.csv')\n",
    "sup_elife = log_likelyhood_sup_elife('./sup_elife_task2v3.csv')\n",
    "sup_gamma = log_likelyhood_sup_gamma('./sup_gamma_task2v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10506.056480868652\n",
      "-9895.029970030373\n",
      "-10370.04651430849\n",
      "-10088.814965705895\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(sup_delta))\n",
    "print(np.sum(sup_dual_delta))\n",
    "print(np.sum(sup_elife))\n",
    "print(np.sum(sup_gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_glm = log_likelyhood_nhb_glm_ru_no_gamma_sqrt('./nhb_glm_ru_no_gamma_sqrt_task2v3.csv')\n",
    "nhb_glm_beta = log_likelyhood_nhb_glm_ru_no_gamma_beta_sqrt('./nhb_glm_ru_no_gamma_sqrt_beta_task2v3.csv')\n",
    "nhb_glm_phi = log_likelyhood_nhb_glm_ru_no_gamma_phi_sqrt('./nhb_glm_ru_no_gamma_sqrt_phi_task2v3.csv')\n",
    "nhb_glm_persev = log_likelyhood_nhb_glm_ru_no_gamma_persev_sqrt('./nhb_glm_ru_no_gamma_sqrt_persev_task2v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9733.747996222502\n",
      "-9958.432966938773\n",
      "-9861.53554218219\n",
      "-9852.577819292299\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(nhb_glm))\n",
    "print(np.sum(nhb_glm_beta))\n",
    "print(np.sum(nhb_glm_phi))\n",
    "print(np.sum(nhb_glm_persev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-162.23277990286692\n"
     ]
    }
   ],
   "source": [
    "nhb_ru_no_gamma = log_likelyhood_ru_no_gamma('./nhb_ru_no_gamma_sqrt_task2v3.csv')\n",
    "print(np.mean(nhb_ru_no_gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.61333333333334\n"
     ]
    }
   ],
   "source": [
    "action,reward,reward_B,_ =read_data(1) \n",
    "print(np.mean(reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04716273116129032\n",
      "0.12133017140322579\n",
      "0.8511362672096775\n"
     ]
    }
   ],
   "source": [
    "beta_a,phi_a,persev_a,beta_b,phi_b,persev_b = read_parameter_glm_3_para('./nhb_glm_ru_no_gamma_sqrt_task2v3.csv')\n",
    "print(np.mean(beta_b))\n",
    "print(np.mean(phi_b))\n",
    "print(np.mean(persev_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-154.6249228757881\n",
      "-156.99593542294357\n"
     ]
    }
   ],
   "source": [
    "glm2_no_gamma_sqrt_task2 = log_likelyhood_nhb_glm2_ru_no_gamma_sqrt_task2('./nhb_glm2_ru_no_gamma_sqrt_task2v3.csv')\n",
    "glm_sqrt = log_likelyhood_nhb_glm_ru_no_gamma_sqrt('./nhb_glm_ru_no_gamma_sqrt_task2v3.csv')\n",
    "print(np.mean(glm2_no_gamma_sqrt_task2))\n",
    "print(np.mean(glm_sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-167.73099504959148\n",
      "-166.34768011471226\n",
      "-165.34542983091796\n"
     ]
    }
   ],
   "source": [
    "glm_ru_no_gamma_beta = log_likelyhood_nhb_glm_ru_no_gamma_beta_sqrt('./nhb_glm_ru_no_gamma_sqrt_beta_task2v3.csv')\n",
    "glm_ru_no_gamma_phi = log_likelyhood_nhb_glm_ru_no_gamma_phi_sqrt('./nhb_glm_ru_no_gamma_sqrt_phi_task2v3.csv')\n",
    "glm_ru_no_gamma_persev = log_likelyhood_nhb_glm_ru_no_gamma_persev_sqrt('./nhb_glm_ru_no_gamma_sqrt_persev_task2v3.csv')\n",
    "print(np.mean(glm_ru_no_gamma_beta))\n",
    "print(np.mean(glm_ru_no_gamma_phi))\n",
    "print(np.mean(glm_ru_no_gamma_persev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_a_0,beta_a_1,_,_,_ = read_parameter_glm2_no_gamma_para('./nhb_glm2_ru_no_gamma_beta_sqrt_task2v3.csv')\n",
    "phi_a_0,phi_a_1,_,_,_ = read_parameter_glm2_no_gamma_para('./nhb_glm2_ru_no_gamma_phi_sqrt_task2v3.csv')\n",
    "persev_a_0,persev_a_1,_,_,_ = read_parameter_glm2_no_gamma_para('./nhb_glm2_ru_no_gamma_persev_sqrt_task2v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKMAAAHTCAYAAABLOaj1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARFUlEQVR4nO3df2xd9XmA8eeNXdJktLSYjHWGNEyONKXdP5tHtVWaupFQdxKk0uhGOymuRBdNKiFStVWsVWnFyjT2DwoZ1ZYNVsM6AWOaFjSUKCnrpHUqI2npQkpRb1lo4tEOHMSg/JqTd3/4pHIix47t69z3Xj8fKcq9537vOd8bPzn33Dg+JzITqYIVnZ6AdIoxqgxjVBnGqDKMUWUYo8ro7/QEFuKSSy7JdevWdXoaWoCDBw++kJlrZnqsK2Nct24dBw4c6PQ0tAAR8ezZHvNtWmUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqwxhVhjGqDGNcxiYmJrjpppuYmJjo9FQAY1zWxsbGOHToEPfee2+npwIY47I1MTHBnj17yEz27NlTYu9ojMvU2NgYJ0+eBODEiRMl9o7GuEzt37+fyclJACYnJ9m3b1+HZ2SMy9bGjRuJCAAigk2bNnV4Rsa4bF177bWcOulXZnLNNdd0eEbGuGzt3r37tD3jww8/3OEZGeOytX///tP2jB4zqmM2btxIf//Uj8339/d7zKjOGR0dZcWKqS9/X18fW7Zs6fCMjHHZGhgYYGRkhIhgZGSEgYGBTk+pO09vovYYHR3lyJEjJfaKYIzL2sDAAHfeeWenp/ETvk2rDGNUGcaoMoxRZRijyjBGlWGMKsMYVYYxqgxjVBnGqDKMUWUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqwxhVhjGqDGNUGcaoMtoSY0SMRMTTEdGKiJtneHxlRDzQPP5YRKxrlm+KiIMRcaj5/TfaMR91p0XHGBF9wF3Ah4ANwEcjYsMZw24AXszMIeAO4PZm+QvANZn5C8AocN9i56Pu1Y4945VAKzOfycw3gfuBzWeM2QyMNbcfAq6KiMjMb2XmfzfLDwOrImJlG+akLtSOGAeBo9PuH2uWzTgmMyeBl4Azz075W8A3M/ONNsxJXajE+Rkj4j1MvXVfPcuYrcBWgLVr156nmel8aseecRy4fNr9y5plM46JiH7gImCiuX8Z8I/Alsz8/tk2kpm7MnM4M4fXrFnThmmrmnbE+DiwPiKuiIgLgOuB3WeM2c3UBxSA64BHMzMj4h3APwM3Z+bX2zAXdbFFx9gcA94I7AWeAh7MzMMRcWtEXNsMuxsYiIgW8Cng1D//3AgMAbdExBPNr59e7JzUneLUhWm6yfDwcB44cKDT09ACRMTBzBye6TG/AzOHaler72XGOIdqV6vvZcY4i4pXq+9lxjiLiler72XGOIuKV6vvZcY4i4pXHu1lxjiLilce7WXGOIuKVx7tZSX+o0Rl1a482suMcQ7Vrjzay3ybVhnGqDKMUWUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqwxhVhjGqDGNUGcaoMoxRZRijyjBGlWGMKsMYVYYxqgxjVBnGqDKMUWUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqwxhVhjGqDGNUGcaoMoxRZRijyjBGlWGMKsMYVYYxqgxjVBnGqDKMUWUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqwxhVhjGqDGNUGcaoMoxRZRijyjBGlWGMKsMYVYYxqgxjVBnGqDKMUWUYo8owRpVhjCqjLTFGxEhEPB0RrYi4eYbHV0bEA83jj0XEumb5QET8S0S8EhF/3o65qHstOsaI6APuAj4EbAA+GhEbzhh2A/BiZg4BdwC3N8tfBz4H/MFi56Hu144945VAKzOfycw3gfuBzWeM2QyMNbcfAq6KiMjMH2fmvzEVpZa5/jasYxA4Ou3+MeB9ZxuTmZMR8RIwALzQhu3Py86dO2m1Wuc8fnx8HIDBwcFzGj80NMS2bdsWNLflrh0xnhcRsRXYCrB27drztt3XXnvtvG1ruWtHjOPA5dPuX9Ysm2nMsYjoBy4CJuazkczcBewCGB4ezoVOdr57re3btwOwY8eOhW5S56gdx4yPA+sj4oqIuAC4Hth9xpjdwGhz+zrg0cxccFDqTYveMzbHgDcCe4E+4J7MPBwRtwIHMnM3cDdwX0S0gONMBQtARBwB3g5cEBEfBq7OzO8sdl7qPm05ZszMR4BHzlh2y7TbrwMfOctz17VjDup+fgdGZRijyjBGlWGMKsMYVYYxqgxjVBnGqDKMUWUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqwxhVhjGqDGNUGcaoMoxRZXTNWchmM9/T3M3HqfWeOgFUO3n6vNP1RIytVosnnnyKE6svbvu6V7w5dX6qg8/8qK3r7Xv1eFvX1wt6IkaAE6sv5rWf/81OT+OcrfruI3MPWmY8ZlQZxqgyeuZtWlPm82Fuvucrh6X90GWMy1i185UbY4+Zz16r2vnKPWZUGcaoMoxRZRijyjBGlWGMKsMYVYYxqgxjVBnGqDKMUWUYo8owRpVhjCrDGFWGMaoMY1QZxqgyeuLHDsbHx+l79aWu+lnkvlcnGB+f7PQ0SnHPqDJ6Ys84ODjID9/o77ozSgwOXtrpaZTSEzH2uqU6sdVSntQK5v8z1sbYBVqtFt87/C3WXniireu94P+mjtLeePZAW9cL8INX+ub9HGPsEmsvPMFnfvF/Oz2Nc/Yn33z7vJ/jBxiVYYwqwxhVhjGqDGNUGcaoMoxRZRijyjBGlWGMKsMYVYYxqgxjVBnGqDKMUWUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqwxhVhjGqDGNUGcaoMtoSY0SMRMTTEdGKiJtneHxlRDzQPP5YRKyb9tgfNcufjogPtmM+6k6LjjEi+oC7gA8BG4CPRsSGM4bdALyYmUPAHcDtzXM3ANcD7wFGgC8169My1I4945VAKzOfycw3gfuBzWeM2QyMNbcfAq6KiGiW35+Zb2TmfwGtZn1ahtoR4yBwdNr9Y82yGcdk5iTwEjBwjs/VMtE1H2AiYmtEHIiIA88//3ynp6Ml0I5zeo8Dl0+7f1mzbKYxxyKiH7gImDjH5wKQmbuAXQDDw8PZhnl3jfHxcX78ct+CzpPdKc++3MdPjc/4pTyrduwZHwfWR8QVEXEBUx9Idp8xZjcw2ty+Dng0M7NZfn3zafsKYD3wH22Yk7rQoveMmTkZETcCe4E+4J7MPBwRtwIHMnM3cDdwX0S0gONMBUsz7kHgO8Ak8MnMbO/1JXrA4OAgb0w+13VXO1g5OL/D/7ZceiMzHwEeOWPZLdNuvw585CzPvQ24rR3zUHfrmg8w6n09c1GivlePL8lVVVe8PvXWePKt7f3w0PfqccBrB07XEzEODQ0t2bpbrZentvFz7Q7n0iWddzfqiRjnc7HE+Tp1kccdO3Ys2TY0xWNGlWGMKsMYVYYxqgxjVBnGqDKMUWUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqwxhVhjGqDGNUGcaoMoxRZRijyjBGlWGMKsMYVYYxqgxjVBnGqDKMUWUYo8owRpXRE2euXQ5+8Er7L0r0o1en9kWXrj7Z1vXC1HzXz/M5xtgFlurc32+2WgCsfHf717+e+c/bGLvAUp2zvNr5yj1mVBnGqDKMUWUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqwxhVhjGqDGNUGcaoMoxRZRijyjBGlWGMKsMYVYYxqgxjVBnGqDKMUWUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqwxhVhjGqDGNUGcaoMoxRZRijyjBGlWGMKsMYVYYxqoxFxRgRF0fEvoj4XvP7O88ybrQZ872IGJ22/LaIOBoRryxmHuoNi90z3gx8NTPXA19t7p8mIi4GPg+8D7gS+Py0aB9ulkmLjnEzMNbcHgM+PMOYDwL7MvN4Zr4I7ANGADLzG5n53CLnoB6x2BgvnRbTD4FLZxgzCByddv9Ys0w6Tf9cAyJiP/AzMzz02el3MjMjIts1sRnmsRXYCrB27dql2ow6aM4YM3Pj2R6LiB9FxLsy87mIeBfwPzMMGwc+MO3+ZcDX5jlPMnMXsAtgeHh4yaJX5yz2bXo3cOrT8SjwTzOM2QtcHRHvbD64XN0sk04z555xDn8KPBgRNwDPAr8NEBHDwO9n5icy83hE/DHwePOcWzPzeDPuz4CPAasj4hjw15n5hUXOaVY7d+6k1Wqd8/hTY7dv335O44eGhti2bduC5rbcLSrGzJwArpph+QHgE9Pu3wPcM8O4TwOfXswcltqqVas6PYVlY7F7xq7jXqsuvx2oMoxRZRijyjBGlWGMKsMYVYYxqgxjVBnGqDKMUWUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqwxhVhjGqDGNUGcaoMoxRZRijyjBGlWGMKsMYVYYxqgxjVBnGqDKMUWUYo8owxjlMTExw0003MTEx0emp9DxjnMPY2BiHDh3i3nvv7fRUep4xzmJiYoI9e/aQmezZs8e94xIzxlmMjY1x8uRJAE6cOOHecYkZ4yz279/P5OQkAJOTk+zbt6/DM+ptxjiLjRs30t8/dd2m/v5+Nm3a1OEZ9TZjnMXo6CgrVkz9EfX19bFly5YOz6i3GeMsBgYGGBkZISIYGRlhYGCg01Pqacvu2oHzNTo6ypEjR9wrngfGOIeBgQHuvPPOTk9jWfBtWmUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqw/8o0WN27txJq9U6p7Gnxm3fvv2c1z80NMS2bdsWNLe5GOMytmrVqk5P4TTG2GOWaq91PnjMqDKMUWUYo8owRpVhjCrDGFWGMaoMY1QZxqgyjFFlGKPKMEaVYYwqwxhVhjGqDGNUGcaoMoxRZURmdnoO8xYRzwPPnsdNXgK8cB63dz6d79f27sxcM9MDXRnj+RYRBzJzuNPzWAqVXptv0yrDGFWGMZ6bXZ2ewBIq89o8ZlQZ7hlVhjGqjJ6KMSLWRcST8xj/8Yj42aWcU7OdlRHxQES0IuKxiFi3wPVUfX2/FhHfjIjJiLhuoevpqRgX4OPAkn+xgBuAFzNzCLgDuP08bBPO3+v7QbOtv1vMSnoxxv6I+EpEPBURD0XE6oj4pYj414g4GBF7I+Jdzd/gYeArEfFERKyKiFsi4vGIeDIidkVEnG0jEfF7zdhvR8Q/RMTqWea0GRhrbj8EXDXburvt9WXmkcz8T+DkAl/TT1bUM7+AdUAC72/u3wP8IfDvwJpm2e8A9zS3vwYMT3v+xdNu3wdcM8u2Bqbd/iKwbZaxTwKXTbv/feCSXnl908Z9GbhuoV+/Xjwl3tHM/Hpz+2+BzwDvBfY1O4I+4LmzPPfXI+LTwGrgYuAw8PBZxr43Ir4IvAO4ENjbltnPrWdfXy/GeOY/nL4MHM7MX5ntSRHxVuBLTO1JjkbEF4C3zvKULwMfzsxvR8THgQ/MMnYcuBw4FhH9wEXAxGzzmUXF19cWvXjMuDYiTn1hPgZ8A1hzallEvCUi3tM8/jLwtub2qS/MCxFxITDXp8K3Ac9FxFuA351j7G5gtLl9HfBo5oK/21Dx9bVFL8b4NPDJiHgKeCewk6k/+Nsj4tvAE8CvNmO/DPxFRDwBvAH8FVPHd3uBx+fYzueAx4CvA9+dY+zdwEBEtIBPATfP6xWdrtzri4hfjohjwEeAv4yIw/N+VfjtQBXSi3tGdale/ADTVhFxF/D+MxbvyMy/mWHsZ5l6q5ru7zPztqWa32JVen2+TasM36ZVhjGqDGNUGcaoMoxRZfw/1A6hyOvJPOQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 144x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "condition = []\n",
    "for i in range(46):\n",
    "    condition.append('beta_a_0')\n",
    "for i in range(46):\n",
    "    condition.append('beta_a_1')\n",
    "data = {\"value\":np.array([beta_a_0,beta_a_1]).reshape(-1,1).squeeze(),\n",
    "        \"condition\":condition}\n",
    "plt.figure(figsize=(2,8))\n",
    "sns.boxplot(data=data,y='value',x='condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 144x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "condition = []\n",
    "for i in range(46):\n",
    "    condition.append('phi_a_0')\n",
    "for i in range(46):\n",
    "    condition.append('phi_a_1')\n",
    "data = {\"value\":np.array([phi_a_0,phi_a_1]).reshape(-1,1).squeeze(),\n",
    "        \"condition\":condition}\n",
    "plt.figure(figsize=(2,8))\n",
    "sns.boxplot(data=data,y='value',x='condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 144x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "condition = []\n",
    "for i in range(46):\n",
    "    condition.append('persev_a_0')\n",
    "for i in range(46):\n",
    "    condition.append('persev_a_1')\n",
    "data = {\"value\":np.array([persev_a_0,persev_a_1]).reshape(-1,1).squeeze(),\n",
    "        \"condition\":condition}\n",
    "plt.figure(figsize=(2,8))\n",
    "sns.boxplot(data=data,y='value',x='condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_a,beta,_,_ = read_parameter_glm_no_gamma_para('./nhb_glm_ru_no_gamma_sqrt_beta_task2v3.csv')\n",
    "phi_a,_,phi,_ = read_parameter_glm_no_gamma_para('./nhb_glm_ru_no_gamma_sqrt_phi_task2v3.csv')\n",
    "persev_a,_,_,persev = read_parameter_glm_no_gamma_para('./nhb_glm_ru_no_gamma_sqrt_persev_task2v3.csv')\n",
    "beta_norm = np.divide(beta_a,beta)\n",
    "phi_norm = np.divide(phi_a,phi)\n",
    "persev_norm = np.divide(persev_a,persev)\n",
    "# data = {'beta_a':beta_a,'phi_a':phi_a,'persev_a':persev_a,\n",
    "#         'beta_norm':beta_norm,'phi_norm':phi_norm,'persev_norm':persev_norm}\n",
    "data = {'beta_a':beta_a,'phi_a':phi_a,'persev_a':persev_a,\n",
    "        'beta_norm':beta_norm,'phi_norm':phi_norm,'persev_norm':persev_norm}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(beta_a,bins=20,edgecolor='black')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD7CAYAAABOi672AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARXklEQVR4nO3de2yTZf/H8U8ZHUi0IcBgsonk8YRHjFF0YtR52glkGyQIU5fgwkGNCFHEczwh+sfmYWI0ECSIJyJsOoEIosZlEBwxIXKSkOgzNgojgo0M2Dqu3x/+mKsbdE+7tvu69ytpAt190e/VhffudNtdj3POCQDQ4/VJ9AAAgK4h2ABgBMEGACMINgAYQbABwIiYBTsYDGrfvn0KBoOxeggA6FViFmy/36/bb79dfr8/Vg8BAL0KL4kAgBEEGwCMINgAYATBBgAjCDYAGEGwAcAIgg0ARhBsADCCYAOAEQQbiLO09BHyeDwR3dLSRyR6fCRQ30QPAPQ2DfV1Gje3IqK1VaX53ToLbOEMGwCMINgAYATBBgAjCDYAGEGwAcAIgg0ARhBsADCCYAOAEQQbAIwg2ABgBMEGACMINgAYQbABwAiCDQBGEGwAMIJgA4ARBBsAjCDYAGBEl4JdWVmpvLw85eXl6bXXXov1TACAToQN9rFjx/TKK69o+fLlqqysVG1trWpqauIxGwCgnbBvwtva2qqTJ0/q2LFjGjBggILBoPr16xdyTCAQUCAQCLnP7/d376QA0MuFDfbZZ5+t2bNnKycnR/3799eYMWN0zTXXhByzbNkylZeXx2xIoKdJSx+hhvq6RI+BXiZssHft2qXPP/9c3377rc455xw99thjWrJkiUpKStqOKS4uVkFBQcg6v9+voqKi7p8Y6AEa6us0bm5FRGurSvO7dRb0HmFfw66urlZGRoYGDx6s5ORkFRYWasuWLSHH+Hw+paenh9xSU1NjNjQA9EZhgz1q1CjV1NSoqalJzjlt3LhRV155ZTxmAwC0E/YlkZtuukk7duxQYWGhvF6vrrzySk2fPj0eswEA2gkbbEmaPn06kQaABOM3HQHACIINAEYQbAAwgmADgBEEGwCMINgAYATBBgAjCDYAGEGwAcAIgg0ARhBsADCCYAOAEQQbAIwg2ABgBMEGACMINgAYQbABwAiCDfQSaekj5PF4IrqlpY9I9PhQF98iDIB9DfV1Gje3IqK1VaX53ToLIsMZNgAYQbABwAiCDQBGEGwAMIJgA4ARBBsAjCDYAGAEwQYAIwg2ABhBsAHACIINAEYQbAAwgmADgBEEGwCMINgAYATBBgAjCDYAGEGwAcCILgV748aNKiwsVHZ2tl5++eVYzwQA6ETYYNfV1en555/XokWL9OWXX2rHjh36/vvv4zEbAKCdsG/Cu379euXm5io1NVWSVFZWpn79+oUcEwgEFAgEQu7z+/3dOCYAIGywf/vtN3m9Xj3wwANqbGxUZmamHn300ZBjli1bpvLy8ljNCCDB+iR55fF4Il7f19tfwZbjEa0dnnae6vf9N+LH/jcJG+zW1lbV1tZq+fLlGjBggB588EGtXr1ahYWFbccUFxeroKAgZJ3f71dRUVH3Twwg7k62tmjc3IqI11eV5ke8vqo0P+LH/bcJG+whQ4YoIyNDgwYNkiTdfvvt2rZtW0iwfT6ffD5f7KYEAIT/pmNmZqaqq6sVCATU2tqqH374QZdffnk8ZgMAtBP2DHv06NEqKSnR1KlT1dLSorFjx2rixInxmA0A0E7YYEvSpEmTNGnSpFjPAgA4A37TEQCMINgAYATBBgAjCDYAGEGwAcAIgg0ARhBsADCCYAOAEQQbAIwg2ABgBMEGACMINgAYQbABwAiCDQBGEGwAMIJgA4ARBBsAjCDYMCstfYQ8Hk9Et7T0EYkeH/ifdektwoCeqKG+TuPmVkS0tqo0v1tnAeKBM2wAMIJgA4ARBBsAjCDYAGAEwQYAIwg2ABhBsAHACIINAEYQbAAwgmADgBEEGwCMINgAYATBBgAjCDYAGEGwAcAIgg0ARhBsADCCYAOAEV0O9muvvab58+fHchYAwBl0KdibNm3S6tWrYz0LAOAMwr4J75EjR1RWVqaZM2dq165dnR4TCAQUCARC7vP7/d0zIQBAUheC/dxzz2nOnDnav3//aY9ZtmyZysvLu3UwAB31SfLK4/EkegwkyBmDvXLlSp177rnKyMjQqlWrTntccXGxCgoKQu7z+/0qKirqnikBSJJOtrZo3NyKiNZWleZ36yyIvzMGe82aNWpsbNSECRP0xx9/qKmpSQsWLNBTTz0VcpzP55PP54vpoADQ250x2EuXLm3786pVq7Rly5YOsQYAxAc/hw0ARoT9puMphYWFKiwsjOUsAIAz4AwbAIwg2ABgBMEGACMINgAYQbABwAiCDQBGEGwAMIJgA4ARBBsAjCDYAGAEwQYAIwg2ABhBsAHACIINAEYQbAAwgmADgBEEGwCM6PI7zgD/Jn2SvPJ4PIkeA10Qzeeqr7e/gi3HI1o7PO081e/7b0RrY4Vgo1c62dqicXMrIl5fVZrfbbPgzKL5XFWV5ke1tqfhJREAMIJgA4ARBBsAjCDYAGAEwQYAIwg2ABhBsAHACIINAEYQbAAwgmADgBEEGwCMINgAYATBBgAjCDYAGEGwAcAIgg0ARhBsADCCYAOAEV16i7Dy8nKtXbtWknTLLbdo3rx5MR0KANBR2DPsmpoaVVdXa/Xq1aqoqND27du1fv36eMwGAGgn7Bl2SkqK5s+fr+TkZEnSBRdcoIaGhpBjAoGAAoFAyH1+v78bxwQAhA32RRdd1PbnX3/9VWvWrNEnn3wScsyyZctUXl7e/dPBhLT0EWqor4tobV9vfwVbjnfzRMC/U5dew5akPXv2aMaMGXriiSc0cuTIkI8VFxeroKAg5D6/36+ioqJuGRI9W0N9ncbNrYhobVVpflRrgd6kS8HeunWrHnnkET311FPKy8vr8HGfzyefz9ftwwEA/hY22Pv379dDDz2ksrIyZWRkxGMmAEAnwgZ7yZIlOnHihBYuXNh23z333KMpU6bEdDAAQKiwwX7mmWf0zDPPxGMWAMAZ8JuOAGAEwQYAIwg2ABhBsAHACIINAEYQbAAwgmADgBEEGwCMINgAYATBBgAjCDYAGEGwAcAIgg0ARhBsADCCYAOAEQQbAIwg2ABgRI8Ndlr6CHk8nohuaekjEj1+3EXzfHmTz4p4rcfjSfTWgZjok+SN6v9FLDrUpXdNT4SG+jqNm1sR0dqq0vxuncWCaJ+vSNeeWg/825xsbelx/y967Bk2ACAUwQYAIwg2ABhBsAHACIINAEYQbAAwgmADgBEEGwCMINgAYATBBgAjCDYAGEGwAcAIgg0ARhBsADCCYAOAEQQbAIwg2ABgBMEGACO6FOwvv/xSubm5uvPOO7VixYpYzwQA6ETY93Q8cOCAysrKtGrVKiUnJ+uee+7R9ddfrwsvvDAe8wEA/l/YYNfU1OiGG27QwIEDJUlZWVlat26dHn744bZjAoGAAoFAyLr6+npJkt/vj2ywvn3V0vR7xGv37dsX0Vqron2+Il2byMdmzzbWJvKxE73naDqUmpqqvn1DE+1xzrkzLXrvvffU1NSkOXPmSJJWrlypbdu26aWXXmo75u2331Z5eXnEgwEAQn3zzTdKT08PuS/sGXZnPfd4PCF/Ly4uVkFBQch9zc3Nqqur08iRI5WUlBTJvAnj9/tVVFSkFStWKDU1NdHjRI399Gzsp2dL1H46e6ywwR42bJhqa2vb/n7w4EENHTo05Bifzyefz9dh7X/+859I5uwxUlNTO3yFs4z99Gzsp2frCfsJ+1MiN954ozZt2qTff/9dx44d09dff62bb745HrMBANrp0hn2nDlzdP/996ulpUWTJk3SVVddFY/ZAADthA22JI0fP17jx4+P9SwAgDPgNx074fP59PDDD3f6urxF7KdnYz89W0/aT9gf6wMA9AycYQOAEQQbAIzotcFuaGhQUVGRsrOzNWvWLB09erTDMc3NzXr88ceVk5OjgoIC7d27t+1jCxYsUF5ensaNG6eqqqp4jt6paPbjnNM777yj/Px8ZWVlqaKiIs7TdxTt50eSgsGgJk+erFWrVsVr7NOKZj9Hjx7V7Nmz2775/9VXX8V7/BDhLga3c+dOTZw4UVlZWXr66acVDAYlde05SIRI97N161ZNnDhREyZMUHFxcdvlOGLK9VLTp093VVVVzjnnysvL3euvv97hmMWLF7tnn33WOefcli1b3KRJk5xzztXU1LjJkye7YDDoGhsb3bXXXuuampriN3wnotlPRUWFmzp1qjtx4oQ7ePCgy8jIcH/88Uf8hu9ENPs55Y033nBjxoxxn3/+eewHDiOa/ZSWlrqFCxc655w7dOiQGzt2rGtsbIzT5KH8fr/LzMx0hw8fdkePHnXjx493e/bsCTkmLy/P/fTTT84555588km3YsUK51zXnoN4i2Y/mZmZbufOnc4551auXOlmzpwZ83l75Rl2S0uLfvzxR2VlZUmSCgsLtW7dug7Hfffdd7r77rslSdddd50OHz6shoYGtba26sSJEwoGgzp27JiSk5PjOv8/RbuftWvXatq0aUpOTlZKSoo++ugj9e/fP657aC/a/Uh/nf3s3r1bmZmZ8Rv8NKLdz5gxY3TfffdJkgYPHqyBAwfq0KFD8dtAO+0vBjdgwIC2i8GdUl9fr+PHj+vqq6+W9Pdeu/ocxFuk+2lubtbs2bM1atQoSdIll1yi/fv3x3zeXhnsw4cP6+yzz267ElZKSooOHDjQ4biDBw8qJSWl7e8pKSny+/266aabdN555+nmm29Wbm6upk+frrPOOitu8/9TtPv57bfftHfvXk2ePFkFBQXasWNHQr8IRbufP//8UwsXLtSLL74Yt5nPJNr9jB07VsOHD5ckrVmzRs3NzQm7vPE/Zxw6dGjIXjrbw4EDB7r8HMRbpPtJTk7WhAkTJEknT55UeXm57rjjjpjP26VfnLFs7dq1evXVV0PuGzlyZIfj/nlBq9Pp06ePPv30UyUlJam6ulpHjhzR/fffr9GjR7d9FY6lWOyntbVVu3fv1ocffqhDhw5pypQpuuyyyzr9d7tbLPbzwgsvaObMmRoyZEh3jPg/icV+2v/bCxYs0OLFiztcdjNeXJiLwZ3u4+HWJUqk+zmlublZ8+fPVzAY1IwZM2IzZDv/+mDn5OQoJycn5L6WlhZdf/31am1tVVJSkhobGztc0Er666ttY2Ojzj//fElqO27RokWaMmWKvF6vUlJSdOutt6q2tjYuwY7FfoYMGaLs7Gx5vV6de+65Gj16tHbs2BGXYHf3flJSUrRp0yb98ssveuutt7R//35t3rxZffv2bXu5wdJ+Th23fPlyLVmyREuWLNEll1wS832cTriLwQ0bNizk5ZpTexg0aJD+/PPPsM9BvEW6H+mvbwbPmjVLAwcO1Lvvviuv1xvzeXvlSyJer1fXXnut1qxZI0mqqKjo9IJWt9xyiyorKyVJtbW16tevn4YPH65Ro0Zpw4YNkqSmpiZt3rxZV1xxRfw28A/R7iczM1Nr166Vc06HDx/Wtm3bdOmll8Z1D+1Fs5+0tDRVV1ersrJSlZWVuu222/TII4/EJdanE+3nZ8OGDfrggw/08ccfJzTWUviLwaWlpalfv37aunWrpL/32tXnIN4i3Y8kPf744zr//PP15ptvxu8lxJh/W7OH2rdvn7v33ntdTk6OmzZtmjty5IhzzrmPPvrIvfHGG845544fP+7mzZvncnNzXX5+vvv555+dc84dPXrUzZs3z2VnZ7u8vDy3dOnSRG2jTTT7aW5udq+88orLzc11WVlZ7rPPPkvYPk6JZj/tPfHEEz3ip0Si2c/48ePd2LFj3d13391227ZtW8L28sUXX7i8vDx31113uffff98551xJSUnbTDt37nQTJ0502dnZbu7cue7EiRPOudM/B4kWyX62b9/uLr74Ypebm9v2OSkpKYn5rPxqOgAY0StfEgEAiwg2ABhBsAHACIINAEYQbAAwgmADgBEEGwCMINgAYMT/AbQl4peCYM/UAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(phi_a,bins=20,edgecolor='black')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(persev_a,bins=20,edgecolor='black')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(beta,bins=20,edgecolor='black')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(phi,bins=20,edgecolor='black')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(persev,bins=20,edgecolor='black')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15735784768697506\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = stats.ttest_1samp(beta_norm, 0)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.045030017082764e-05\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = stats.ttest_1samp(phi_norm, 0)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7191605594735604e-06\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = stats.ttest_1samp(persev_norm, 0)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 86.4x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = (np.random.random((62))-np.ones((62))*0.5)*0.6\n",
    "plt.figure(figsize=(1.2,6))\n",
    "sns.boxplot(data=df[\"beta_norm\"],linewidth=2,fliersize=0,color='white')\n",
    "plt.scatter(x,beta_norm,s=30,color='royalblue',linewidths=0.5,alpha=0.8)\n",
    "plt.yticks([-3,-2,-1,0,1,2])\n",
    "plt.xticks([])\n",
    "plt.ylim([-2.2,2])\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 86.4x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = (np.random.random((62))-np.ones((62))*0.5)*0.6\n",
    "plt.figure(figsize=(1.2,6))\n",
    "sns.boxplot(data=df[\"phi_norm\"],linewidth=2,fliersize=0,color='white')\n",
    "plt.scatter(x,phi_norm,s=30,color=(81/255, 214/255, 255/255),linewidths=0.5,alpha=0.8)\n",
    "plt.yticks([-3,-2,-1,0,1,2])\n",
    "plt.xticks([])\n",
    "plt.ylim([-2.2,2])\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 86.4x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = (np.random.random((62))-np.ones((62))*0.5)*0.6\n",
    "plt.figure(figsize=(1.2,6))\n",
    "sns.boxplot(data=df[\"persev_norm\"],linewidth=2,fliersize=0,color='white')\n",
    "plt.scatter(x,persev_norm,s=30,color='skyblue',linewidths=0.5,alpha=0.8)\n",
    "plt.yticks([-3,-2,-1,0,1,2])\n",
    "plt.xticks([])\n",
    "plt.ylim([-2.2,2])\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_a,phi_a,persev_a,beta_b,phi_b,persev_b = read_parameter_glm_3_para('./nhb_glm_ru_no_gamma_sqrt_task2v3.csv')\n",
    "data = {'beta_a':beta_a,'phi_a':phi_a,'persev_a':persev_a}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5752436518358337, 0.5672424224030783, 61.0)\n"
     ]
    }
   ],
   "source": [
    "d = sm.stats.DescrStatsW(beta_a)\n",
    "print(d.ttest_mean(0))\n",
    "# import statsmodels.stats.weightstats \n",
    "# z,pval = statsmodels.stats.weightstats(data['beta_a'],value=0)\n",
    "# print(z,pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_a_task1 = [0.00097608, -0.001000131, -0.000395348, 0.007428459, 0.013607663, 0.011833751, 0.001699002, 0.010883782, 0.011808975, 0.00546067, 0.000794419, 0.007767514, -0.001469065, 0.009611183, 0.005569217, 0.005823073, 0.007729267, 0.011634529, 0.006826233, 0.013824823, 0.001741767, 0.012649176, 0.002539273, -0.002076027, 0.017377162, 0.011361612, 0.008048473, 0.003734259, 0.007057873, 0.007342628, -0.000360819, 0.012931463, 0.001081247, 0.009832184, 0.008734755, 0.002251463, -0.000425405, 0.01416426, 0.01370699, 0.015798669, 0.003355362, -0.00061569, 0.006821868, 0.003521461, 0.012306518, 0.008321856]\n",
    "phi_a_task1 = [-0.016765288, -0.023271977, -0.025077523, -0.01262617, -0.058780819, -0.004680608, -0.007852543, -0.029045234, -0.012808073, 0.014809459, -0.025820274, -0.041756473, -0.04722482, -0.042012111, -0.043637902, -0.029015232, -0.006294179, -0.04593319, -0.048420001, -0.048272497, -0.004992295, -0.022065832, -0.021737275, -0.003236842, -0.045364555, -0.044373222, -0.045237802, -0.069970798, -0.011788373, -0.016073619, 0.011987613, -0.025097504, 0.01892951, -0.052127773, -0.074700645, 0.026985483, -0.00939715, -0.051109949, -0.075901617, -0.040472687, -0.009342589, -0.045157132, -0.036676848, -0.021484073, -0.052577207, -0.049077109]\n",
    "persev_a_task1 = [0.107634599, 0.106203849, 0.104906043, 0.172990487, 0.499521336, 0.285805225, 0.158954669, 0.18616974, 0.331826009, 0.311706553, 0.321789268, 0.737636471, 0.161406982, 0.333195453, 0.046479939, 0.256077267, 0.200854731, 0.60070845, 0.120949461, 0.418376745, 0.084348457, 0.250232253, 0.206334875, 0.059449977, 0.406852932, 0.285345763, 0.204745443, 0.385691573, 0.179048352, 0.148566255, -0.043264862, 0.148527304, -0.103027371, 0.366675958, 0.711935855, -0.233229929, 0.206527758, 0.522355008, 0.374769025, 0.235136416, 0.125518604, 0.06454168, 0.3281264, 0.329729532, 0.519153106, 0.129862707]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006421087579476862\n"
     ]
    }
   ],
   "source": [
    "print(get_p_value(beta_a, beta_a_task1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006017468498305728\n"
     ]
    }
   ],
   "source": [
    "print(get_p_value(phi_a, phi_a_task1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.09700043576009e-11\n"
     ]
    }
   ],
   "source": [
    "print(get_p_value(persev_a, phi_a_task1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 72x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(1,6))\n",
    "sns.boxplot(data=df[\"persev_a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_a,phi_a,persev_a,beta,phi,persev = read_parameter_glm_3_para('./nhb_glm_ru_no_gamma_sqrt_task2v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(beta_a,bins=20,edgecolor='black')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(phi_a,bins=20,edgecolor='black')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(persev_a,bins=20,edgecolor='black')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(beta,bins=20,edgecolor='black')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(phi,bins=20,edgecolor='black')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(persev,bins=20,edgecolor='black')\n",
    "sns.set(style='ticks')\n",
    "sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17680b14d7d9a3bae9c4871fddb2c879681776f38d67c6256fcb9de429c7e820"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
